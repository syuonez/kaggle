{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"kaggle_rainforest.ipynb","provenance":[{"file_id":"1b6fVC-AcLCKjFCDV6ZP2w3ybJX3nIktF","timestamp":1625281895552},{"file_id":"1ZEGI4FSGMBOKB-_LQjv25E8nz1BXEyOP","timestamp":1613256988512},{"file_id":"1ZxxigeQ3ZYNW1GCoLDXtFAGiDezp3Uva","timestamp":1613201170373},{"file_id":"1Un7AxKiyCGwOCGnSmF1zCf3gcmdUrX2J","timestamp":1613175231195},{"file_id":"1_hXOadHZorBok8jL95BcT58kR70g8ywU","timestamp":1613174445259},{"file_id":"1G5YZm31leKrAB7R7516mW0-8Y0O9BNPF","timestamp":1613144310834},{"file_id":"1q3sVw0Qeq1rPeUcbnKXOrpZSABtHDDwG","timestamp":1613053348703},{"file_id":"1V9b01nJ09iqQzXxU87L_gSSPHFE-K0Uk","timestamp":1613010546951},{"file_id":"1owl8TFVSxT17jlRxx_GnU_T019HJC9Gq","timestamp":1612972188611},{"file_id":"13un31ZNh9JhJxYCbR5WniSv79KxZF2as","timestamp":1612929594820},{"file_id":"1obu3ChrC8SBkEMzDsX2SAPudixryqF-S","timestamp":1612662013842},{"file_id":"1ExKd_NlYCJhVfedUjMby76e86Rk96b-3","timestamp":1612358277736}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyMqC9cjys66MmHqA3tiwOAP"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WbNtCffgf9Sw"},"source":["# Import"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kz-0T55VKldx","executionInfo":{"elapsed":853,"status":"ok","timestamp":1613267836230,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"2a4d13d0-ba9a-4a56-d8ac-517c974f30e9"},"source":["import subprocess\n","import json\n","import pickle\n","\n","DEFAULT_ATTRIBUTES = (\n","    'index',\n","    'uuid',\n","    'name',\n","    'timestamp',\n","    'memory.total',\n","    'memory.free',\n","    'memory.used',\n","    'utilization.gpu',\n","    'utilization.memory'\n",")\n","\n","def get_gpu_info(nvidia_smi_path='nvidia-smi', keys=DEFAULT_ATTRIBUTES, no_units=True):\n","    nu_opt = '' if not no_units else ',nounits'\n","    cmd = '%s --query-gpu=%s --format=csv,noheader%s' % (nvidia_smi_path, ','.join(keys), nu_opt)\n","    output = subprocess.check_output(cmd, shell=True)\n","    lines = output.decode().split('\\n')\n","    lines = [ line.strip() for line in lines if line.strip() != '' ]\n","\n","    return [ { k: v for k, v in zip(keys, line.split(', ')) } for line in lines ]\n","\n","\n","import pprint\n","pprint.pprint(get_gpu_info())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[{'index': '0',\n","  'memory.free': '16160',\n","  'memory.total': '16160',\n","  'memory.used': '0',\n","  'name': 'Tesla V100-SXM2-16GB',\n","  'timestamp': '2021/02/14 01:57:15.701',\n","  'utilization.gpu': '0',\n","  'utilization.memory': '0',\n","  'uuid': 'GPU-419b2a37-5033-f671-8d48-762ff3b6436f'}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_PDTXIuKPOC","executionInfo":{"status":"ok","timestamp":1625282187683,"user_tz":-540,"elapsed":125969,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"}},"outputId":"87c93f6f-4792-47f0-885f-72f5a39de0c2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XkUFQbQJKcof","executionInfo":{"elapsed":8059,"status":"ok","timestamp":1613267888025,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"46192762-e163-4855-ac5b-1482c324fb4a"},"source":["cd /content/drive/My Drive/kaggle/kaggle-bird"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/kaggle/kaggle-bird\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ll8V6K24K3Nz","executionInfo":{"elapsed":25869,"status":"ok","timestamp":1613267906082,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"14db951a-6be8-4594-ac7a-774d2cc6df5b"},"source":["!pip -q install --upgrade pip\n","!pip -q install timm\n","!pip -q install torchlibrosa\n","!pip -q install audiomentations\n","!pip -q install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.5MB 13.0MB/s \n","\u001b[K     |████████████████████████████████| 244 kB 13.3 MB/s \n","\u001b[?25h  Building wheel for warmup-scheduler (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iWJiFzOALY8S","executionInfo":{"elapsed":38304,"status":"ok","timestamp":1613267918698,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"c9ca6b95-d053-46e2-b267-fb10f3b68572"},"source":["!pip install microsoftvision\n","!pip install soundfile\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting microsoftvision\n","  Downloading microsoftvision-1.0.5-py3-none-any.whl (5.7 kB)\n","Collecting azure-storage-blob\n","  Downloading azure_storage_blob-12.7.1-py2.py3-none-any.whl (339 kB)\n","\u001b[K     |████████████████████████████████| 339 kB 12.4 MB/s \n","\u001b[?25hCollecting azure-identity\n","  Downloading azure_identity-1.5.0-py2.py3-none-any.whl (103 kB)\n","\u001b[K     |████████████████████████████████| 103 kB 22.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from microsoftvision) (4.41.1)\n","Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from microsoftvision) (1.7.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->microsoftvision) (1.19.5)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->microsoftvision) (0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->microsoftvision) (3.7.4.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->microsoftvision) (0.16.0)\n","Collecting cryptography>=2.1.4\n","  Downloading cryptography-3.4.5-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n","\u001b[K     |████████████████████████████████| 3.2 MB 22.0 MB/s \n","\u001b[?25hCollecting msal<2.0.0,>=1.6.0\n","  Downloading msal-1.9.0-py2.py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 7.7 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.6 in /usr/local/lib/python3.6/dist-packages (from azure-identity->microsoftvision) (1.15.0)\n","Collecting msal-extensions~=0.3.0\n","  Downloading msal_extensions-0.3.0-py2.py3-none-any.whl (16 kB)\n","Collecting azure-core<2.0.0,>=1.0.0\n","  Downloading azure_core-1.11.0-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 96.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from azure-core<2.0.0,>=1.0.0->azure-identity->microsoftvision) (2.23.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.1.4->azure-identity->microsoftvision) (1.14.4)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-identity->microsoftvision) (2.20)\n","Collecting PyJWT[crypto]<3,>=1.0.0\n","  Downloading PyJWT-2.0.1-py3-none-any.whl (15 kB)\n","Collecting portalocker~=1.0\n","  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.0.0->azure-identity->microsoftvision) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.0.0->azure-identity->microsoftvision) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.0.0->azure-identity->microsoftvision) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.0.0->azure-identity->microsoftvision) (2020.12.5)\n","Collecting msrest>=0.6.18\n","  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n","\u001b[K     |████████████████████████████████| 85 kB 4.9 MB/s \n","\u001b[?25hCollecting isodate>=0.6.0\n","  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.18->azure-storage-blob->microsoftvision) (1.3.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-storage-blob->microsoftvision) (3.1.0)\n","Installing collected packages: PyJWT, cryptography, portalocker, msal, isodate, msrest, msal-extensions, azure-core, azure-storage-blob, azure-identity, microsoftvision\n","Successfully installed PyJWT-2.0.1 azure-core-1.11.0 azure-identity-1.5.0 azure-storage-blob-12.7.1 cryptography-3.4.5 isodate-0.6.0 microsoftvision-1.0.5 msal-1.9.0 msal-extensions-0.3.0 msrest-0.6.21 portalocker-1.7.1\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.6/dist-packages (0.10.3.post1)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.4)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n","Collecting transformers\n","  Downloading transformers-4.3.2-py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 13.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2 MB)\n","\u001b[K     |████████████████████████████████| 3.2 MB 80.1 MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n","\u001b[K     |████████████████████████████████| 883 kB 91.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers) (3.4.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893258 sha256=984a53b0658984811342c39f1dce98011799c2784f444676d071965af94095d1\n","  Stored in directory: /root/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YMjaWJfnLG3K"},"source":["from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from warmup_scheduler import GradualWarmupScheduler  # https://github.com/ildoonet/pytorch-gradual-warmup-lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jm_RywnjLOHM"},"source":["import os, glob, random, time\n","import numpy as np, pandas as pd\n","import matplotlib.pyplot as plt\n","import librosa, librosa.display\n","import soundfile as sf\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from tqdm import tqdm\n","from functools import partial\n","from sklearn import metrics\n","from sklearn.model_selection import StratifiedKFold\n","from transformers import get_linear_schedule_with_warmup\n","from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n","from torchlibrosa.augmentation import SpecAugmentation\n","\n","import timm\n","from timm.models.efficientnet import tf_efficientnet_b0_ns\n","\n","import torchvision.models as models"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1acBwNcbUHRO"},"source":["# MODEL"]},{"cell_type":"code","metadata":{"id":"HWaDnI5lLWRk"},"source":["def init_layer(layer):\n","    nn.init.xavier_uniform_(layer.weight)\n","\n","    if hasattr(layer, \"bias\"):\n","        if layer.bias is not None:\n","            layer.bias.data.fill_(0.)\n","\n","\n","def init_bn(bn):\n","    bn.bias.data.fill_(0.)\n","    bn.weight.data.fill_(1.0)\n","\n","\n","def init_weights(model):\n","    classname = model.__class__.__name__\n","    if classname.find(\"Conv2d\") != -1:\n","        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n","        model.bias.data.fill_(0)\n","    elif classname.find(\"BatchNorm\") != -1:\n","        model.weight.data.normal_(1.0, 0.02)\n","        model.bias.data.fill_(0)\n","    elif classname.find(\"GRU\") != -1:\n","        for weight in model.parameters():\n","            if len(weight.size()) > 1:\n","                nn.init.orghogonal_(weight.data)\n","    elif classname.find(\"Linear\") != -1:\n","        model.weight.data.normal_(0, 0.01)\n","        model.bias.data.zero_()\n","\n","def do_mixup(x: torch.Tensor, mixup_lambda: torch.Tensor):\n","    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes\n","    (1, 3, 5, ...).\n","    Args:\n","      x: (batch_size * 2, ...)\n","      mixup_lambda: (batch_size * 2,)\n","    Returns:\n","      out: (batch_size, ...)\n","    \"\"\"\n","    out = (x[0::2].transpose(0, -1) * mixup_lambda[0::2] +\n","           x[1::2].transpose(0, -1) * mixup_lambda[1::2]).transpose(0, -1)\n","    return out\n","\n","\n","class Mixup(object):\n","    def __init__(self, mixup_alpha, random_seed=1234):\n","        \"\"\"Mixup coefficient generator.\n","        \"\"\"\n","        self.mixup_alpha = mixup_alpha\n","        self.random_state = np.random.RandomState(random_seed)\n","\n","    def get_lambda(self, batch_size):\n","        \"\"\"Get mixup random coefficients.\n","        Args:\n","          batch_size: int\n","        Returns:\n","          mixup_lambdas: (batch_size,)\n","        \"\"\"\n","        mixup_lambdas = []\n","        for n in range(0, batch_size, 2):\n","            lam = self.random_state.beta(self.mixup_alpha, self.mixup_alpha, 1)[0]\n","            mixup_lambdas.append(lam)\n","            mixup_lambdas.append(1. - lam)\n","\n","        return torch.from_numpy(np.array(mixup_lambdas, dtype=np.float32))\n","\n","def interpolate(x: torch.Tensor, ratio: int):\n","    \"\"\"Interpolate data in time domain. This is used to compensate the\n","    resolution reduction in downsampling of a CNN.\n","    Args:\n","      x: (batch_size, time_steps, classes_num)\n","      ratio: int, ratio to interpolate\n","    Returns:\n","      upsampled: (batch_size, time_steps * ratio, classes_num)\n","    \"\"\"\n","    (batch_size, time_steps, classes_num) = x.shape\n","    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n","    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n","    return upsampled\n","\n","\n","def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n","    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n","    is the same as the value of the last frame.\n","    Args:\n","      framewise_output: (batch_size, frames_num, classes_num)\n","      frames_num: int, number of frames to pad\n","    Outputs:\n","      output: (batch_size, frames_num, classes_num)\n","    \"\"\"\n","    pad = framewise_output[:, -1:, :].repeat(\n","        1, frames_num - framewise_output.shape[1], 1)\n","    \"\"\"tensor for padding\"\"\"\n","\n","    output = torch.cat((framewise_output, pad), dim=1)\n","    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n","\n","    return output\n","\n","\n","class ConvBlock(nn.Module):\n","    def __init__(self, in_channels: int, out_channels: int):\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv2d(\n","            in_channels=in_channels,\n","            out_channels=out_channels,\n","            kernel_size=(3, 3),\n","            stride=(1, 1),\n","            padding=(1, 1),\n","            bias=False)\n","\n","        self.conv2 = nn.Conv2d(\n","            in_channels=out_channels,\n","            out_channels=out_channels,\n","            kernel_size=(3, 3),\n","            stride=(1, 1),\n","            padding=(1, 1),\n","            bias=False)\n","\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        self.init_weight()\n","\n","    def init_weight(self):\n","        init_layer(self.conv1)\n","        init_layer(self.conv2)\n","        init_bn(self.bn1)\n","        init_bn(self.bn2)\n","\n","    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n","\n","        x = input\n","        x = F.relu_(self.bn1(self.conv1(x)))\n","        x = F.relu_(self.bn2(self.conv2(x)))\n","        if pool_type == 'max':\n","            x = F.max_pool2d(x, kernel_size=pool_size)\n","        elif pool_type == 'avg':\n","            x = F.avg_pool2d(x, kernel_size=pool_size)\n","        elif pool_type == 'avg+max':\n","            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n","            x2 = F.max_pool2d(x, kernel_size=pool_size)\n","            x = x1 + x2\n","        else:\n","            raise Exception('Incorrect argument!')\n","\n","        return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-EHSs-DMKTj"},"source":["class AttBlock(nn.Module):\n","    def __init__(self,\n","                 in_features: int,\n","                 out_features: int,\n","                 activation=\"linear\",\n","                 temperature=1.0):\n","        super().__init__()\n","\n","        self.activation = activation\n","        self.temperature = temperature\n","        self.att = nn.Conv1d(\n","            in_channels=in_features,\n","            out_channels=out_features,\n","            kernel_size=1,\n","            stride=1,\n","            padding=0,\n","            bias=True)\n","        self.cla = nn.Conv1d(\n","            in_channels=in_features,\n","            out_channels=out_features,\n","            kernel_size=1,\n","            stride=1,\n","            padding=0,\n","            bias=True)\n","\n","        self.bn_att = nn.BatchNorm1d(out_features)\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        init_layer(self.att)\n","        init_layer(self.cla)\n","        init_bn(self.bn_att)\n","\n","    def forward(self, x):\n","        # x: (n_samples, n_in, n_time)\n","        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n","        cla = self.nonlinear_transform(self.cla(x))\n","        x = torch.sum(norm_att * cla, dim=2)\n","        return x, norm_att, cla\n","\n","    def nonlinear_transform(self, x):\n","        if self.activation == 'linear':\n","            return x\n","        elif self.activation == 'sigmoid':\n","            return torch.sigmoid(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YtfebUM03sBv"},"source":["# Create Folds"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"z98Fea2jSkFI","executionInfo":{"elapsed":41085,"status":"ok","timestamp":1613267924203,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"9964a177-7e80-42e0-9c0b-cf8b381b961f"},"source":["train_moto = pd.read_csv(\"/content/drive/My Drive/kaggle/kaggle-bird/mluti_label_train_df.csv\")\n","train_moto"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>recording_id</th>\n","      <th>species_id</th>\n","      <th>songtype_id</th>\n","      <th>t_min</th>\n","      <th>f_min</th>\n","      <th>t_max</th>\n","      <th>f_max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>d49a94504_01</td>\n","      <td>0,18</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>97630c03d_03</td>\n","      <td>0,18,3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>97630c03d_02</td>\n","      <td>0,18,3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>d9bfc9e6b_02</td>\n","      <td>0,1,3,12</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3710abba6_02</td>\n","      <td>0,18</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2423</th>\n","      <td>59a9eb657_02</td>\n","      <td>23,3,12</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>2424</th>\n","      <td>6c032e356_01</td>\n","      <td>23,12</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>2425</th>\n","      <td>006ab765f_05</td>\n","      <td>23,3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>2426</th>\n","      <td>79f38de91_02</td>\n","      <td>23</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>2427</th>\n","      <td>774912d66_03</td>\n","      <td>23,3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2428 rows × 7 columns</p>\n","</div>"],"text/plain":["      recording_id species_id  songtype_id  t_min  f_min  t_max  f_max\n","0     d49a94504_01       0,18            1      0   5000    5.2  10000\n","1     97630c03d_03     0,18,3            1      0   5000    5.2  10000\n","2     97630c03d_02     0,18,3            1      0   5000    5.2  10000\n","3     d9bfc9e6b_02   0,1,3,12            1      0   5000    5.2  10000\n","4     3710abba6_02       0,18            1      0   5000    5.2  10000\n","...            ...        ...          ...    ...    ...    ...    ...\n","2423  59a9eb657_02    23,3,12            1      0   5000    5.2  10000\n","2424  6c032e356_01      23,12            1      0   5000    5.2  10000\n","2425  006ab765f_05       23,3            1      0   5000    5.2  10000\n","2426  79f38de91_02         23            1      0   5000    5.2  10000\n","2427  774912d66_03       23,3            1      0   5000    5.2  10000\n","\n","[2428 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"YpSVN1YgL7Rf"},"source":["FOLDS = 5\n","SEED = 42\n","\n","train = pd.read_csv(\"/content/drive/My Drive/kaggle/kaggle-bird/mluti_label_train_df.csv\")#.sort_values(\"recording_id\")\n","ss = pd.read_csv(\"/content/drive/My Drive/kaggle/kaggle-bird/sample_submission.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"rRN2bqzJMk8u","executionInfo":{"elapsed":40628,"status":"ok","timestamp":1613267924650,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"14a6efc6-3324-4f7e-db60-dfa1f6250d07"},"source":["train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>recording_id</th>\n","      <th>species_id</th>\n","      <th>songtype_id</th>\n","      <th>t_min</th>\n","      <th>f_min</th>\n","      <th>t_max</th>\n","      <th>f_max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>d49a94504_01</td>\n","      <td>0,18</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>97630c03d_03</td>\n","      <td>0,18,3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>97630c03d_02</td>\n","      <td>0,18,3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>d9bfc9e6b_02</td>\n","      <td>0,1,3,12</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3710abba6_02</td>\n","      <td>0,18</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2423</th>\n","      <td>59a9eb657_02</td>\n","      <td>23,3,12</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>2424</th>\n","      <td>6c032e356_01</td>\n","      <td>23,12</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>2425</th>\n","      <td>006ab765f_05</td>\n","      <td>23,3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>2426</th>\n","      <td>79f38de91_02</td>\n","      <td>23</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>2427</th>\n","      <td>774912d66_03</td>\n","      <td>23,3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2428 rows × 7 columns</p>\n","</div>"],"text/plain":["      recording_id species_id  songtype_id  t_min  f_min  t_max  f_max\n","0     d49a94504_01       0,18            1      0   5000    5.2  10000\n","1     97630c03d_03     0,18,3            1      0   5000    5.2  10000\n","2     97630c03d_02     0,18,3            1      0   5000    5.2  10000\n","3     d9bfc9e6b_02   0,1,3,12            1      0   5000    5.2  10000\n","4     3710abba6_02       0,18            1      0   5000    5.2  10000\n","...            ...        ...          ...    ...    ...    ...    ...\n","2423  59a9eb657_02    23,3,12            1      0   5000    5.2  10000\n","2424  6c032e356_01      23,12            1      0   5000    5.2  10000\n","2425  006ab765f_05       23,3            1      0   5000    5.2  10000\n","2426  79f38de91_02         23            1      0   5000    5.2  10000\n","2427  774912d66_03       23,3            1      0   5000    5.2  10000\n","\n","[2428 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"z5nWXHp1MPIi"},"source":["species_id_count = []\n","for i in train['species_id'].to_list():\n","    species_id = i.split(',')\n","    species_id_count.append(np.array(species_id))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hdfLbKtcNLg3","executionInfo":{"elapsed":40259,"status":"ok","timestamp":1613267924653,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"39b3c6fa-97c0-485d-8ca0-173cca8e7675"},"source":["species_id_all = np.concatenate(np.array(species_id_count), axis=0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PeHYn_RxPQjy"},"source":["species_id_all_df = pd.DataFrame(species_id_all)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WVeT65kWN8Kk","executionInfo":{"elapsed":39912,"status":"ok","timestamp":1613267924654,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"ba439843-b964-4807-ec2b-4849fc8a326d"},"source":["species_id_all_df.value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3     1257\n","12     520\n","18     512\n","7      357\n","1      314\n","23     260\n","11     249\n","21     243\n","15     235\n","4      204\n","8      164\n","0      157\n","20     133\n","2      129\n","22     126\n","14     125\n","10     120\n","5      118\n","19     110\n","9      109\n","13     107\n","16     100\n","17     100\n","6       97\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0WQgSJ9_UmjO","executionInfo":{"elapsed":39725,"status":"ok","timestamp":1613267924654,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"ee26bd44-b7dc-4f48-c026-8b188feeabe5"},"source":["species_id_all_df.value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3     1257\n","12     520\n","18     512\n","7      357\n","1      314\n","23     260\n","11     249\n","21     243\n","15     235\n","4      204\n","8      164\n","0      157\n","20     133\n","2      129\n","22     126\n","14     125\n","10     120\n","5      118\n","19     110\n","9      109\n","13     107\n","16     100\n","17     100\n","6       97\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"aVllVog3UPb8"},"source":["all_labels = []\n","for index,row in train.iterrows():\n","  species_ids = row['species_id'].split(',')\n","  label = np.zeros(24, dtype=np.int64)\n","  for i in species_ids:\n","    i = int(i)\n","    label[i] = 1\n","  # label = np.append(label,row['recording_id'])\n","  all_labels.append(label)\n","  # print(row['recording_id'])\n","  # print(label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WQMXmHYhkVIv"},"source":["new_y = np.array(all_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Dx009DwkxJO","executionInfo":{"elapsed":39490,"status":"ok","timestamp":1613267924948,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"8433e3a8-5410-4a2f-c3a3-d53f4601f9ab"},"source":["new_y"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 0, 0, ..., 0, 0, 0],\n","       [1, 0, 0, ..., 0, 0, 0],\n","       [1, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 1],\n","       [0, 0, 0, ..., 0, 0, 1],\n","       [0, 0, 0, ..., 0, 0, 1]])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"5cvqZ1qVlFY1"},"source":["# new_X = np.array(train['recording_id'])\n","new_X = np.array(train.index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W4doghbMn7iB","executionInfo":{"elapsed":39131,"status":"ok","timestamp":1613267924949,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"664d45bd-41b9-4b90-f9fa-003de7e4626d"},"source":["new_X"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   0,    1,    2, ..., 2425, 2426, 2427])"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"TQxc63FtlYn0"},"source":["# !pip install iterative-stratification"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LyRtiWNLlgs3","executionInfo":{"elapsed":42161,"status":"ok","timestamp":1613267928341,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"49a641bf-4b59-4b7b-a84d-c23f587ef9ee"},"source":["#get data\n","train['kfold'] = np.nan\n","\n","#split data\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","mskf = MultilabelStratifiedKFold(n_splits=FOLDS, random_state=SEED)\n","for i, (_, test_index) in enumerate(mskf.split(new_X, new_y)):\n","    train.iloc[test_index, -1] = i\n","    \n","train['kfold'] = train['kfold'].astype('int')\n","\n","train.to_csv(\"train_all.csv\", index=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n","  FutureWarning\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"Va25uZaHljKo","executionInfo":{"elapsed":41962,"status":"ok","timestamp":1613267928342,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"158f543e-f879-4a66-84cf-87db496e6680"},"source":["train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>recording_id</th>\n","      <th>species_id</th>\n","      <th>songtype_id</th>\n","      <th>t_min</th>\n","      <th>f_min</th>\n","      <th>t_max</th>\n","      <th>f_max</th>\n","      <th>kfold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>d49a94504_01</td>\n","      <td>0,18</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>97630c03d_03</td>\n","      <td>0,18,3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>97630c03d_02</td>\n","      <td>0,18,3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>d9bfc9e6b_02</td>\n","      <td>0,1,3,12</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3710abba6_02</td>\n","      <td>0,18</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2423</th>\n","      <td>59a9eb657_02</td>\n","      <td>23,3,12</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2424</th>\n","      <td>6c032e356_01</td>\n","      <td>23,12</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2425</th>\n","      <td>006ab765f_05</td>\n","      <td>23,3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2426</th>\n","      <td>79f38de91_02</td>\n","      <td>23</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2427</th>\n","      <td>774912d66_03</td>\n","      <td>23,3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5000</td>\n","      <td>5.2</td>\n","      <td>10000</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2428 rows × 8 columns</p>\n","</div>"],"text/plain":["      recording_id species_id  songtype_id  t_min  f_min  t_max  f_max  kfold\n","0     d49a94504_01       0,18            1      0   5000    5.2  10000      2\n","1     97630c03d_03     0,18,3            1      0   5000    5.2  10000      1\n","2     97630c03d_02     0,18,3            1      0   5000    5.2  10000      2\n","3     d9bfc9e6b_02   0,1,3,12            1      0   5000    5.2  10000      1\n","4     3710abba6_02       0,18            1      0   5000    5.2  10000      2\n","...            ...        ...          ...    ...    ...    ...    ...    ...\n","2423  59a9eb657_02    23,3,12            1      0   5000    5.2  10000      3\n","2424  6c032e356_01      23,12            1      0   5000    5.2  10000      4\n","2425  006ab765f_05       23,3            1      0   5000    5.2  10000      0\n","2426  79f38de91_02         23            1      0   5000    5.2  10000      4\n","2427  774912d66_03       23,3            1      0   5000    5.2  10000      3\n","\n","[2428 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"OZZfJPN-oXgI"},"source":["train_fold = train[train['kfold']==2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ydbjvvtuljXa"},"source":["species_id_count = []\n","for i in train_fold['species_id'].to_list():\n","    species_id = i.split(',')\n","    species_id_count.append(np.array(species_id))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XSrklr6zoG_a","executionInfo":{"elapsed":41260,"status":"ok","timestamp":1613267928344,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"83f3e94c-7038-46a5-ca95-757ca0094581"},"source":["species_id_all = np.concatenate(np.array(species_id_count), axis=0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"OTyDZAp0oRSI"},"source":["species_id_all_df = pd.DataFrame(species_id_all)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPOnTdE_oylF","executionInfo":{"elapsed":39956,"status":"ok","timestamp":1613267928345,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"112ca4af-16dd-4499-ebc1-2510e28c6f89"},"source":["#fold2 #確認\n","species_id_all_df.value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3     251\n","12    104\n","18    102\n","7      72\n","1      63\n","23     52\n","11     50\n","21     48\n","15     47\n","4      41\n","8      33\n","0      31\n","20     27\n","2      26\n","22     25\n","14     25\n","10     24\n","5      24\n","9      22\n","13     22\n","19     22\n","16     20\n","17     20\n","6      19\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"e1gVKz8QpdTN"},"source":["import microsoftvision\n","from torchvision import transforms\n","import torch\n","from PIL import Image\n","\n","def get_image():\n","    img = cv2.imread('example.jpg', cv2.IMREAD_COLOR)\n","    img = cv2.resize(img, (256, 256))\n","    img = img[16:256-16, 16:256-16]\n","    preprocess = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ])\n","    return preprocess(image).unsqueeze(0) # Unsqueeze only required when there's 1 image in images batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UNqfP8SVC7i_"},"source":["class PANNsDense161Att(nn.Module):\n","    def __init__(self, sample_rate: int, window_size: int, hop_size: int,\n","                 mel_bins: int, fmin: int, fmax: int, classes_num: int, apply_aug: bool, top_db=None):\n","        super().__init__()\n","        \n","        window = 'hann'\n","        center = True\n","        pad_mode = 'reflect'\n","        ref = 1.0\n","        amin = 1e-10\n","        self.interpolate_ratio = 30  # Downsampled ratio\n","        self.apply_aug = apply_aug\n","\n","        # Spectrogram extractor\n","        self.spectrogram_extractor = Spectrogram(\n","            n_fft=window_size,\n","            hop_length=hop_size,\n","            win_length=window_size,\n","            window=window,\n","            center=center,\n","            pad_mode=pad_mode,\n","            freeze_parameters=True)\n","\n","        # Logmel feature extractor\n","        self.logmel_extractor = LogmelFilterBank(\n","            sr=sample_rate,\n","            n_fft=window_size,\n","            n_mels=mel_bins,\n","            fmin=fmin,\n","            fmax=fmax,\n","            ref=ref,\n","            amin=amin,\n","            top_db=top_db,\n","            freeze_parameters=True)\n","\n","        # Spec augmenter\n","        self.spec_augmenter = SpecAugmentation(\n","            time_drop_width=64,\n","            time_stripes_num=2,\n","            freq_drop_width=8,\n","            freq_stripes_num=2)\n","\n","        self.bn0 = nn.BatchNorm2d(mel_bins)\n","\n","        self.fc1 = nn.Linear(2048,1024, bias=True)#<======2208,1024,512=0.943\n","        self.att_block = AttBlock(1024, classes_num, activation='linear')#<===========sigmoid\n","\n","        self.init_weight()\n","\n","        # self.densenet_features = models.densenet161(pretrained=True).features\n","        # This will load pretrained model\n","        self.model = microsoftvision.models.resnet50(pretrained=True)\n","        self.densenet_features = nn.Sequential(*list(self.model.children())[:-1])\n","\n","    def init_weight(self):\n","        init_bn(self.bn0)\n","        init_layer(self.fc1)\n","        \n","    def cnn_feature_extractor(self, x):\n","        x = self.densenet_features(x)\n","        return x\n","    \n","    def preprocess(self, input_x, mixup_lambda=None):\n","\n","        x = self.spectrogram_extractor(input_x)  # (batch_size, 1, time_steps, freq_bins)\n","        x = self.logmel_extractor(x)  # (batch_size, 1, time_steps, mel_bins)\n","\n","        frames_num = x.shape[2]\n","\n","        x = x.transpose(1, 3)\n","        x = self.bn0(x)\n","        x = x.transpose(1, 3)\n","\n","        if self.training and self.apply_aug:\n","            x = self.spec_augmenter(x)\n","\n","        # Mixup on spectrogram\n","        if self.training  and self.apply_aug and mixup_lambda is not None:\n","            x = do_mixup(x, mixup_lambda)\n","        return x, frames_num\n","        \n","\n","    def forward(self, input_data):\n","        x = self.spectrogram_extractor(input_data)\n","        # batch_size x 1 x time_steps x freq_bins\n","        x = self.logmel_extractor(x)\n","        # batch_size x 1 x time_steps x mel_bins\n","        frames_num = x.shape[2]\n","\n","        x = x.transpose(1, 3)\n","        x = self.bn0(x)\n","        x = x.transpose(1, 3)\n","        \n","        # Output shape (batch size, channels, time, frequency)\n","        x = x.expand(x.shape[0], 3, x.shape[2], x.shape[3])\n","        x = self.cnn_feature_extractor(x)\n","        x = torch.mean(x, dim=3)\n","\n","        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n","        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n","        x = x1 + x2\n","\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = x.transpose(1, 2)\n","        x = F.relu_(self.fc1(x))\n","        x = x.transpose(1, 2)\n","        x = F.dropout(x, p=0.5, training=self.training)\n","\n","        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n","        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n","        segmentwise_output = segmentwise_output.transpose(1, 2)\n","\n","        # Get framewise output\n","        framewise_output = interpolate(segmentwise_output,\n","                                       self.interpolate_ratio)\n","        framewise_output = pad_framewise_output(framewise_output, frames_num)\n","\n","        output_dict = {\n","            'framewise_output' : framewise_output,\n","            'logit' : logit,\n","            'clipwise_output' : clipwise_output\n","        }\n","\n","        return output_dict\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vv2UzSYD4DZ3"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"id":"g0eHe34Z4KDm"},"source":["def crop_or_pad(y, sr, period, record, mode=\"train\"):\n","    len_y = len(y)\n","    effective_length = sr * period\n","    rint = np.random.randint(len(record['t_min']))\n","    time_start = record['t_min'][rint] * sr\n","    time_end = record['t_max'][rint] * sr\n","    if len_y > effective_length:\n","        # Positioning sound slice\n","        center = np.round((time_start + time_end) / 2)\n","        beginning = center - effective_length / 2\n","        if beginning < 0:\n","            beginning = 0\n","        beginning = np.random.randint(beginning, center)\n","        ending = beginning + effective_length\n","        if ending > len_y:\n","            ending = len_y\n","        beginning = ending - effective_length\n","        y = y[beginning:ending].astype(np.float32)\n","    else:\n","        y = y.astype(np.float32)\n","        beginning = 0\n","        ending = effective_length\n","\n","\n","    beginning_time = beginning / sr\n","    ending_time = ending / sr\n","    label = np.zeros(24, dtype='f')\n","\n","    for i in range(len(record['t_min'])):\n","        if (record['t_min'][i] <= ending_time) and (record['t_max'][i] >= beginning_time):\n","            label[record['species_id'][i]] = 1\n","    \n","    return y, label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YrT_h8Mk4LT7"},"source":["class SedDataset:\n","    def __init__(self, df, period=5, stride=5, audio_transform=None, data_path=\"train\", mode=\"train\"):\n","\n","        self.period = period\n","        self.stride = stride\n","        self.audio_transform = audio_transform\n","        self.data_path = data_path\n","        self.mode = mode\n","\n","        self.df = df.groupby(\"recording_id\").agg(lambda x: list(x)).reset_index()\n","\n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, idx):\n","        record = self.df.iloc[idx]\n","\n","        y, sr = sf.read(f\"{self.data_path}/{record['recording_id']}.wav\")#flac\n","        \n","        if self.mode != \"test\":\n","            effective_length = self.period * sr\n","            y = y[0:effective_length].astype(np.float32)\n","            label = np.zeros(24, dtype='f')\n","\n","            # y, label = crop_or_pad(y, sr, period=self.period, record=record, mode=self.mode)\n","\n","            if self.audio_transform:\n","                y = self.audio_transform(samples=y, sample_rate=sr)\n","            species_ids = record['species_id'][0].split(',') \n","            for i in species_ids:\n","                i = int(i)\n","                label[i] = 1\n","\n","        else:#<=====test\n","            y_ = []\n","            i = 0\n","            #sr = 48000\n","            #period = 10s\n","            effective_length = self.period * sr\n","            #effective_length 480000\n","            stride = self.stride * sr#self.stride = 5sづつ10sがスライドする\n","            #stride 240000\n","            y = np.stack([y[i:i+effective_length].astype(np.float32) for i in range(0, 60*sr+stride-effective_length, stride)])#range(0,60*48000+240000-480000,240000)\n","            # print(y.shape)\n","      \n","            #いらない\n","            label = np.zeros(24, dtype='f')\n","            if self.mode == \"valid\":\n","                species_ids = record['species_id'][0].split(',') \n","                for i in species_ids:\n","                    i = int(i)\n","                    label[i] = 1\n","\n","        return {\n","            \"image\" : y,\n","            \"target\" : label,\n","            \"id\" : record['recording_id']\n","        }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"61oXdE004Mjz"},"source":["# Augmentations"]},{"cell_type":"code","metadata":{"id":"bOtYeZqz4Pft"},"source":["import audiomentations as AA\n","\n","train_audio_transform = AA.Compose([\n","    AA.AddGaussianNoise(p=0.5),\n","    AA.AddGaussianSNR(p=0.5),\n","    #AA.AddBackgroundNoise(\"../input/train_audio/\", p=1)\n","    #AA.AddImpulseResponse(p=0.1),\n","    #AA.AddShortNoises(\"../input/train_audio/\", p=1)\n","    AA.FrequencyMask(min_frequency_band=0.0,  max_frequency_band=0.2, p=0.3),\n","    AA.TimeMask(min_band_part=0.0, max_band_part=0.2, p=0.8),\n","    AA.PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.1),\n","    AA.Shift(p=0.1),\n","    #AA.Normalize(p=0.1),\n","    #AA.ClippingDistortion(min_percentile_threshold=0, max_percentile_threshold=1, p=0.05),\n","    #AA.PolarityInversion(p=0.05),\n","    AA.Gain(p=0.2)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"grNO2a0z4QsK"},"source":["# Utils"]},{"cell_type":"code","metadata":{"id":"qOMYrNXd4Twx"},"source":["def _lwlrap_sklearn(truth, scores):\n","    \"\"\"Reference implementation from https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8\"\"\"\n","    sample_weight = np.sum(truth > 0, axis=1)\n","    nonzero_weight_sample_indices = np.flatnonzero(sample_weight > 0)\n","    overall_lwlrap = metrics.label_ranking_average_precision_score(\n","        truth[nonzero_weight_sample_indices, :] > 0, \n","        scores[nonzero_weight_sample_indices, :], \n","        sample_weight=sample_weight[nonzero_weight_sample_indices])\n","    return overall_lwlrap\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","class MetricMeter(object):\n","    def __init__(self):\n","        self.reset()\n","    \n","    def reset(self):\n","        self.y_true = []\n","        self.y_pred = []\n","    \n","    def update(self, y_true, y_pred):\n","        self.y_true.extend(y_true.cpu().detach().numpy().tolist())\n","        self.y_pred.extend(y_pred.cpu().detach().numpy().tolist())\n","\n","    @property\n","    def avg(self):\n","        #score_class, weight = lwlrap(np.array(self.y_true), np.array(self.y_pred))\n","        self.score = _lwlrap_sklearn(np.array(self.y_true), np.array(self.y_pred)) #(score_class * weight).sum()\n","        return {\n","            \"lwlrap\" : self.score\n","        }\n","\n","def seed_everithing(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HT5q876N4U3J"},"source":["# Losses"]},{"cell_type":"code","metadata":{"id":"AR0vNV3T4W9U"},"source":["from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n","\n","class PANNsLoss(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        # self.bce = nn.BCELoss()\n","        self.bce = nn.BCEWithLogitsLoss(pos_weight = pos_weight)#pos_weight = pos_weight\n","\n","    def forward(self, input, target):\n","        # input_ = input[\"framewise_output\"]\n","        input_ = input[\"logit\"]\n","        input_ = torch.where(torch.isnan(input_),\n","                             torch.zeros_like(input_),\n","                             input_)\n","        input_ = torch.where(torch.isinf(input_),\n","                             torch.zeros_like(input_),\n","                             input_)\n","\n","        target = target.float()\n","\n","        return self.bce(input_, target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mdtpJ9sKyTjL"},"source":["class ImprovedPANNsLoss(nn.Module):\n","    def __init__(self, output_key=\"logit\", weights=[1, 0.5]):\n","        super().__init__()\n","\n","        self.output_key = output_key\n","        if output_key == \"logit\":\n","            self.normal_loss = nn.BCEWithLogitsLoss()\n","        else:\n","            self.normal_loss = nn.BCELoss()\n","\n","        self.bce = nn.BCELoss()\n","        self.weights = weights\n","\n","    def forward(self, input, target):\n","        input_ = input[self.output_key]\n","        target = target.float()#torch.Size([16, 24])\n","\n","        framewise_output = input[\"framewise_output\"]\n","        clipwise_output_with_max, _ = framewise_output.max(dim=1)#torch.Size([16, 24])\n","        normal_loss = self.normal_loss(input_, target)\n","        # print('normal_loss',normal_loss)\n","\n","\n","        # clipwise_output_with_max = torch.where(torch.isnan(clipwise_output_with_max),\n","        #                      torch.zeros_like(clipwise_output_with_max),\n","        #                      clipwise_output_with_max)\n","        # clipwise_output_with_max = torch.where(torch.isinf(clipwise_output_with_max),\n","        #                      torch.zeros_like(clipwise_output_with_max),\n","        #                      clipwise_output_with_max)\n","        # target = target.float()\n","\n","        # auxiliary_loss = self.bce(clipwise_output_with_max, target)\n","        # print('auxiliary_loss',auxiliary_loss)\n","        return normal_loss #self.weights[0] * normal_loss + self.weights[1] * auxiliary_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B-9B5Sz-VKl-"},"source":["class FocalLoss(nn.Module):\n","  def __init__(self):\n","        super().__init__()\n","        # self.bce = nn.BCEWithLogitsLoss()\n","        self.alpha = 0.25\n","        self.gamma = 2.5\n","\n","  def forward(self, input, target): \n","    # preds = input[\"logit\"]#<====================\n","    preds = input[\"framewise_output\"]\n","    preds,_ = preds.max(dim=1)#torch.Size([16, 24])\n","    \n","\n","    # preds = torch.where(torch.isnan(preds),\n","    #                          torch.zeros_like(preds),\n","    #                          preds)\n","    # preds = torch.where(torch.isinf(preds),\n","    #                          torch.zeros_like(preds),\n","    #                          preds)\n","\n","\n","    \n","\n","    targets = target.float()#torch.Size([16, 24])\n","\n","    loss_fct = nn.BCEWithLogitsLoss(reduction='none')\n","    bce_loss = loss_fct(preds, targets)\n","    probas = torch.sigmoid(preds)\n","    loss = torch.where(targets >= 0.5, self.alpha * (1. - probas)**self.gamma * bce_loss, probas**self.gamma * bce_loss)\n","    loss = loss.mean()\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-VbWM0y_s4in"},"source":["class FocalLoss_(nn.Module):\n","    def __init__(self, gamma=2):\n","        super().__init__()\n","        self.gamma = gamma\n","\n","    def forward(self, input, target):\n","        ############\n","        input = input[\"framewise_output\"]\n","        input,_ = input.max(dim=1)#torch.Size([16, 24])\n","        ############\n","        if not (target.size() == input.size()):\n","            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n","                             .format(target.size(), input.size()))\n","\n","        max_val = (-input).clamp(min=0)\n","        loss = input - input * target + max_val + \\\n","               ((-max_val).exp() + (-input - max_val).exp()).log()\n","\n","        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n","        loss = (invprobs * self.gamma).exp() * loss\n","\n","        return loss.sum(dim=1).mean()\n","    \n","class FbetaLoss(nn.Module):\n","    def __init__(self, beta=1):\n","        super(FbetaLoss, self).__init__()\n","        self.small_value = 1e-6\n","        self.beta = beta\n","\n","    def forward(self, logits, labels):\n","        beta = self.beta\n","        ############\n","        logits = logits[\"framewise_output\"]\n","        logits,_ = logits.max(dim=1)#torch.Size([16, 24])\n","        ############\n","        batch_size = logits.size()[0]\n","        p = F.sigmoid(logits)\n","        l = labels\n","        num_pos = torch.sum(p, 1) + self.small_value\n","        num_pos_hat = torch.sum(l, 1) + self.small_value\n","        tp = torch.sum(l * p, 1)\n","        precise = tp / num_pos\n","        recall = tp / num_pos_hat\n","        fs = (1 + beta * beta) * precise * recall / (beta * beta * precise + recall + self.small_value)\n","        loss = fs.sum() / batch_size\n","        return 1 - loss\n","\n","class CombineLoss(nn.Module):\n","    def __init__(self):\n","        super(CombineLoss, self).__init__()\n","        self.fbeta_loss = FbetaLoss(beta=2)\n","        self.focal_loss = FocalLoss_()\n","        \n","    def forward(self, logits, labels):\n","        loss_beta = self.fbeta_loss(logits, labels)\n","        loss_focal = self.focal_loss(logits, labels)\n","        return 0.5 * loss_beta + 0.5 * loss_focal"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2apkqcLubSJq","executionInfo":{"elapsed":1210,"status":"ok","timestamp":1613268077530,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"fb8f9516-60b9-494f-822a-86aa71b7dcbe"},"source":["!git clone https://github.com/wutong16/DistributionBalancedLoss.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'DistributionBalancedLoss' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PWo6ikEcbo2l","executionInfo":{"elapsed":8959,"status":"ok","timestamp":1613268085871,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"7be2b2aa-092b-4b7a-824a-0bfeefb031b2"},"source":["!pip install mmcv"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting mmcv\n","  Downloading mmcv-1.2.6.tar.gz (226 kB)\n","\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 42.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 46.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 30 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 40 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 51 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 61 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 71 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 81 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 102 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 112 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 122 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 133 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 143 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 153 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 163 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 174 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 184 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 194 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 204 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 215 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 225 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 226 kB 12.8 MB/s \n","\u001b[?25hCollecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mmcv) (1.19.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from mmcv) (7.0.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mmcv) (3.13)\n","Collecting yapf\n","  Downloading yapf-0.30.0-py2.py3-none-any.whl (190 kB)\n","\u001b[K     |████████████████████████████████| 190 kB 21.9 MB/s \n","\u001b[?25hBuilding wheels for collected packages: mmcv\n","  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mmcv: filename=mmcv-1.2.6-py2.py3-none-any.whl size=330823 sha256=62a1ad8e07e782cae6cf2e124e6c5de87fb92a5ff1898e4a0e55088edf2faa68\n","  Stored in directory: /root/.cache/pip/wheels/87/f0/65/3e1050b7be0dceb5892edaa279aeaab83a8c11de67e857ca16\n","Successfully built mmcv\n","Installing collected packages: yapf, addict, mmcv\n","Successfully installed addict-2.4.0 mmcv-1.2.6 yapf-0.30.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eDugX-_bcbme"},"source":["# from DistributionBalancedLoss import*"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Mz1zj3NeGq6"},"source":["# import sys\n","# sys.path.insert(0, \"DistributionBalancedLoss\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qoY2-qRqdfhj"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import mmcv\n","# from .utils import weight_reduce_loss\n","# from ..registry import LOSSES\n","# from .cross_entropy_loss import cross_entropy, _expand_binary_labels, binary_cross_entropy, partial_cross_entropy\n","import numpy as np\n","import time\n","import matplotlib.pyplot as plt\n","from torch.nn import Parameter\n","from sklearn.manifold import TSNE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1TFUqKJobp9a"},"source":["# ResampleLoss"]},{"cell_type":"code","metadata":{"id":"fEulynxmbEhs"},"source":["import functools\n","\n","import torch.nn.functional as F\n","\n","\n","def reduce_loss(loss, reduction):\n","    \"\"\"Reduce loss as specified.\n","    Args:\n","        loss (Tensor): Elementwise loss tensor.\n","        reduction (str): Options are \"none\", \"mean\" and \"sum\".\n","    Return:\n","        Tensor: Reduced loss tensor.\n","    \"\"\"\n","    reduction_enum = F._Reduction.get_enum(reduction)\n","    # none: 0, elementwise_mean:1, sum: 2\n","    if reduction_enum == 0:\n","        return loss\n","    elif reduction_enum == 1:\n","        return loss.mean()\n","    elif reduction_enum == 2:\n","        return loss.sum()\n","\n","\n","def weight_reduce_loss(loss, weight=None, reduction='mean', avg_factor=None):\n","    \"\"\"Apply element-wise weight and reduce loss.\n","    Args:\n","        loss (Tensor): Element-wise loss.\n","        weight (Tensor): Element-wise weights.\n","        reduction (str): Same as built-in losses of PyTorch.\n","        avg_factor (float): Avarage factor when computing the mean of losses.\n","    Returns:\n","        Tensor: Processed loss values.\n","    \"\"\"\n","    # if weight is specified, apply element-wise weight\n","    if weight is not None:\n","        loss = loss * weight\n","\n","    # if avg_factor is not specified, just reduce the loss\n","    if avg_factor is None:\n","        loss = reduce_loss(loss, reduction)\n","    else:\n","        # if reduction is mean, then average the loss by avg_factor\n","        if reduction == 'mean':\n","            loss = loss.sum() / avg_factor\n","        # if reduction is 'none', then do nothing, otherwise raise an error\n","        elif reduction != 'none':\n","            raise ValueError('avg_factor can not be used with reduction=\"sum\"')\n","    return loss\n","\n","\n","def weighted_loss(loss_func):\n","    \"\"\"Create a weighted version of a given loss function.\n","    To use this decorator, the loss function must have the signature like\n","    `loss_func(pred, target, **kwargs)`. The function only needs to compute\n","    element-wise loss without any reduction. This decorator will add weight\n","    and reduction arguments to the function. The decorated function will have\n","    the signature like `loss_func(pred, target, weight=None, reduction='mean',\n","    avg_factor=None, **kwargs)`.\n","    :Example:\n","    >>> @weighted_loss\n","    >>> def l1_loss(pred, target):\n","    >>>     return (pred - target).abs()\n","    >>> pred = torch.Tensor([0, 2, 3])\n","    >>> target = torch.Tensor([1, 1, 1])\n","    >>> weight = torch.Tensor([1, 0, 1])\n","    >>> l1_loss(pred, target)\n","    tensor(1.3333)\n","    >>> l1_loss(pred, target, weight)\n","    tensor(1.)\n","    >>> l1_loss(pred, target, reduction='none')\n","    tensor([1., 1., 2.])\n","    >>> l1_loss(pred, target, weight, avg_factor=2)\n","    tensor(1.5000)\n","    \"\"\"\n","\n","    @functools.wraps(loss_func)\n","    def wrapper(pred,\n","                target,\n","                weight=None,\n","                reduction='mean',\n","                avg_factor=None,\n","                **kwargs):\n","        # get element-wise loss\n","        loss = loss_func(pred, target, **kwargs)\n","        loss = weight_reduce_loss(loss, weight, reduction, avg_factor)\n","        return loss\n","\n","    return wrapper\n","\n","\n","\n","def binary_cross_entropy(pred,\n","                         label,\n","                         weight=None,\n","                         reduction='mean',\n","                         avg_factor=None):\n","    if pred.dim() != label.dim():\n","        label, weight = _expand_binary_labels(label, weight, pred.size(-1))\n","\n","    # weighted element-wise losses\n","    if weight is not None:\n","        weight = weight.float()\n","\n","    loss = F.binary_cross_entropy_with_logits(\n","        pred, label.float(), weight, reduction='none')\n","    loss = weight_reduce_loss(loss, reduction=reduction, avg_factor=avg_factor)\n","\n","    return loss\n","\n","# @LOSSES.register_module\n","class ResampleLoss(nn.Module):\n","\n","    def __init__(self,\n","                 use_sigmoid=True,#False\n","                 reduction='mean',\n","                 loss_weight=1.0,\n","                 partial=False,\n","                 focal=dict(\n","                     focal=True,\n","                     balance_param=2.0,\n","                     gamma=2,\n","                 ),\n","                 CB_loss=dict(\n","                     CB_beta=0.9,\n","                     CB_mode='average_w'  # 'by_class', 'average_n', 'average_w', 'min_n'\n","                 ),\n","                 map_param=dict(\n","                     alpha=10.0,\n","                     beta=0.2,\n","                     gamma=0.1\n","                 ),\n","                 logit_reg=dict(\n","                     neg_scale=5.0,\n","                     init_bias=0.1\n","                 ),\n","                 reweight_func='rebalance',  # None, 'inv', 'sqrt_inv', 'rebalance', 'CB'\n","                 weight_norm='by_batch', # None, 'by_instance', 'by_batch'\n","                 freq_file='./class_freq.pkl'):\n","        super(ResampleLoss, self).__init__()\n","\n","        assert (use_sigmoid is True) or (partial is False)\n","        self.use_sigmoid = use_sigmoid\n","        self.partial = partial\n","        self.loss_weight = loss_weight\n","        self.reduction = reduction\n","        if self.use_sigmoid:\n","            if self.partial:\n","                self.cls_criterion = None#partial_cross_entropy\n","            else:\n","                self.cls_criterion = binary_cross_entropy\n","        else:\n","            self.cls_criterion = None#cross_entropy\n","\n","        # reweighting function\n","        self.reweight_func = reweight_func\n","\n","        # normalization (optional)\n","        self.weight_norm = weight_norm\n","\n","        # focal loss params\n","        self.focal = focal['focal']\n","        self.gamma = focal['gamma']\n","        self.balance_param = focal['balance_param']\n","\n","        # mapping function params\n","        self.map_alpha = map_param['alpha']\n","        self.map_beta = map_param['beta']\n","        self.map_gamma = map_param['gamma']\n","\n","        # CB loss params (optional)\n","        self.CB_beta = CB_loss['CB_beta']\n","        self.CB_mode = CB_loss['CB_mode']\n","\n","        self.class_freq = torch.from_numpy(np.asarray(\n","            mmcv.load(freq_file)['class_freq'])).float().cuda()\n","        self.neg_class_freq = torch.from_numpy(\n","            np.asarray(mmcv.load(freq_file)['neg_class_freq'])).float().cuda()\n","        self.num_classes = self.class_freq.shape[0]\n","        self.train_num = self.class_freq[0] + self.neg_class_freq[0]\n","        # regularization params\n","        self.logit_reg = logit_reg\n","        self.neg_scale = logit_reg[\n","            'neg_scale'] if 'neg_scale' in logit_reg else 1.0\n","        init_bias = logit_reg['init_bias'] if 'init_bias' in logit_reg else 0.0\n","        self.init_bias = - torch.log(\n","            self.train_num / self.class_freq - 1) * init_bias / self.neg_scale\n","\n","        self.freq_inv = torch.ones(self.class_freq.shape).cuda() / self.class_freq\n","        self.propotion_inv = self.train_num / self.class_freq\n","\n","        print('\\033[1;35m loading from {} | {} | {} | s\\033[0;0m'.format(freq_file, reweight_func, logit_reg))\n","        print('\\033[1;35m rebalance reweighting mapping params: {:.2f} | {:.2f} | {:.2f} \\033[0;0m'.format(self.map_alpha, self.map_beta, self.map_gamma))\n","        #loading from ./class_freq.pkl | None | {'neg_scale': 5.0, 'init_bias': 0.1} | s\n","        #rebalance reweighting mapping params: 10.00 | 0.20 | 0.10 \n","\n","    def forward(self,\n","                cls_score,\n","                label,\n","                weight=None,\n","                avg_factor=None,\n","                reduction_override=None,\n","                **kwargs):\n","\n","        assert reduction_override in (None, 'none', 'mean', 'sum')\n","        reduction = (\n","            reduction_override if reduction_override else self.reduction)\n","        # print('reduction',reduction)\n","        weight = self.reweight_functions(label)\n","        # print('label.float()',label.float())\n","        # print('cls_score',cls_score)\n","        # print('weight',weight)\n","        # print('=========================')\n","        cls_score, weight = self.logit_reg_functions(label.float(), cls_score, weight)\n","        # print(cls_score)\n","        # print(weight)\n","\n","        if self.focal:#<=======================================================\n","            logpt = - self.cls_criterion(\n","                cls_score.clone(), label, weight=None, reduction='none',\n","                avg_factor=avg_factor)\n","            # pt is sigmoid(logit) for pos or sigmoid(-logit) for neg\n","            pt = torch.exp(logpt)\n","            loss = self.cls_criterion(\n","                cls_score, label.float(), weight=weight, reduction='none')\n","            loss = ((1 - pt) ** self.gamma) * loss\n","            loss = self.balance_param * loss\n","        else:\n","            loss = self.cls_criterion(cls_score, label.float(), weight,\n","                                      reduction=reduction)\n","\n","        loss = self.loss_weight * loss\n","        loss = weight_reduce_loss(loss, weight, reduction, avg_factor)\n","        return loss\n","\n","    def reweight_functions(self, label):\n","        if self.reweight_func is None:\n","            return None\n","        elif self.reweight_func in ['inv', 'sqrt_inv']:\n","            weight = self.RW_weight(label.float())\n","        elif self.reweight_func in 'rebalance':\n","            weight = self.rebalance_weight(label.float())\n","        elif self.reweight_func in 'CB':\n","            weight = self.CB_weight(label.float())\n","        else:\n","            return None\n","\n","        if self.weight_norm is not None:\n","            if 'by_instance' in self.weight_norm:\n","                max_by_instance, _ = torch.max(weight, dim=-1, keepdim=True)\n","                weight = weight / max_by_instance\n","            elif 'by_batch' in self.weight_norm:\n","                weight = weight / torch.max(weight)\n","\n","        return weight\n","\n","    def logit_reg_functions(self, labels, logits, weight=None):\n","        if not self.logit_reg:\n","            return logits, weight\n","        if 'init_bias' in self.logit_reg:\n","            logits += self.init_bias\n","        if 'neg_scale' in self.logit_reg:\n","            logits = logits * (1 - labels) * self.neg_scale  + logits * labels\n","            weight = weight / self.neg_scale * (1 - labels) + weight * labels\n","        return logits, weight\n","\n","    def rebalance_weight(self, gt_labels):\n","        repeat_rate = torch.sum( gt_labels.float() * self.freq_inv, dim=1, keepdim=True)\n","        pos_weight = self.freq_inv.clone().detach().unsqueeze(0) / repeat_rate\n","        # pos and neg are equally treated\n","        weight = torch.sigmoid(self.map_beta * (pos_weight - self.map_gamma)) + self.map_alpha\n","        return weight\n","\n","    def CB_weight(self, gt_labels):\n","        if  'by_class' in self.CB_mode:\n","            weight = torch.tensor((1 - self.CB_beta)).cuda() / \\\n","                     (1 - torch.pow(self.CB_beta, self.class_freq)).cuda()\n","        elif 'average_n' in self.CB_mode:\n","            avg_n = torch.sum(gt_labels * self.class_freq, dim=1, keepdim=True) / \\\n","                    torch.sum(gt_labels, dim=1, keepdim=True)\n","            weight = torch.tensor((1 - self.CB_beta)).cuda() / \\\n","                     (1 - torch.pow(self.CB_beta, avg_n)).cuda()\n","        elif 'average_w' in self.CB_mode:\n","            weight_ = torch.tensor((1 - self.CB_beta)).cuda() / \\\n","                      (1 - torch.pow(self.CB_beta, self.class_freq)).cuda()\n","            weight = torch.sum(gt_labels * weight_, dim=1, keepdim=True) / \\\n","                     torch.sum(gt_labels, dim=1, keepdim=True)\n","        elif 'min_n' in self.CB_mode:\n","            min_n, _ = torch.min(gt_labels * self.class_freq +\n","                                 (1 - gt_labels) * 100000, dim=1, keepdim=True)\n","            weight = torch.tensor((1 - self.CB_beta)).cuda() / \\\n","                     (1 - torch.pow(self.CB_beta, min_n)).cuda()\n","        else:\n","            raise NameError\n","        return weight\n","\n","    def RW_weight(self, gt_labels, by_class=True):\n","        if 'sqrt' in self.reweight_func:\n","            weight = torch.sqrt(self.propotion_inv)\n","        else:\n","            weight = self.propotion_inv\n","        if not by_class:\n","            sum_ = torch.sum(weight * gt_labels, dim=1, keepdim=True)\n","            weight = sum_ / torch.sum(gt_labels, dim=1, keepdim=True)\n","        return weight"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ZgwXwOQ4YE0"},"source":["# Functions"]},{"cell_type":"code","metadata":{"id":"d5otgvWR4Z0C"},"source":["def train_epoch(args, model, loader, criterion, optimizer, scheduler, epoch):\n","    losses = AverageMeter()\n","    scores = MetricMeter()\n","\n","    model.train()\n","    t = tqdm(loader)\n","    for i, sample in enumerate(t):\n","        \n","        optimizer.zero_grad()\n","        input = sample['image'].to(args.device)\n","        target = sample['target'].to(args.device)\n","        output = model(input)\n","        ##################\n","        output = output[\"framewise_output\"]\n","        output,_ = output.max(dim=1)#torch.Size([16, 24])\n","        ##################\n","\n","        loss = criterion(output, target)\n","        # print('loss',loss)\n","        # loss = loss.mean()\n","        loss.backward()\n","        optimizer.step()\n","        if scheduler and args.step_scheduler:\n","            scheduler.step()\n","\n","        bs = input.size(0)\n","        # print(output['logit'].shape)torch.Size([16, 24])\n","        # print(torch.sigmoid(output['logit']))\n","        # scores.update(target, torch.sigmoid(output['logit']))#<=====================\n","        # scores.update(target, torch.sigmoid(torch.max(output['framewise_output'], dim=1)[0]))#<===============#torch.Size([16, 469, 24])\n","        scores.update(target, torch.sigmoid(output))#<===============#torch.Size([16, 469, 24])\n","\n","        losses.update(loss.item(), bs)\n","\n","        t.set_description(f\"Train E:{epoch} - Loss{losses.avg:0.4f}\")\n","    t.close()\n","    return scores.avg, losses.avg\n","        \n","def valid_epoch(args, model, loader, criterion, epoch):\n","    losses = AverageMeter()\n","    scores = MetricMeter()\n","    model.eval()\n","    with torch.no_grad():\n","        t = tqdm(loader)\n","        for i, sample in enumerate(t):\n","            input = sample['image'].to(args.device)\n","            target = sample['target'].to(args.device)\n","            output = model(input)\n","            ##################\n","            output = output[\"framewise_output\"]\n","            output,_ = output.max(dim=1)#torch.Size([16, 24])\n","            ##################\n","            loss = criterion(output, target)\n","\n","            bs = input.size(0)\n","            # scores.update(target, torch.sigmoid(output['logit']))#<=============\n","           # scores.update(target, torch.sigmoid(torch.max(output['framewise_output'], dim=1)[0]))#<===============#torch.Size([16, 469, 24])\n","            scores.update(target, torch.sigmoid(output))#<===============#torch.Size([16, 469, 24])\n","            losses.update(loss.item(), bs)\n","            t.set_description(f\"Valid E:{epoch} - Loss:{losses.avg:0.4f}\")\n","    t.close()\n","    return scores.avg, losses.avg\n","\n","def test_epoch(args, model, loader):\n","    model.eval()\n","    pred_list = []\n","    id_list = []\n","    with torch.no_grad():\n","        t = tqdm(loader)\n","        for i, sample in enumerate(t):\n","            input = sample[\"image\"].to(args.device)#torch.Size([16, 11, 480000])\n","\n","            bs, seq, w = input.shape#seq,11画像あるようなもの\n","            input = input.reshape(bs*seq, w)#torch.Size([176, 480000])#176画像をまとめてpredしているようなもの\n","\n","            id = sample[\"id\"]\n","            output = model(input)\n","            \n","            #output['framewise_output']:torch.Size([176, 938, 24])\n","            # print(torch.sigmoid(output['logit']).shape)#torch.Size([192, 24])\n","            # output = torch.sigmoid(output['logit'])#<======================\n","            output = torch.sigmoid(torch.max(output['framewise_output'], dim=1)[0])#torch.Size([176, 24])\n","\n","\n","            output = output.reshape(bs, seq, -1)#torch.Size([16, 11, 24])\n","            \n","            # output = torch.sum(output, dim=1)#torch.Size([16, 24])#<=================\n","            output, _ = torch.max(output, dim=1)#<=================\n","            output = output.cpu().detach().numpy().tolist()\n","            pred_list.extend(output)\n","            id_list.extend(id)\n","    \n","    return pred_list, id_list"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"346ju4g2VqXb"},"source":["# Scheduler"]},{"cell_type":"code","metadata":{"id":"vRZzGE7n4bH_"},"source":["# Fix Warmup Bug\n","class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n","    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n","        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n","    def get_lr(self):\n","        if self.last_epoch > self.total_epoch:\n","            if self.after_scheduler:\n","                if not self.finished:\n","                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n","                    self.finished = True\n","                return self.after_scheduler.get_lr()\n","            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n","        if self.multiplier == 1.0:\n","            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n","        else:\n","            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5ZDarx7PnA_1"},"source":["# Config"]},{"cell_type":"code","metadata":{"id":"PhEqJeg3nC1H"},"source":["class args:\n","    DEBUG = False\n","\n","    exp_name = \"bird_mluti_ResNet50_5F_BASE_head1024_framewides_ResampleLoss_2048_512_256_addmask0202_earystop35_batch\"\n","    pretrain_weights = None \n","\n","    model_param = {\n","        'sample_rate': 48000,\n","        'window_size' : 2048, #512, #* 2, # 512 * 2\n","        'hop_size' : 512,#345 * 2, # 320\n","        'mel_bins' : 256, # 60\n","        'fmin' : 0,\n","        'fmax' : 48000 // 2,\n","        'classes_num' : 24,\n","        'apply_aug' : True,\n","    }\n","    period = 5#<==========================\n","    seed = 42\n","    start_epcoh = 0 \n","#     epochs = 50\n","    ################\n","    freeze_epo = 0\n","    warmup_epo = 3\n","    cosine_epo = 46\n","    epochs = freeze_epo + warmup_epo + cosine_epo\n","    ################\n","    lr = 1e-4\n","    batch_size = 16\n","    num_workers = 4\n","    early_stop = 30\n","    step_scheduler = False#True\n","    epoch_scheduler = True#False\n","\n","    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n","    train_csv = \"train_all.csv\"\n","    test_csv = \"test_df.csv\"\n","    sub_csv = \"/content/drive/My Drive/kaggle/kaggle-bird/sample_submission.csv\"\n","    output_dir = \"weights\"\n","    train_data_path = \"/content/drive/My Drive/kaggle/kaggle-bird/train_split12_wav\"\n","    test_data_path = \"/content/drive/My Drive/kaggle/kaggle-bird/test_wav\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vc4IXrr04fEP"},"source":["def main(fold):\n","    seed_everithing(args.seed)\n","\n","    args.fold = fold\n","    args.save_path = os.path.join(args.output_dir, args.exp_name)\n","    os.makedirs(args.save_path, exist_ok=True)\n","\n","    train_df = pd.read_csv(args.train_csv)\n","    sub_df = pd.read_csv(args.sub_csv)\n","    if args.DEBUG:\n","        train_df = train_df.sample(200)\n","    train_fold = train_df[train_df.kfold != fold]\n","    print(train_fold)\n","    print(len(train_fold))\n","    valid_fold = train_df[train_df.kfold == fold]\n","\n","    #########################################\n","    species_id_count_ = []\n","    for i in train_fold['species_id'].to_list():\n","        species_id = i.split(',')\n","        species_id_count_.append(np.array(species_id))\n","\n","\n","    species_id_all_ = np.concatenate(np.array(species_id_count_), axis=0)\n","    species_id_all_df_ = pd.DataFrame(species_id_all_)\n","    species_id_all_df_[0] = species_id_all_df_[0].astype('int64')\n","    samples_per_cls_tra = list(np.concatenate(np.array(species_id_all_df_.apply(species_id_all_df_.value_counts).sort_index())))\n","    print(samples_per_cls_tra)\n","    neg_counts = [len(train_fold)-pos_count for pos_count in samples_per_cls_tra]\n","    print(neg_counts)\n","    arr_pog = samples_per_cls_tra\n","    arr_neg = neg_counts.copy()\n","\n","    frec_dict = {}\n","    frec_dict[\"class_freq\"] = arr_pog\n","    frec_dict[\"neg_class_freq\"] = arr_neg\n","\n","\n","    with open(\"class_freq.pkl\", \"wb\") as f:\n","        pickle.dump(frec_dict, f) #保存\n","    print(frec_dict)\n","    #########################################\n","\n","    train_dataset = SedDataset(\n","        df = train_fold,\n","        period=args.period,\n","        audio_transform=train_audio_transform,\n","        data_path=args.train_data_path,\n","        mode=\"train\"\n","    )\n","\n","    valid_dataset = SedDataset(\n","        df = valid_fold,\n","        period=args.period,\n","        stride=5,\n","        audio_transform=None,\n","        data_path=args.train_data_path,\n","        mode=\"valid\"\n","    )\n","\n","    test_dataset = SedDataset(\n","        df = sub_df,\n","        period=args.period,\n","        stride=1,#<=======================================\n","        audio_transform=None,\n","        data_path=args.test_data_path,\n","        mode=\"test\"\n","    )\n","\n","    ##################\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset,\n","        batch_size=args.batch_size,\n","        shuffle=True,\n","        drop_last=True,\n","        num_workers=args.num_workers\n","    )\n","\n","    valid_loader = torch.utils.data.DataLoader(\n","        valid_dataset,\n","        batch_size=args.batch_size,\n","        shuffle=False,\n","        drop_last=False,\n","        num_workers=args.num_workers\n","    )\n","\n","    test_loader = torch.utils.data.DataLoader(\n","        test_dataset,\n","        batch_size=4,\n","        shuffle=False,\n","        drop_last=False,\n","        num_workers=args.num_workers\n","    )\n","\n","    # model = AudioSEDModel(**args.model_param)#<==============\n","    model = PANNsDense161Att(**args.model_param)\n","    model = model.to(args.device)\n","\n","    if args.pretrain_weights:\n","        print(\"---------------------loading pretrain weights\")\n","        model.load_state_dict(torch.load(args.pretrain_weights, map_location=args.device), strict=False)\n","        model = model.to(args.device)\n","\n","    criterion = ResampleLoss()#CombineLoss()#FocalLoss #ImprovedPANNsLoss() #PANNsLoss()() #BCEWithLogitsLoss()#<=======================\n","    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n","    ######################\n","#     num_train_steps = int(len(train_loader) * args.epochs)\n","#     num_warmup_steps = int(0.1 * args.epochs * len(train_loader))\n","#     scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)\n","    \n","    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.cosine_epo)\n","    scheduler = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=args.warmup_epo, after_scheduler=scheduler_cosine)\n","    ######################\n","    best_lwlrap = -np.inf\n","    early_stop_count = 0\n","# ===========================================================================\n","    for epoch in range(args.start_epcoh, args.epochs):\n","        train_avg, train_loss = train_epoch(args, model, train_loader, criterion, optimizer, scheduler, epoch)\n","        valid_avg, valid_loss = valid_epoch(args, model, valid_loader, criterion, epoch)\n","\n","        if args.epoch_scheduler:\n","            scheduler.step(epoch)\n","        \n","        content = f\"\"\"\n","                {time.ctime()} \\n\n","                Fold:{args.fold}, Epoch:{epoch}, lr:{optimizer.param_groups[0]['lr']:.7}\\n\n","                Train Loss:{train_loss:0.4f} - LWLRAP:{train_avg['lwlrap']:0.4f}\\n\n","                Valid Loss:{valid_loss:0.4f} - LWLRAP:{valid_avg['lwlrap']:0.4f}\\n\n","        \"\"\"\n","        print(content)\n","        with open(f'{args.save_path}/log_{args.exp_name}.txt', 'a') as appender:\n","            appender.write(content+'\\n')\n","        \n","        if valid_avg['lwlrap'] > best_lwlrap:\n","            print(f\"########## >>>>>>>> Model Improved From {best_lwlrap} ----> {valid_avg['lwlrap']}\")\n","            torch.save(model.state_dict(), os.path.join(args.save_path, f'fold-{args.fold}.bin'))\n","            best_lwlrap = valid_avg['lwlrap']\n","            early_stop_count = 0\n","        else:\n","            early_stop_count += 1\n","        #torch.save(model.state_dict(), os.path.join(args.save_path, f'fold-{args.fold}_last.bin'))\n","\n","        if args.early_stop == early_stop_count:\n","            print(\"\\n $$$ ---? Ohoo.... we reached early stoping count :\", early_stop_count)\n","            break\n","        \n","        #eary_stop\n","        if epoch == 30:\n","            torch.save(model.state_dict(), os.path.join(args.save_path, f'epo30-fold-{args.fold}.bin'))\n","            print(\"\\n $$$ ---? Ohoo.... we reached early stoping count :\", early_stop_count)\n","\n","        if epoch == 35:\n","            torch.save(model.state_dict(), os.path.join(args.save_path, f'epo35-fold-{args.fold}.bin'))\n","            print(\"\\n $$$ ---? Ohoo.... we reached early stoping count :\", early_stop_count)\n","                \n","        if epoch == 40:\n","            torch.save(model.state_dict(), os.path.join(args.save_path, f'epo40-fold-{args.fold}.bin'))\n","            print(\"\\n $$$ ---? Ohoo.... we reached early stoping count :\", early_stop_count)\n","            \n","        if epoch == 45:\n","            torch.save(model.state_dict(), os.path.join(args.save_path, f'epo45-fold-{args.fold}.bin'))\n","            print(\"\\n $$$ ---? Ohoo.... we reached early stoping count :\", early_stop_count)\n","            break\n","\n","\n"," # ===========================================================================   \n","    model.load_state_dict(torch.load(os.path.join(args.save_path, f'fold-{args.fold}.bin'), map_location=args.device))\n","    model = model.to(args.device)\n","    # print(model)\n","\n","    target_cols = sub_df.columns[1:].values.tolist()\n","    test_pred, ids = test_epoch(args, model, test_loader)\n","    print(np.array(test_pred).shape)\n","\n","    test_pred_df = pd.DataFrame({\n","        \"recording_id\" : sub_df.recording_id.values\n","    })\n","    test_pred_df[target_cols] = test_pred\n","    test_pred_df.to_csv(os.path.join(args.save_path, f\"fold-{args.fold}-submission.csv\"), index=False)\n","    print(os.path.join(args.save_path, f\"fold-{args.fold}-submission.csv\"))\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n7p6ySci4qwr"},"source":["# Main"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1aKaOlHl4taT","outputId":"f88cebfb-b2ad-43a0-ddbf-c935d9c0e395"},"source":["for folds in range(FOLDS):\n","  main(fold=folds)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["      recording_id  species_id  songtype_id  t_min  f_min  t_max  f_max  kfold\n","0     d49a94504_01        0,18            1      0   5000    5.2  10000      2\n","1     97630c03d_03      0,18,3            1      0   5000    5.2  10000      1\n","2     97630c03d_02      0,18,3            1      0   5000    5.2  10000      2\n","3     d9bfc9e6b_02    0,1,3,12            1      0   5000    5.2  10000      1\n","4     3710abba6_02        0,18            1      0   5000    5.2  10000      2\n","...            ...         ...          ...    ...    ...    ...    ...    ...\n","2422  59a9eb657_03  23,3,12,18            1      0   5000    5.2  10000      1\n","2423  59a9eb657_02     23,3,12            1      0   5000    5.2  10000      3\n","2424  6c032e356_01       23,12            1      0   5000    5.2  10000      4\n","2426  79f38de91_02          23            1      0   5000    5.2  10000      4\n","2427  774912d66_03        23,3            1      0   5000    5.2  10000      3\n","\n","[1945 rows x 8 columns]\n","1945\n","[125, 251, 103, 1005, 163, 94, 78, 285, 131, 88, 96, 199, 416, 86, 100, 188, 80, 80, 409, 88, 107, 194, 101, 208]\n","[1820, 1694, 1842, 940, 1782, 1851, 1867, 1660, 1814, 1857, 1849, 1746, 1529, 1859, 1845, 1757, 1865, 1865, 1536, 1857, 1838, 1751, 1844, 1737]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"stream","text":["{'class_freq': [125, 251, 103, 1005, 163, 94, 78, 285, 131, 88, 96, 199, 416, 86, 100, 188, 80, 80, 409, 88, 107, 194, 101, 208], 'neg_class_freq': [1820, 1694, 1842, 940, 1782, 1851, 1867, 1660, 1814, 1857, 1849, 1746, 1529, 1859, 1845, 1757, 1865, 1865, 1536, 1857, 1838, 1751, 1844, 1737]}\n","Loading Microsoft Vision pretrained model\n","Model already downloaded.\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[1;35m loading from ./class_freq.pkl | rebalance | {'neg_scale': 5.0, 'init_bias': 0.1} | s\u001b[0;0m\n","\u001b[1;35m rebalance reweighting mapping params: 10.00 | 0.20 | 0.10 \u001b[0;0m\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:0 - Loss0.3495: 100%|██████████| 121/121 [11:46<00:00,  5.84s/it]\n","Valid E:0 - Loss:0.0957: 100%|██████████| 31/31 [01:00<00:00,  1.96s/it]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:14:40 2021 \n","\n","                Fold:0, Epoch:0, lr:0.0001\n","\n","                Train Loss:0.3495 - LWLRAP:0.3664\n","\n","                Valid Loss:0.0957 - LWLRAP:0.5647\n","\n","        \n","########## >>>>>>>> Model Improved From -inf ----> 0.5646994585899298\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:1 - Loss0.0599: 100%|██████████| 121/121 [00:44<00:00,  2.71it/s]\n","Valid E:1 - Loss:0.0427: 100%|██████████| 31/31 [00:01<00:00, 15.80it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:15:29 2021 \n","\n","                Fold:0, Epoch:1, lr:0.0004\n","\n","                Train Loss:0.0599 - LWLRAP:0.4478\n","\n","                Valid Loss:0.0427 - LWLRAP:0.5805\n","\n","        \n","########## >>>>>>>> Model Improved From 0.5646994585899298 ----> 0.580540731262638\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:2 - Loss0.0470: 100%|██████████| 121/121 [00:46<00:00,  2.57it/s]\n","Valid E:2 - Loss:0.0373: 100%|██████████| 31/31 [00:01<00:00, 15.51it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:16:18 2021 \n","\n","                Fold:0, Epoch:2, lr:0.0007\n","\n","                Train Loss:0.0470 - LWLRAP:0.4927\n","\n","                Valid Loss:0.0373 - LWLRAP:0.5953\n","\n","        \n","########## >>>>>>>> Model Improved From 0.580540731262638 ----> 0.5953269731441296\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:3 - Loss0.0388: 100%|██████████| 121/121 [00:43<00:00,  2.76it/s]\n","Valid E:3 - Loss:0.0353: 100%|██████████| 31/31 [00:01<00:00, 15.58it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:17:05 2021 \n","\n","                Fold:0, Epoch:3, lr:0.001\n","\n","                Train Loss:0.0388 - LWLRAP:0.5451\n","\n","                Valid Loss:0.0353 - LWLRAP:0.6019\n","\n","        \n","########## >>>>>>>> Model Improved From 0.5953269731441296 ----> 0.6019065417085644\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:4 - Loss0.0378: 100%|██████████| 121/121 [00:50<00:00,  2.42it/s]\n","Valid E:4 - Loss:0.0350: 100%|██████████| 31/31 [00:01<00:00, 15.64it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:17:58 2021 \n","\n","                Fold:0, Epoch:4, lr:0.001\n","\n","                Train Loss:0.0378 - LWLRAP:0.5587\n","\n","                Valid Loss:0.0350 - LWLRAP:0.6058\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6019065417085644 ----> 0.6057776486601236\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:5 - Loss0.0348: 100%|██████████| 121/121 [00:48<00:00,  2.50it/s]\n","Valid E:5 - Loss:0.0327: 100%|██████████| 31/31 [00:01<00:00, 15.59it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:18:49 2021 \n","\n","                Fold:0, Epoch:5, lr:0.000995343\n","\n","                Train Loss:0.0348 - LWLRAP:0.5933\n","\n","                Valid Loss:0.0327 - LWLRAP:0.6537\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6057776486601236 ----> 0.6537045106891192\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:6 - Loss0.0338: 100%|██████████| 121/121 [00:47<00:00,  2.56it/s]\n","Valid E:6 - Loss:0.0322: 100%|██████████| 31/31 [00:01<00:00, 15.56it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:19:39 2021 \n","\n","                Fold:0, Epoch:6, lr:0.000989542\n","\n","                Train Loss:0.0338 - LWLRAP:0.6063\n","\n","                Valid Loss:0.0322 - LWLRAP:0.6545\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6537045106891192 ----> 0.6544565117162198\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:7 - Loss0.0327: 100%|██████████| 121/121 [00:50<00:00,  2.42it/s]\n","Valid E:7 - Loss:0.0306: 100%|██████████| 31/31 [00:01<00:00, 15.68it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:20:31 2021 \n","\n","                Fold:0, Epoch:7, lr:0.0009814586\n","\n","                Train Loss:0.0327 - LWLRAP:0.6311\n","\n","                Valid Loss:0.0306 - LWLRAP:0.6864\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6544565117162198 ----> 0.6864104856837773\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:8 - Loss0.0318: 100%|██████████| 121/121 [00:48<00:00,  2.51it/s]\n","Valid E:8 - Loss:0.0304: 100%|██████████| 31/31 [00:01<00:00, 15.61it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:21:22 2021 \n","\n","                Fold:0, Epoch:8, lr:0.0009711305\n","\n","                Train Loss:0.0318 - LWLRAP:0.6515\n","\n","                Valid Loss:0.0304 - LWLRAP:0.7054\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6864104856837773 ----> 0.705445468768633\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:9 - Loss0.0309: 100%|██████████| 121/121 [00:45<00:00,  2.65it/s]\n","Valid E:9 - Loss:0.0300: 100%|██████████| 31/31 [00:02<00:00, 15.50it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:22:11 2021 \n","\n","                Fold:0, Epoch:9, lr:0.0009586057\n","\n","                Train Loss:0.0309 - LWLRAP:0.6649\n","\n","                Valid Loss:0.0300 - LWLRAP:0.7140\n","\n","        \n","########## >>>>>>>> Model Improved From 0.705445468768633 ----> 0.714014949822514\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:10 - Loss0.0299: 100%|██████████| 121/121 [00:50<00:00,  2.41it/s]\n","Valid E:10 - Loss:0.0276: 100%|██████████| 31/31 [00:01<00:00, 15.60it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:23:03 2021 \n","\n","                Fold:0, Epoch:10, lr:0.0009439426\n","\n","                Train Loss:0.0299 - LWLRAP:0.6824\n","\n","                Valid Loss:0.0276 - LWLRAP:0.7444\n","\n","        \n","########## >>>>>>>> Model Improved From 0.714014949822514 ----> 0.7443995011690818\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:11 - Loss0.0287: 100%|██████████| 121/121 [00:50<00:00,  2.42it/s]\n","Valid E:11 - Loss:0.0267: 100%|██████████| 31/31 [00:01<00:00, 15.52it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:23:56 2021 \n","\n","                Fold:0, Epoch:11, lr:0.0009272097\n","\n","                Train Loss:0.0287 - LWLRAP:0.7086\n","\n","                Valid Loss:0.0267 - LWLRAP:0.7874\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7443995011690818 ----> 0.7874380250406675\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:12 - Loss0.0275: 100%|██████████| 121/121 [00:46<00:00,  2.59it/s]\n","Valid E:12 - Loss:0.0237: 100%|██████████| 31/31 [00:01<00:00, 15.60it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:24:46 2021 \n","\n","                Fold:0, Epoch:12, lr:0.0009084849\n","\n","                Train Loss:0.0275 - LWLRAP:0.7348\n","\n","                Valid Loss:0.0237 - LWLRAP:0.8186\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7874380250406675 ----> 0.8185741584300811\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:13 - Loss0.0258: 100%|██████████| 121/121 [00:45<00:00,  2.66it/s]\n","Valid E:13 - Loss:0.0215: 100%|██████████| 31/31 [00:01<00:00, 15.60it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:25:34 2021 \n","\n","                Fold:0, Epoch:13, lr:0.0008878556\n","\n","                Train Loss:0.0258 - LWLRAP:0.7583\n","\n","                Valid Loss:0.0215 - LWLRAP:0.8432\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8185741584300811 ----> 0.8432254210828516\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:14 - Loss0.0242: 100%|██████████| 121/121 [00:44<00:00,  2.70it/s]\n","Valid E:14 - Loss:0.0205: 100%|██████████| 31/31 [00:01<00:00, 15.57it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:26:21 2021 \n","\n","                Fold:0, Epoch:14, lr:0.000865418\n","\n","                Train Loss:0.0242 - LWLRAP:0.7867\n","\n","                Valid Loss:0.0205 - LWLRAP:0.8635\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8432254210828516 ----> 0.8634618452052554\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:15 - Loss0.0226: 100%|██████████| 121/121 [00:50<00:00,  2.39it/s]\n","Valid E:15 - Loss:0.0190: 100%|██████████| 31/31 [00:02<00:00, 15.41it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:27:15 2021 \n","\n","                Fold:0, Epoch:15, lr:0.0008412766\n","\n","                Train Loss:0.0226 - LWLRAP:0.8150\n","\n","                Valid Loss:0.0190 - LWLRAP:0.8805\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8634618452052554 ----> 0.8804635849794806\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:16 - Loss0.0205: 100%|██████████| 121/121 [00:49<00:00,  2.46it/s]\n","Valid E:16 - Loss:0.0161: 100%|██████████| 31/31 [00:02<00:00, 15.08it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:28:07 2021 \n","\n","                Fold:0, Epoch:16, lr:0.000815544\n","\n","                Train Loss:0.0205 - LWLRAP:0.8444\n","\n","                Valid Loss:0.0161 - LWLRAP:0.9135\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8804635849794806 ----> 0.9134780309592758\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:17 - Loss0.0190: 100%|██████████| 121/121 [00:48<00:00,  2.49it/s]\n","Valid E:17 - Loss:0.0164: 100%|██████████| 31/31 [00:01<00:00, 15.62it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:28:58 2021 \n","\n","                Fold:0, Epoch:17, lr:0.0007883402\n","\n","                Train Loss:0.0190 - LWLRAP:0.8645\n","\n","                Valid Loss:0.0164 - LWLRAP:0.9127\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:18 - Loss0.0182: 100%|██████████| 121/121 [00:45<00:00,  2.65it/s]\n","Valid E:18 - Loss:0.0142: 100%|██████████| 31/31 [00:01<00:00, 15.55it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:29:46 2021 \n","\n","                Fold:0, Epoch:18, lr:0.000759792\n","\n","                Train Loss:0.0182 - LWLRAP:0.8766\n","\n","                Valid Loss:0.0142 - LWLRAP:0.9329\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9134780309592758 ----> 0.9328626625506833\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:19 - Loss0.0178: 100%|██████████| 121/121 [00:47<00:00,  2.53it/s]\n","Valid E:19 - Loss:0.0143: 100%|██████████| 31/31 [00:02<00:00, 15.42it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:30:36 2021 \n","\n","                Fold:0, Epoch:19, lr:0.0007300325\n","\n","                Train Loss:0.0178 - LWLRAP:0.8783\n","\n","                Valid Loss:0.0143 - LWLRAP:0.9339\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9328626625506833 ----> 0.9338726263049513\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:20 - Loss0.0165: 100%|██████████| 121/121 [00:47<00:00,  2.53it/s]\n","Valid E:20 - Loss:0.0140: 100%|██████████| 31/31 [00:02<00:00, 15.41it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:31:27 2021 \n","\n","                Fold:0, Epoch:20, lr:0.0006992005\n","\n","                Train Loss:0.0165 - LWLRAP:0.8947\n","\n","                Valid Loss:0.0140 - LWLRAP:0.9268\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:21 - Loss0.0157: 100%|██████████| 121/121 [00:43<00:00,  2.77it/s]\n","Valid E:21 - Loss:0.0134: 100%|██████████| 31/31 [00:01<00:00, 15.54it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:32:13 2021 \n","\n","                Fold:0, Epoch:21, lr:0.0006674398\n","\n","                Train Loss:0.0157 - LWLRAP:0.9000\n","\n","                Valid Loss:0.0134 - LWLRAP:0.9337\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:22 - Loss0.0155: 100%|██████████| 121/121 [00:45<00:00,  2.69it/s]\n","Valid E:22 - Loss:0.0143: 100%|██████████| 31/31 [00:02<00:00, 15.49it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:33:00 2021 \n","\n","                Fold:0, Epoch:22, lr:0.0006348984\n","\n","                Train Loss:0.0155 - LWLRAP:0.9041\n","\n","                Valid Loss:0.0143 - LWLRAP:0.9350\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9338726263049513 ----> 0.9349892574114652\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:23 - Loss0.0151: 100%|██████████| 121/121 [00:47<00:00,  2.56it/s]\n","Valid E:23 - Loss:0.0136: 100%|██████████| 31/31 [00:02<00:00, 15.32it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:33:50 2021 \n","\n","                Fold:0, Epoch:23, lr:0.000601728\n","\n","                Train Loss:0.0151 - LWLRAP:0.9060\n","\n","                Valid Loss:0.0136 - LWLRAP:0.9372\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9349892574114652 ----> 0.9371618573337754\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:24 - Loss0.0147: 100%|██████████| 121/121 [00:50<00:00,  2.37it/s]\n","Valid E:24 - Loss:0.0134: 100%|██████████| 31/31 [00:02<00:00, 15.37it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:34:44 2021 \n","\n","                Fold:0, Epoch:24, lr:0.0005680833\n","\n","                Train Loss:0.0147 - LWLRAP:0.9128\n","\n","                Valid Loss:0.0134 - LWLRAP:0.9343\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:25 - Loss0.0147: 100%|██████████| 121/121 [00:47<00:00,  2.53it/s]\n","Valid E:25 - Loss:43.6049: 100%|██████████| 31/31 [00:02<00:00, 15.46it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:35:34 2021 \n","\n","                Fold:0, Epoch:25, lr:0.0005341212\n","\n","                Train Loss:0.0147 - LWLRAP:0.9120\n","\n","                Valid Loss:43.6049 - LWLRAP:0.2201\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:26 - Loss0.0179: 100%|██████████| 121/121 [00:50<00:00,  2.38it/s]\n","Valid E:26 - Loss:0.0132: 100%|██████████| 31/31 [00:02<00:00, 15.48it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:36:27 2021 \n","\n","                Fold:0, Epoch:26, lr:0.0005\n","\n","                Train Loss:0.0179 - LWLRAP:0.8761\n","\n","                Valid Loss:0.0132 - LWLRAP:0.9403\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9371618573337754 ----> 0.9402515439987563\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:27 - Loss0.0151: 100%|██████████| 121/121 [00:47<00:00,  2.53it/s]\n","Valid E:27 - Loss:0.0139: 100%|██████████| 31/31 [00:02<00:00, 15.21it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:37:18 2021 \n","\n","                Fold:0, Epoch:27, lr:0.0004658788\n","\n","                Train Loss:0.0151 - LWLRAP:0.9049\n","\n","                Valid Loss:0.0139 - LWLRAP:0.9336\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:28 - Loss0.0149: 100%|██████████| 121/121 [00:51<00:00,  2.37it/s]\n","Valid E:28 - Loss:0.0137: 100%|██████████| 31/31 [00:02<00:00, 15.36it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:38:11 2021 \n","\n","                Fold:0, Epoch:28, lr:0.0004319167\n","\n","                Train Loss:0.0149 - LWLRAP:0.9104\n","\n","                Valid Loss:0.0137 - LWLRAP:0.9345\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:29 - Loss0.0202: 100%|██████████| 121/121 [00:48<00:00,  2.48it/s]\n","Valid E:29 - Loss:0.0135: 100%|██████████| 31/31 [00:02<00:00, 15.45it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:39:02 2021 \n","\n","                Fold:0, Epoch:29, lr:0.000398272\n","\n","                Train Loss:0.0202 - LWLRAP:0.8643\n","\n","                Valid Loss:0.0135 - LWLRAP:0.9321\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:30 - Loss0.0169: 100%|██████████| 121/121 [00:49<00:00,  2.43it/s]\n","Valid E:30 - Loss:0.0125: 100%|██████████| 31/31 [00:01<00:00, 15.50it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:39:54 2021 \n","\n","                Fold:0, Epoch:30, lr:0.0003651016\n","\n","                Train Loss:0.0169 - LWLRAP:0.8886\n","\n","                Valid Loss:0.0125 - LWLRAP:0.9465\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9402515439987563 ----> 0.9464842705202903\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 0\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:31 - Loss0.0147: 100%|██████████| 121/121 [00:50<00:00,  2.39it/s]\n","Valid E:31 - Loss:0.0128: 100%|██████████| 31/31 [00:01<00:00, 15.60it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:40:48 2021 \n","\n","                Fold:0, Epoch:31, lr:0.0003325602\n","\n","                Train Loss:0.0147 - LWLRAP:0.9109\n","\n","                Valid Loss:0.0128 - LWLRAP:0.9471\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9464842705202903 ----> 0.9470660139263171\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:32 - Loss0.0141: 100%|██████████| 121/121 [00:46<00:00,  2.59it/s]\n","Valid E:32 - Loss:0.0130: 100%|██████████| 31/31 [00:02<00:00, 15.34it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:41:37 2021 \n","\n","                Fold:0, Epoch:32, lr:0.0003007995\n","\n","                Train Loss:0.0141 - LWLRAP:0.9159\n","\n","                Valid Loss:0.0130 - LWLRAP:0.9375\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:33 - Loss0.0130: 100%|██████████| 121/121 [00:47<00:00,  2.56it/s]\n","Valid E:33 - Loss:0.0143: 100%|██████████| 31/31 [00:02<00:00, 15.49it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:42:27 2021 \n","\n","                Fold:0, Epoch:33, lr:0.0002699675\n","\n","                Train Loss:0.0130 - LWLRAP:0.9283\n","\n","                Valid Loss:0.0143 - LWLRAP:0.9346\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:34 - Loss0.0127: 100%|██████████| 121/121 [00:49<00:00,  2.43it/s]\n","Valid E:34 - Loss:0.0137: 100%|██████████| 31/31 [00:01<00:00, 15.57it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:43:19 2021 \n","\n","                Fold:0, Epoch:34, lr:0.000240208\n","\n","                Train Loss:0.0127 - LWLRAP:0.9269\n","\n","                Valid Loss:0.0137 - LWLRAP:0.9346\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:35 - Loss0.0120: 100%|██████████| 121/121 [00:44<00:00,  2.72it/s]\n","Valid E:35 - Loss:0.0126: 100%|██████████| 31/31 [00:02<00:00, 15.43it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:44:06 2021 \n","\n","                Fold:0, Epoch:35, lr:0.0002116598\n","\n","                Train Loss:0.0120 - LWLRAP:0.9324\n","\n","                Valid Loss:0.0126 - LWLRAP:0.9494\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9470660139263171 ----> 0.9493872689804561\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 0\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:36 - Loss0.0116: 100%|██████████| 121/121 [00:45<00:00,  2.64it/s]\n","Valid E:36 - Loss:0.0129: 100%|██████████| 31/31 [00:01<00:00, 15.77it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:44:55 2021 \n","\n","                Fold:0, Epoch:36, lr:0.000184456\n","\n","                Train Loss:0.0116 - LWLRAP:0.9358\n","\n","                Valid Loss:0.0129 - LWLRAP:0.9474\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:37 - Loss0.0112: 100%|██████████| 121/121 [00:46<00:00,  2.59it/s]\n","Valid E:37 - Loss:0.0128: 100%|██████████| 31/31 [00:02<00:00, 15.28it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:45:44 2021 \n","\n","                Fold:0, Epoch:37, lr:0.0001587234\n","\n","                Train Loss:0.0112 - LWLRAP:0.9388\n","\n","                Valid Loss:0.0128 - LWLRAP:0.9482\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:38 - Loss0.0111: 100%|██████████| 121/121 [00:46<00:00,  2.58it/s]\n","Valid E:38 - Loss:0.0129: 100%|██████████| 31/31 [00:02<00:00, 15.50it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:46:33 2021 \n","\n","                Fold:0, Epoch:38, lr:0.000134582\n","\n","                Train Loss:0.0111 - LWLRAP:0.9407\n","\n","                Valid Loss:0.0129 - LWLRAP:0.9499\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9493872689804561 ----> 0.9499466619221321\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:39 - Loss0.0103: 100%|██████████| 121/121 [00:49<00:00,  2.46it/s]\n","Valid E:39 - Loss:0.0123: 100%|██████████| 31/31 [00:02<00:00, 15.26it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:47:25 2021 \n","\n","                Fold:0, Epoch:39, lr:0.0001121444\n","\n","                Train Loss:0.0103 - LWLRAP:0.9462\n","\n","                Valid Loss:0.0123 - LWLRAP:0.9527\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9499466619221321 ----> 0.9526780151172861\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:40 - Loss0.0101: 100%|██████████| 121/121 [00:50<00:00,  2.41it/s]\n","Valid E:40 - Loss:0.0127: 100%|██████████| 31/31 [00:02<00:00, 15.38it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:48:18 2021 \n","\n","                Fold:0, Epoch:40, lr:9.151505e-05\n","\n","                Train Loss:0.0101 - LWLRAP:0.9492\n","\n","                Valid Loss:0.0127 - LWLRAP:0.9467\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 1\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:41 - Loss0.0094: 100%|██████████| 121/121 [00:49<00:00,  2.45it/s]\n","Valid E:41 - Loss:0.0126: 100%|██████████| 31/31 [00:02<00:00, 15.42it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:49:10 2021 \n","\n","                Fold:0, Epoch:41, lr:7.27903e-05\n","\n","                Train Loss:0.0094 - LWLRAP:0.9486\n","\n","                Valid Loss:0.0126 - LWLRAP:0.9515\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:42 - Loss0.0093: 100%|██████████| 121/121 [00:50<00:00,  2.41it/s]\n","Valid E:42 - Loss:0.0124: 100%|██████████| 31/31 [00:02<00:00, 15.34it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:50:02 2021 \n","\n","                Fold:0, Epoch:42, lr:5.605739e-05\n","\n","                Train Loss:0.0093 - LWLRAP:0.9516\n","\n","                Valid Loss:0.0124 - LWLRAP:0.9521\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:43 - Loss0.0089: 100%|██████████| 121/121 [00:48<00:00,  2.48it/s]\n","Valid E:43 - Loss:0.0130: 100%|██████████| 31/31 [00:01<00:00, 15.53it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:50:53 2021 \n","\n","                Fold:0, Epoch:43, lr:4.139435e-05\n","\n","                Train Loss:0.0089 - LWLRAP:0.9528\n","\n","                Valid Loss:0.0130 - LWLRAP:0.9464\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:44 - Loss0.0086: 100%|██████████| 121/121 [00:50<00:00,  2.40it/s]\n","Valid E:44 - Loss:0.0124: 100%|██████████| 31/31 [00:02<00:00, 15.39it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:51:46 2021 \n","\n","                Fold:0, Epoch:44, lr:2.886954e-05\n","\n","                Train Loss:0.0086 - LWLRAP:0.9546\n","\n","                Valid Loss:0.0124 - LWLRAP:0.9522\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:45 - Loss0.0083: 100%|██████████| 121/121 [00:47<00:00,  2.56it/s]\n","Valid E:45 - Loss:0.0126: 100%|██████████| 31/31 [00:02<00:00, 15.43it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 02:52:35 2021 \n","\n","                Fold:0, Epoch:45, lr:1.854136e-05\n","\n","                Train Loss:0.0083 - LWLRAP:0.9569\n","\n","                Valid Loss:0.0126 - LWLRAP:0.9487\n","\n","        \n","\n"," $$$ ---? Ohoo.... we reached early stoping count : 6\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 498/498 [09:37<00:00,  1.16s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["(1992, 24)\n","weights/bird_mluti_ResNet50_5F_BASE_head1024_framewides_ResampleLoss_2048_512_256_addmask0202_earystop35_batch/fold-0-submission.csv\n","      recording_id species_id  songtype_id  t_min  f_min  t_max  f_max  kfold\n","0     d49a94504_01       0,18            1      0   5000    5.2  10000      2\n","2     97630c03d_02     0,18,3            1      0   5000    5.2  10000      2\n","4     3710abba6_02       0,18            1      0   5000    5.2  10000      2\n","6     5f9157d7b_01     0,3,18            1      0   5000    5.2  10000      0\n","7     d9bfc9e6b_01   0,1,3,12            1      0   5000    5.2  10000      2\n","...            ...        ...          ...    ...    ...    ...    ...    ...\n","2423  59a9eb657_02    23,3,12            1      0   5000    5.2  10000      3\n","2424  6c032e356_01      23,12            1      0   5000    5.2  10000      4\n","2425  006ab765f_05       23,3            1      0   5000    5.2  10000      0\n","2426  79f38de91_02         23            1      0   5000    5.2  10000      4\n","2427  774912d66_03       23,3            1      0   5000    5.2  10000      3\n","\n","[1939 rows x 8 columns]\n","1939\n","[126, 251, 103, 1006, 163, 94, 77, 286, 131, 87, 96, 199, 416, 86, 100, 188, 80, 80, 410, 88, 106, 195, 101, 208]\n","[1813, 1688, 1836, 933, 1776, 1845, 1862, 1653, 1808, 1852, 1843, 1740, 1523, 1853, 1839, 1751, 1859, 1859, 1529, 1851, 1833, 1744, 1838, 1731]\n","{'class_freq': [126, 251, 103, 1006, 163, 94, 77, 286, 131, 87, 96, 199, 416, 86, 100, 188, 80, 80, 410, 88, 106, 195, 101, 208], 'neg_class_freq': [1813, 1688, 1836, 933, 1776, 1845, 1862, 1653, 1808, 1852, 1843, 1740, 1523, 1853, 1839, 1751, 1859, 1859, 1529, 1851, 1833, 1744, 1838, 1731]}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"stream","text":["Loading Microsoft Vision pretrained model\n","Model already downloaded.\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[1;35m loading from ./class_freq.pkl | rebalance | {'neg_scale': 5.0, 'init_bias': 0.1} | s\u001b[0;0m\n","\u001b[1;35m rebalance reweighting mapping params: 10.00 | 0.20 | 0.10 \u001b[0;0m\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:0 - Loss0.3676: 100%|██████████| 120/120 [00:45<00:00,  2.62it/s]\n","Valid E:0 - Loss:0.1204: 100%|██████████| 31/31 [00:02<00:00, 15.13it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:03:07 2021 \n","\n","                Fold:1, Epoch:0, lr:0.0001\n","\n","                Train Loss:0.3676 - LWLRAP:0.3702\n","\n","                Valid Loss:0.1204 - LWLRAP:0.5586\n","\n","        \n","########## >>>>>>>> Model Improved From -inf ----> 0.5586006697892858\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:1 - Loss0.0639: 100%|██████████| 120/120 [00:45<00:00,  2.67it/s]\n","Valid E:1 - Loss:0.0493: 100%|██████████| 31/31 [00:02<00:00, 15.34it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:03:54 2021 \n","\n","                Fold:1, Epoch:1, lr:0.0004\n","\n","                Train Loss:0.0639 - LWLRAP:0.4275\n","\n","                Valid Loss:0.0493 - LWLRAP:0.5374\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:2 - Loss0.0479: 100%|██████████| 120/120 [00:45<00:00,  2.65it/s]\n","Valid E:2 - Loss:0.0393: 100%|██████████| 31/31 [00:02<00:00, 15.23it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:04:42 2021 \n","\n","                Fold:1, Epoch:2, lr:0.0007\n","\n","                Train Loss:0.0479 - LWLRAP:0.4862\n","\n","                Valid Loss:0.0393 - LWLRAP:0.6033\n","\n","        \n","########## >>>>>>>> Model Improved From 0.5586006697892858 ----> 0.6033221392516785\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:3 - Loss0.0402: 100%|██████████| 120/120 [00:46<00:00,  2.58it/s]\n","Valid E:3 - Loss:0.0365: 100%|██████████| 31/31 [00:02<00:00, 15.40it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:05:31 2021 \n","\n","                Fold:1, Epoch:3, lr:0.001\n","\n","                Train Loss:0.0402 - LWLRAP:0.5263\n","\n","                Valid Loss:0.0365 - LWLRAP:0.6327\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6033221392516785 ----> 0.6327386535975388\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:4 - Loss0.0374: 100%|██████████| 120/120 [00:46<00:00,  2.59it/s]\n","Valid E:4 - Loss:0.0358: 100%|██████████| 31/31 [00:02<00:00, 15.31it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:06:20 2021 \n","\n","                Fold:1, Epoch:4, lr:0.001\n","\n","                Train Loss:0.0374 - LWLRAP:0.5582\n","\n","                Valid Loss:0.0358 - LWLRAP:0.6242\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:5 - Loss0.0358: 100%|██████████| 120/120 [00:46<00:00,  2.58it/s]\n","Valid E:5 - Loss:0.0347: 100%|██████████| 31/31 [00:02<00:00, 15.02it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:07:09 2021 \n","\n","                Fold:1, Epoch:5, lr:0.000995343\n","\n","                Train Loss:0.0358 - LWLRAP:0.5709\n","\n","                Valid Loss:0.0347 - LWLRAP:0.6479\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6327386535975388 ----> 0.6479060676601409\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:6 - Loss0.0347: 100%|██████████| 120/120 [00:45<00:00,  2.63it/s]\n","Valid E:6 - Loss:0.0324: 100%|██████████| 31/31 [00:02<00:00, 15.40it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:07:57 2021 \n","\n","                Fold:1, Epoch:6, lr:0.000989542\n","\n","                Train Loss:0.0347 - LWLRAP:0.5913\n","\n","                Valid Loss:0.0324 - LWLRAP:0.6521\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6479060676601409 ----> 0.6521067477349682\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:7 - Loss0.0332: 100%|██████████| 120/120 [00:44<00:00,  2.69it/s]\n","Valid E:7 - Loss:0.0317: 100%|██████████| 31/31 [00:02<00:00, 15.15it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:08:45 2021 \n","\n","                Fold:1, Epoch:7, lr:0.0009814586\n","\n","                Train Loss:0.0332 - LWLRAP:0.6140\n","\n","                Valid Loss:0.0317 - LWLRAP:0.6801\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6521067477349682 ----> 0.6800921407316896\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:8 - Loss0.0326: 100%|██████████| 120/120 [00:52<00:00,  2.27it/s]\n","Valid E:8 - Loss:0.0315: 100%|██████████| 31/31 [00:02<00:00, 15.32it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:09:40 2021 \n","\n","                Fold:1, Epoch:8, lr:0.0009711305\n","\n","                Train Loss:0.0326 - LWLRAP:0.6291\n","\n","                Valid Loss:0.0315 - LWLRAP:0.6852\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6800921407316896 ----> 0.6851674574518869\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:9 - Loss0.0315: 100%|██████████| 120/120 [00:46<00:00,  2.59it/s]\n","Valid E:9 - Loss:0.0307: 100%|██████████| 31/31 [00:02<00:00, 15.16it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:10:29 2021 \n","\n","                Fold:1, Epoch:9, lr:0.0009586057\n","\n","                Train Loss:0.0315 - LWLRAP:0.6450\n","\n","                Valid Loss:0.0307 - LWLRAP:0.6941\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6851674574518869 ----> 0.6940656765653573\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:10 - Loss0.0310: 100%|██████████| 120/120 [00:49<00:00,  2.44it/s]\n","Valid E:10 - Loss:0.0310: 100%|██████████| 31/31 [00:02<00:00, 15.23it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:11:21 2021 \n","\n","                Fold:1, Epoch:10, lr:0.0009439426\n","\n","                Train Loss:0.0310 - LWLRAP:0.6623\n","\n","                Valid Loss:0.0310 - LWLRAP:0.7049\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6940656765653573 ----> 0.704891484281707\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:11 - Loss0.0297: 100%|██████████| 120/120 [00:47<00:00,  2.54it/s]\n","Valid E:11 - Loss:0.0270: 100%|██████████| 31/31 [00:02<00:00, 15.20it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:12:11 2021 \n","\n","                Fold:1, Epoch:11, lr:0.0009272097\n","\n","                Train Loss:0.0297 - LWLRAP:0.6849\n","\n","                Valid Loss:0.0270 - LWLRAP:0.7447\n","\n","        \n","########## >>>>>>>> Model Improved From 0.704891484281707 ----> 0.7447110687233133\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:12 - Loss0.0287: 100%|██████████| 120/120 [00:48<00:00,  2.47it/s]\n","Valid E:12 - Loss:0.0271: 100%|██████████| 31/31 [00:02<00:00, 15.22it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:13:03 2021 \n","\n","                Fold:1, Epoch:12, lr:0.0009084849\n","\n","                Train Loss:0.0287 - LWLRAP:0.7000\n","\n","                Valid Loss:0.0271 - LWLRAP:0.7497\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7447110687233133 ----> 0.7496902516380056\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:13 - Loss0.0278: 100%|██████████| 120/120 [00:49<00:00,  2.43it/s]\n","Valid E:13 - Loss:0.0249: 100%|██████████| 31/31 [00:02<00:00, 15.07it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:13:55 2021 \n","\n","                Fold:1, Epoch:13, lr:0.0008878556\n","\n","                Train Loss:0.0278 - LWLRAP:0.7223\n","\n","                Valid Loss:0.0249 - LWLRAP:0.7794\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7496902516380056 ----> 0.7793518051543334\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:14 - Loss0.0261: 100%|██████████| 120/120 [00:47<00:00,  2.55it/s]\n","Valid E:14 - Loss:0.0235: 100%|██████████| 31/31 [00:02<00:00, 15.02it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:14:45 2021 \n","\n","                Fold:1, Epoch:14, lr:0.000865418\n","\n","                Train Loss:0.0261 - LWLRAP:0.7449\n","\n","                Valid Loss:0.0235 - LWLRAP:0.8072\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7793518051543334 ----> 0.8071714921358091\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:15 - Loss0.0252: 100%|██████████| 120/120 [00:43<00:00,  2.79it/s]\n","Valid E:15 - Loss:0.0222: 100%|██████████| 31/31 [00:02<00:00, 15.28it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:15:31 2021 \n","\n","                Fold:1, Epoch:15, lr:0.0008412766\n","\n","                Train Loss:0.0252 - LWLRAP:0.7662\n","\n","                Valid Loss:0.0222 - LWLRAP:0.8269\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8071714921358091 ----> 0.8268696596019012\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:16 - Loss0.0239: 100%|██████████| 120/120 [00:48<00:00,  2.47it/s]\n","Valid E:16 - Loss:0.0206: 100%|██████████| 31/31 [00:02<00:00, 15.32it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:16:22 2021 \n","\n","                Fold:1, Epoch:16, lr:0.000815544\n","\n","                Train Loss:0.0239 - LWLRAP:0.7877\n","\n","                Valid Loss:0.0206 - LWLRAP:0.8500\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8268696596019012 ----> 0.85002540546366\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:17 - Loss0.0214: 100%|██████████| 120/120 [00:48<00:00,  2.47it/s]\n","Valid E:17 - Loss:0.0186: 100%|██████████| 31/31 [00:02<00:00, 15.32it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:17:13 2021 \n","\n","                Fold:1, Epoch:17, lr:0.0007883402\n","\n","                Train Loss:0.0214 - LWLRAP:0.8254\n","\n","                Valid Loss:0.0186 - LWLRAP:0.8845\n","\n","        \n","########## >>>>>>>> Model Improved From 0.85002540546366 ----> 0.884539081230339\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:18 - Loss0.0201: 100%|██████████| 120/120 [00:51<00:00,  2.33it/s]\n","Valid E:18 - Loss:0.0179: 100%|██████████| 31/31 [00:02<00:00, 14.86it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:18:08 2021 \n","\n","                Fold:1, Epoch:18, lr:0.000759792\n","\n","                Train Loss:0.0201 - LWLRAP:0.8428\n","\n","                Valid Loss:0.0179 - LWLRAP:0.8881\n","\n","        \n","########## >>>>>>>> Model Improved From 0.884539081230339 ----> 0.8880769254888062\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:19 - Loss0.0191: 100%|██████████| 120/120 [00:48<00:00,  2.49it/s]\n","Valid E:19 - Loss:0.0166: 100%|██████████| 31/31 [00:02<00:00, 15.05it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:18:59 2021 \n","\n","                Fold:1, Epoch:19, lr:0.0007300325\n","\n","                Train Loss:0.0191 - LWLRAP:0.8552\n","\n","                Valid Loss:0.0166 - LWLRAP:0.9065\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8880769254888062 ----> 0.9065283372621928\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:20 - Loss0.0178: 100%|██████████| 120/120 [00:48<00:00,  2.47it/s]\n","Valid E:20 - Loss:0.0162: 100%|██████████| 31/31 [00:02<00:00, 14.91it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:19:50 2021 \n","\n","                Fold:1, Epoch:20, lr:0.0006992005\n","\n","                Train Loss:0.0178 - LWLRAP:0.8712\n","\n","                Valid Loss:0.0162 - LWLRAP:0.9091\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9065283372621928 ----> 0.9091000910710856\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:21 - Loss0.0172: 100%|██████████| 120/120 [00:45<00:00,  2.62it/s]\n","Valid E:21 - Loss:0.0169: 100%|██████████| 31/31 [00:02<00:00, 15.05it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:20:39 2021 \n","\n","                Fold:1, Epoch:21, lr:0.0006674398\n","\n","                Train Loss:0.0172 - LWLRAP:0.8807\n","\n","                Valid Loss:0.0169 - LWLRAP:0.9146\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9091000910710856 ----> 0.9146108829620172\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:22 - Loss0.0165: 100%|██████████| 120/120 [00:48<00:00,  2.47it/s]\n","Valid E:22 - Loss:0.0146: 100%|██████████| 31/31 [00:02<00:00, 14.93it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:21:30 2021 \n","\n","                Fold:1, Epoch:22, lr:0.0006348984\n","\n","                Train Loss:0.0165 - LWLRAP:0.8873\n","\n","                Valid Loss:0.0146 - LWLRAP:0.9287\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9146108829620172 ----> 0.9287396889653311\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:23 - Loss0.0156: 100%|██████████| 120/120 [00:48<00:00,  2.45it/s]\n","Valid E:23 - Loss:0.0150: 100%|██████████| 31/31 [00:02<00:00, 14.95it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:22:22 2021 \n","\n","                Fold:1, Epoch:23, lr:0.000601728\n","\n","                Train Loss:0.0156 - LWLRAP:0.8992\n","\n","                Valid Loss:0.0150 - LWLRAP:0.9200\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:24 - Loss0.0148: 100%|██████████| 120/120 [00:50<00:00,  2.36it/s]\n","Valid E:24 - Loss:0.0142: 100%|██████████| 31/31 [00:02<00:00, 14.71it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:23:15 2021 \n","\n","                Fold:1, Epoch:24, lr:0.0005680833\n","\n","                Train Loss:0.0148 - LWLRAP:0.9064\n","\n","                Valid Loss:0.0142 - LWLRAP:0.9291\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9287396889653311 ----> 0.9290896979368775\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:25 - Loss0.0146: 100%|██████████| 120/120 [00:49<00:00,  2.45it/s]\n","Valid E:25 - Loss:0.0144: 100%|██████████| 31/31 [00:02<00:00, 15.07it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:24:07 2021 \n","\n","                Fold:1, Epoch:25, lr:0.0005341212\n","\n","                Train Loss:0.0146 - LWLRAP:0.9117\n","\n","                Valid Loss:0.0144 - LWLRAP:0.9365\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9290896979368775 ----> 0.936469573625249\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:26 - Loss0.0137: 100%|██████████| 120/120 [00:47<00:00,  2.50it/s]\n","Valid E:26 - Loss:0.0145: 100%|██████████| 31/31 [00:02<00:00, 15.04it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:24:58 2021 \n","\n","                Fold:1, Epoch:26, lr:0.0005\n","\n","                Train Loss:0.0137 - LWLRAP:0.9159\n","\n","                Valid Loss:0.0145 - LWLRAP:0.9322\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:27 - Loss0.0136: 100%|██████████| 120/120 [00:46<00:00,  2.57it/s]\n","Valid E:27 - Loss:0.0156: 100%|██████████| 31/31 [00:02<00:00, 15.13it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:25:47 2021 \n","\n","                Fold:1, Epoch:27, lr:0.0004658788\n","\n","                Train Loss:0.0136 - LWLRAP:0.9177\n","\n","                Valid Loss:0.0156 - LWLRAP:0.9266\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:28 - Loss0.0137: 100%|██████████| 120/120 [00:46<00:00,  2.59it/s]\n","Valid E:28 - Loss:0.3054: 100%|██████████| 31/31 [00:02<00:00, 14.87it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:26:36 2021 \n","\n","                Fold:1, Epoch:28, lr:0.0004319167\n","\n","                Train Loss:0.0137 - LWLRAP:0.9238\n","\n","                Valid Loss:0.3054 - LWLRAP:0.2759\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:29 - Loss0.0233: 100%|██████████| 120/120 [00:50<00:00,  2.38it/s]\n","Valid E:29 - Loss:0.0161: 100%|██████████| 31/31 [00:02<00:00, 14.97it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:27:28 2021 \n","\n","                Fold:1, Epoch:29, lr:0.000398272\n","\n","                Train Loss:0.0233 - LWLRAP:0.8088\n","\n","                Valid Loss:0.0161 - LWLRAP:0.9113\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:30 - Loss0.0172: 100%|██████████| 120/120 [00:47<00:00,  2.55it/s]\n","Valid E:30 - Loss:0.0143: 100%|██████████| 31/31 [00:02<00:00, 14.81it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:28:18 2021 \n","\n","                Fold:1, Epoch:30, lr:0.0003651016\n","\n","                Train Loss:0.0172 - LWLRAP:0.8874\n","\n","                Valid Loss:0.0143 - LWLRAP:0.9303\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 5\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:31 - Loss0.0152: 100%|██████████| 120/120 [00:48<00:00,  2.45it/s]\n","Valid E:31 - Loss:0.0138: 100%|██████████| 31/31 [00:02<00:00, 14.95it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:29:10 2021 \n","\n","                Fold:1, Epoch:31, lr:0.0003325602\n","\n","                Train Loss:0.0152 - LWLRAP:0.9088\n","\n","                Valid Loss:0.0138 - LWLRAP:0.9326\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:32 - Loss0.0146: 100%|██████████| 120/120 [00:53<00:00,  2.24it/s]\n","Valid E:32 - Loss:0.0136: 100%|██████████| 31/31 [00:02<00:00, 14.88it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:30:06 2021 \n","\n","                Fold:1, Epoch:32, lr:0.0003007995\n","\n","                Train Loss:0.0146 - LWLRAP:0.9142\n","\n","                Valid Loss:0.0136 - LWLRAP:0.9411\n","\n","        \n","########## >>>>>>>> Model Improved From 0.936469573625249 ----> 0.9410894309009834\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:33 - Loss0.0142: 100%|██████████| 120/120 [00:48<00:00,  2.49it/s]\n","Valid E:33 - Loss:0.0135: 100%|██████████| 31/31 [00:02<00:00, 14.91it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:30:57 2021 \n","\n","                Fold:1, Epoch:33, lr:0.0002699675\n","\n","                Train Loss:0.0142 - LWLRAP:0.9170\n","\n","                Valid Loss:0.0135 - LWLRAP:0.9373\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:34 - Loss0.0129: 100%|██████████| 120/120 [00:48<00:00,  2.45it/s]\n","Valid E:34 - Loss:0.0140: 100%|██████████| 31/31 [00:02<00:00, 14.97it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:31:48 2021 \n","\n","                Fold:1, Epoch:34, lr:0.000240208\n","\n","                Train Loss:0.0129 - LWLRAP:0.9274\n","\n","                Valid Loss:0.0140 - LWLRAP:0.9387\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:35 - Loss0.0127: 100%|██████████| 120/120 [00:48<00:00,  2.49it/s]\n","Valid E:35 - Loss:0.0128: 100%|██████████| 31/31 [00:02<00:00, 14.88it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:32:38 2021 \n","\n","                Fold:1, Epoch:35, lr:0.0002116598\n","\n","                Train Loss:0.0127 - LWLRAP:0.9269\n","\n","                Valid Loss:0.0128 - LWLRAP:0.9430\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9410894309009834 ----> 0.9430480829602751\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 0\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:36 - Loss0.0119: 100%|██████████| 120/120 [00:48<00:00,  2.48it/s]\n","Valid E:36 - Loss:0.0140: 100%|██████████| 31/31 [00:02<00:00, 15.12it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:33:30 2021 \n","\n","                Fold:1, Epoch:36, lr:0.000184456\n","\n","                Train Loss:0.0119 - LWLRAP:0.9351\n","\n","                Valid Loss:0.0140 - LWLRAP:0.9357\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:37 - Loss0.0113: 100%|██████████| 120/120 [00:49<00:00,  2.42it/s]\n","Valid E:37 - Loss:0.0128: 100%|██████████| 31/31 [00:02<00:00, 15.10it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:34:22 2021 \n","\n","                Fold:1, Epoch:37, lr:0.0001587234\n","\n","                Train Loss:0.0113 - LWLRAP:0.9381\n","\n","                Valid Loss:0.0128 - LWLRAP:0.9438\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9430480829602751 ----> 0.9437963032777329\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:38 - Loss0.0113: 100%|██████████| 120/120 [00:47<00:00,  2.50it/s]\n","Valid E:38 - Loss:0.0140: 100%|██████████| 31/31 [00:02<00:00, 14.95it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:35:13 2021 \n","\n","                Fold:1, Epoch:38, lr:0.000134582\n","\n","                Train Loss:0.0113 - LWLRAP:0.9378\n","\n","                Valid Loss:0.0140 - LWLRAP:0.9404\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:39 - Loss0.0112: 100%|██████████| 120/120 [00:48<00:00,  2.46it/s]\n","Valid E:39 - Loss:0.0135: 100%|██████████| 31/31 [00:02<00:00, 15.10it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:36:04 2021 \n","\n","                Fold:1, Epoch:39, lr:0.0001121444\n","\n","                Train Loss:0.0112 - LWLRAP:0.9411\n","\n","                Valid Loss:0.0135 - LWLRAP:0.9455\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9437963032777329 ----> 0.9454767991965052\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:40 - Loss0.0101: 100%|██████████| 120/120 [00:51<00:00,  2.34it/s]\n","Valid E:40 - Loss:0.0134: 100%|██████████| 31/31 [00:02<00:00, 15.03it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:36:58 2021 \n","\n","                Fold:1, Epoch:40, lr:9.151505e-05\n","\n","                Train Loss:0.0101 - LWLRAP:0.9477\n","\n","                Valid Loss:0.0134 - LWLRAP:0.9433\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 1\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:41 - Loss0.0099: 100%|██████████| 120/120 [00:46<00:00,  2.56it/s]\n","Valid E:41 - Loss:0.0134: 100%|██████████| 31/31 [00:02<00:00, 15.21it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:37:48 2021 \n","\n","                Fold:1, Epoch:41, lr:7.27903e-05\n","\n","                Train Loss:0.0099 - LWLRAP:0.9470\n","\n","                Valid Loss:0.0134 - LWLRAP:0.9432\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:42 - Loss0.0098: 100%|██████████| 120/120 [00:44<00:00,  2.69it/s]\n","Valid E:42 - Loss:0.0136: 100%|██████████| 31/31 [00:02<00:00, 14.96it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:38:35 2021 \n","\n","                Fold:1, Epoch:42, lr:5.605739e-05\n","\n","                Train Loss:0.0098 - LWLRAP:0.9477\n","\n","                Valid Loss:0.0136 - LWLRAP:0.9420\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:43 - Loss0.0091: 100%|██████████| 120/120 [00:48<00:00,  2.46it/s]\n","Valid E:43 - Loss:0.0136: 100%|██████████| 31/31 [00:02<00:00, 15.24it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:39:26 2021 \n","\n","                Fold:1, Epoch:43, lr:4.139435e-05\n","\n","                Train Loss:0.0091 - LWLRAP:0.9539\n","\n","                Valid Loss:0.0136 - LWLRAP:0.9438\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:44 - Loss0.0090: 100%|██████████| 120/120 [00:51<00:00,  2.32it/s]\n","Valid E:44 - Loss:0.0133: 100%|██████████| 31/31 [00:02<00:00, 14.98it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:40:20 2021 \n","\n","                Fold:1, Epoch:44, lr:2.886954e-05\n","\n","                Train Loss:0.0090 - LWLRAP:0.9535\n","\n","                Valid Loss:0.0133 - LWLRAP:0.9447\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:45 - Loss0.0084: 100%|██████████| 120/120 [00:50<00:00,  2.39it/s]\n","Valid E:45 - Loss:0.0138: 100%|██████████| 31/31 [00:02<00:00, 15.04it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:41:12 2021 \n","\n","                Fold:1, Epoch:45, lr:1.854136e-05\n","\n","                Train Loss:0.0084 - LWLRAP:0.9553\n","\n","                Valid Loss:0.0138 - LWLRAP:0.9442\n","\n","        \n","\n"," $$$ ---? Ohoo.... we reached early stoping count : 6\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 498/498 [05:32<00:00,  1.50it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["(1992, 24)\n","weights/bird_mluti_ResNet50_5F_BASE_head1024_framewides_ResampleLoss_2048_512_256_addmask0202_earystop35_batch/fold-1-submission.csv\n","      recording_id species_id  songtype_id  t_min  f_min  t_max  f_max  kfold\n","1     97630c03d_03     0,18,3            1      0   5000    5.2  10000      1\n","3     d9bfc9e6b_02   0,1,3,12            1      0   5000    5.2  10000      1\n","5     d49a94504_02     0,18,3            1      0   5000    5.2  10000      1\n","6     5f9157d7b_01     0,3,18            1      0   5000    5.2  10000      0\n","8     97630c03d_01   0,3,18,7            1      0   5000    5.2  10000      4\n","...            ...        ...          ...    ...    ...    ...    ...    ...\n","2423  59a9eb657_02    23,3,12            1      0   5000    5.2  10000      3\n","2424  6c032e356_01      23,12            1      0   5000    5.2  10000      4\n","2425  006ab765f_05       23,3            1      0   5000    5.2  10000      0\n","2426  79f38de91_02         23            1      0   5000    5.2  10000      4\n","2427  774912d66_03       23,3            1      0   5000    5.2  10000      3\n","\n","[1944 rows x 8 columns]\n","1944\n","[126, 251, 103, 1006, 163, 94, 78, 285, 131, 87, 96, 199, 416, 85, 100, 188, 80, 80, 410, 88, 106, 195, 101, 208]\n","[1818, 1693, 1841, 938, 1781, 1850, 1866, 1659, 1813, 1857, 1848, 1745, 1528, 1859, 1844, 1756, 1864, 1864, 1534, 1856, 1838, 1749, 1843, 1736]\n","{'class_freq': [126, 251, 103, 1006, 163, 94, 78, 285, 131, 87, 96, 199, 416, 85, 100, 188, 80, 80, 410, 88, 106, 195, 101, 208], 'neg_class_freq': [1818, 1693, 1841, 938, 1781, 1850, 1866, 1659, 1813, 1857, 1848, 1745, 1528, 1859, 1844, 1756, 1864, 1864, 1534, 1856, 1838, 1749, 1843, 1736]}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"stream","text":["Loading Microsoft Vision pretrained model\n","Model already downloaded.\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[1;35m loading from ./class_freq.pkl | rebalance | {'neg_scale': 5.0, 'init_bias': 0.1} | s\u001b[0;0m\n","\u001b[1;35m rebalance reweighting mapping params: 10.00 | 0.20 | 0.10 \u001b[0;0m\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:0 - Loss0.3463: 100%|██████████| 121/121 [00:48<00:00,  2.52it/s]\n","Valid E:0 - Loss:0.1309: 100%|██████████| 31/31 [00:02<00:00, 15.08it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:47:41 2021 \n","\n","                Fold:2, Epoch:0, lr:0.0001\n","\n","                Train Loss:0.3463 - LWLRAP:0.3739\n","\n","                Valid Loss:0.1309 - LWLRAP:0.5558\n","\n","        \n","########## >>>>>>>> Model Improved From -inf ----> 0.5557533469087548\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:1 - Loss0.0714: 100%|██████████| 121/121 [00:47<00:00,  2.55it/s]\n","Valid E:1 - Loss:0.0502: 100%|██████████| 31/31 [00:02<00:00, 15.45it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:48:31 2021 \n","\n","                Fold:2, Epoch:1, lr:0.0004\n","\n","                Train Loss:0.0714 - LWLRAP:0.4297\n","\n","                Valid Loss:0.0502 - LWLRAP:0.5414\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:2 - Loss0.0493: 100%|██████████| 121/121 [00:47<00:00,  2.52it/s]\n","Valid E:2 - Loss:0.0395: 100%|██████████| 31/31 [00:02<00:00, 15.20it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:49:22 2021 \n","\n","                Fold:2, Epoch:2, lr:0.0007\n","\n","                Train Loss:0.0493 - LWLRAP:0.4719\n","\n","                Valid Loss:0.0395 - LWLRAP:0.5679\n","\n","        \n","########## >>>>>>>> Model Improved From 0.5557533469087548 ----> 0.567925637472647\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:3 - Loss0.0407: 100%|██████████| 121/121 [00:46<00:00,  2.58it/s]\n","Valid E:3 - Loss:0.0368: 100%|██████████| 31/31 [00:02<00:00, 15.12it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:50:11 2021 \n","\n","                Fold:2, Epoch:3, lr:0.001\n","\n","                Train Loss:0.0407 - LWLRAP:0.5277\n","\n","                Valid Loss:0.0368 - LWLRAP:0.6343\n","\n","        \n","########## >>>>>>>> Model Improved From 0.567925637472647 ----> 0.6342819205702196\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:4 - Loss0.0378: 100%|██████████| 121/121 [00:46<00:00,  2.58it/s]\n","Valid E:4 - Loss:0.0359: 100%|██████████| 31/31 [00:02<00:00, 15.12it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:51:01 2021 \n","\n","                Fold:2, Epoch:4, lr:0.001\n","\n","                Train Loss:0.0378 - LWLRAP:0.5482\n","\n","                Valid Loss:0.0359 - LWLRAP:0.6206\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:5 - Loss0.0353: 100%|██████████| 121/121 [00:47<00:00,  2.55it/s]\n","Valid E:5 - Loss:0.0341: 100%|██████████| 31/31 [00:02<00:00, 15.06it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:51:51 2021 \n","\n","                Fold:2, Epoch:5, lr:0.000995343\n","\n","                Train Loss:0.0353 - LWLRAP:0.5834\n","\n","                Valid Loss:0.0341 - LWLRAP:0.6630\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6342819205702196 ----> 0.6629945604960307\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:6 - Loss0.0343: 100%|██████████| 121/121 [00:51<00:00,  2.36it/s]\n","Valid E:6 - Loss:0.0316: 100%|██████████| 31/31 [00:02<00:00, 15.11it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:52:45 2021 \n","\n","                Fold:2, Epoch:6, lr:0.000989542\n","\n","                Train Loss:0.0343 - LWLRAP:0.5987\n","\n","                Valid Loss:0.0316 - LWLRAP:0.6756\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6629945604960307 ----> 0.6756121109056323\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:7 - Loss0.0328: 100%|██████████| 121/121 [00:51<00:00,  2.34it/s]\n","Valid E:7 - Loss:0.0319: 100%|██████████| 31/31 [00:02<00:00, 15.17it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:53:40 2021 \n","\n","                Fold:2, Epoch:7, lr:0.0009814586\n","\n","                Train Loss:0.0328 - LWLRAP:0.6213\n","\n","                Valid Loss:0.0319 - LWLRAP:0.6805\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6756121109056323 ----> 0.6804858077750907\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:8 - Loss0.0322: 100%|██████████| 121/121 [00:50<00:00,  2.42it/s]\n","Valid E:8 - Loss:0.0309: 100%|██████████| 31/31 [00:02<00:00, 15.19it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:54:32 2021 \n","\n","                Fold:2, Epoch:8, lr:0.0009711305\n","\n","                Train Loss:0.0322 - LWLRAP:0.6380\n","\n","                Valid Loss:0.0309 - LWLRAP:0.6949\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6804858077750907 ----> 0.6949111755430909\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:9 - Loss0.0312: 100%|██████████| 121/121 [00:50<00:00,  2.40it/s]\n","Valid E:9 - Loss:0.0303: 100%|██████████| 31/31 [00:02<00:00, 15.10it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:55:26 2021 \n","\n","                Fold:2, Epoch:9, lr:0.0009586057\n","\n","                Train Loss:0.0312 - LWLRAP:0.6606\n","\n","                Valid Loss:0.0303 - LWLRAP:0.6998\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6949111755430909 ----> 0.6998080874306843\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:10 - Loss0.0319: 100%|██████████| 121/121 [00:47<00:00,  2.56it/s]\n","Valid E:10 - Loss:0.0286: 100%|██████████| 31/31 [00:02<00:00, 14.87it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:56:16 2021 \n","\n","                Fold:2, Epoch:10, lr:0.0009439426\n","\n","                Train Loss:0.0319 - LWLRAP:0.6647\n","\n","                Valid Loss:0.0286 - LWLRAP:0.7207\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6998080874306843 ----> 0.7207023997544695\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:11 - Loss0.0302: 100%|██████████| 121/121 [00:47<00:00,  2.54it/s]\n","Valid E:11 - Loss:0.0289: 100%|██████████| 31/31 [00:02<00:00, 15.17it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:57:06 2021 \n","\n","                Fold:2, Epoch:11, lr:0.0009272097\n","\n","                Train Loss:0.0302 - LWLRAP:0.6806\n","\n","                Valid Loss:0.0289 - LWLRAP:0.7019\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:12 - Loss0.0294: 100%|██████████| 121/121 [00:49<00:00,  2.43it/s]\n","Valid E:12 - Loss:0.0273: 100%|██████████| 31/31 [00:02<00:00, 15.23it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:57:58 2021 \n","\n","                Fold:2, Epoch:12, lr:0.0009084849\n","\n","                Train Loss:0.0294 - LWLRAP:0.6840\n","\n","                Valid Loss:0.0273 - LWLRAP:0.7386\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7207023997544695 ----> 0.7386204321781247\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:13 - Loss0.0284: 100%|██████████| 121/121 [00:45<00:00,  2.65it/s]\n","Valid E:13 - Loss:0.0270: 100%|██████████| 31/31 [00:02<00:00, 15.04it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:58:47 2021 \n","\n","                Fold:2, Epoch:13, lr:0.0008878556\n","\n","                Train Loss:0.0284 - LWLRAP:0.7045\n","\n","                Valid Loss:0.0270 - LWLRAP:0.7514\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7386204321781247 ----> 0.7514399392960226\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:14 - Loss0.0275: 100%|██████████| 121/121 [00:48<00:00,  2.52it/s]\n","Valid E:14 - Loss:0.0250: 100%|██████████| 31/31 [00:02<00:00, 14.92it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 03:59:38 2021 \n","\n","                Fold:2, Epoch:14, lr:0.000865418\n","\n","                Train Loss:0.0275 - LWLRAP:0.7165\n","\n","                Valid Loss:0.0250 - LWLRAP:0.7641\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7514399392960226 ----> 0.7641100697973985\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:15 - Loss0.0261: 100%|██████████| 121/121 [00:51<00:00,  2.34it/s]\n","Valid E:15 - Loss:0.0235: 100%|██████████| 31/31 [00:02<00:00, 15.02it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:00:32 2021 \n","\n","                Fold:2, Epoch:15, lr:0.0008412766\n","\n","                Train Loss:0.0261 - LWLRAP:0.7385\n","\n","                Valid Loss:0.0235 - LWLRAP:0.7991\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7641100697973985 ----> 0.7990614242811308\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:16 - Loss0.0252: 100%|██████████| 121/121 [00:47<00:00,  2.55it/s]\n","Valid E:16 - Loss:0.0241: 100%|██████████| 31/31 [00:02<00:00, 15.17it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:01:23 2021 \n","\n","                Fold:2, Epoch:16, lr:0.000815544\n","\n","                Train Loss:0.0252 - LWLRAP:0.7559\n","\n","                Valid Loss:0.0241 - LWLRAP:0.8166\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7990614242811308 ----> 0.8166456144806037\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:17 - Loss0.0240: 100%|██████████| 121/121 [00:48<00:00,  2.49it/s]\n","Valid E:17 - Loss:0.0211: 100%|██████████| 31/31 [00:02<00:00, 15.00it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:02:14 2021 \n","\n","                Fold:2, Epoch:17, lr:0.0007883402\n","\n","                Train Loss:0.0240 - LWLRAP:0.7828\n","\n","                Valid Loss:0.0211 - LWLRAP:0.8466\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8166456144806037 ----> 0.8466049073721542\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:18 - Loss0.0219: 100%|██████████| 121/121 [00:49<00:00,  2.45it/s]\n","Valid E:18 - Loss:0.0190: 100%|██████████| 31/31 [00:02<00:00, 15.02it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:03:06 2021 \n","\n","                Fold:2, Epoch:18, lr:0.000759792\n","\n","                Train Loss:0.0219 - LWLRAP:0.8118\n","\n","                Valid Loss:0.0190 - LWLRAP:0.8715\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8466049073721542 ----> 0.8714856188151137\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:19 - Loss0.0209: 100%|██████████| 121/121 [00:46<00:00,  2.59it/s]\n","Valid E:19 - Loss:0.0193: 100%|██████████| 31/31 [00:02<00:00, 15.10it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:03:56 2021 \n","\n","                Fold:2, Epoch:19, lr:0.0007300325\n","\n","                Train Loss:0.0209 - LWLRAP:0.8299\n","\n","                Valid Loss:0.0193 - LWLRAP:0.8741\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8714856188151137 ----> 0.8741411218600602\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:20 - Loss0.0192: 100%|██████████| 121/121 [00:47<00:00,  2.52it/s]\n","Valid E:20 - Loss:0.0196: 100%|██████████| 31/31 [00:02<00:00, 14.85it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:04:47 2021 \n","\n","                Fold:2, Epoch:20, lr:0.0006992005\n","\n","                Train Loss:0.0192 - LWLRAP:0.8589\n","\n","                Valid Loss:0.0196 - LWLRAP:0.8824\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8741411218600602 ----> 0.882431400616809\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:21 - Loss0.0181: 100%|██████████| 121/121 [00:48<00:00,  2.49it/s]\n","Valid E:21 - Loss:0.0154: 100%|██████████| 31/31 [00:02<00:00, 14.99it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:05:38 2021 \n","\n","                Fold:2, Epoch:21, lr:0.0006674398\n","\n","                Train Loss:0.0181 - LWLRAP:0.8678\n","\n","                Valid Loss:0.0154 - LWLRAP:0.9140\n","\n","        \n","########## >>>>>>>> Model Improved From 0.882431400616809 ----> 0.9140034237992826\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:22 - Loss0.0175: 100%|██████████| 121/121 [00:47<00:00,  2.53it/s]\n","Valid E:22 - Loss:0.0157: 100%|██████████| 31/31 [00:02<00:00, 14.98it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:06:29 2021 \n","\n","                Fold:2, Epoch:22, lr:0.0006348984\n","\n","                Train Loss:0.0175 - LWLRAP:0.8819\n","\n","                Valid Loss:0.0157 - LWLRAP:0.9163\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9140034237992826 ----> 0.9162860128511361\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:23 - Loss0.0163: 100%|██████████| 121/121 [00:49<00:00,  2.45it/s]\n","Valid E:23 - Loss:0.0154: 100%|██████████| 31/31 [00:02<00:00, 15.05it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:07:21 2021 \n","\n","                Fold:2, Epoch:23, lr:0.000601728\n","\n","                Train Loss:0.0163 - LWLRAP:0.8928\n","\n","                Valid Loss:0.0154 - LWLRAP:0.9156\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:24 - Loss0.0153: 100%|██████████| 121/121 [00:46<00:00,  2.60it/s]\n","Valid E:24 - Loss:0.0141: 100%|██████████| 31/31 [00:02<00:00, 15.07it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:08:10 2021 \n","\n","                Fold:2, Epoch:24, lr:0.0005680833\n","\n","                Train Loss:0.0153 - LWLRAP:0.9012\n","\n","                Valid Loss:0.0141 - LWLRAP:0.9270\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9162860128511361 ----> 0.9269783013455664\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:25 - Loss0.0150: 100%|██████████| 121/121 [00:52<00:00,  2.32it/s]\n","Valid E:25 - Loss:0.0137: 100%|██████████| 31/31 [00:02<00:00, 15.18it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:09:05 2021 \n","\n","                Fold:2, Epoch:25, lr:0.0005341212\n","\n","                Train Loss:0.0150 - LWLRAP:0.9083\n","\n","                Valid Loss:0.0137 - LWLRAP:0.9308\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9269783013455664 ----> 0.9308401018608258\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:26 - Loss0.0142: 100%|██████████| 121/121 [00:49<00:00,  2.45it/s]\n","Valid E:26 - Loss:0.0142: 100%|██████████| 31/31 [00:02<00:00, 14.94it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:09:57 2021 \n","\n","                Fold:2, Epoch:26, lr:0.0005\n","\n","                Train Loss:0.0142 - LWLRAP:0.9138\n","\n","                Valid Loss:0.0142 - LWLRAP:0.9306\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:27 - Loss0.0133: 100%|██████████| 121/121 [00:47<00:00,  2.53it/s]\n","Valid E:27 - Loss:0.0132: 100%|██████████| 31/31 [00:02<00:00, 15.15it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:10:47 2021 \n","\n","                Fold:2, Epoch:27, lr:0.0004658788\n","\n","                Train Loss:0.0133 - LWLRAP:0.9199\n","\n","                Valid Loss:0.0132 - LWLRAP:0.9406\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9308401018608258 ----> 0.9405575620901953\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:28 - Loss0.0134: 100%|██████████| 121/121 [00:50<00:00,  2.40it/s]\n","Valid E:28 - Loss:0.0130: 100%|██████████| 31/31 [00:02<00:00, 15.03it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:11:40 2021 \n","\n","                Fold:2, Epoch:28, lr:0.0004319167\n","\n","                Train Loss:0.0134 - LWLRAP:0.9207\n","\n","                Valid Loss:0.0130 - LWLRAP:0.9373\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:29 - Loss0.0127: 100%|██████████| 121/121 [00:47<00:00,  2.57it/s]\n","Valid E:29 - Loss:0.0134: 100%|██████████| 31/31 [00:02<00:00, 14.99it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:12:30 2021 \n","\n","                Fold:2, Epoch:29, lr:0.000398272\n","\n","                Train Loss:0.0127 - LWLRAP:0.9277\n","\n","                Valid Loss:0.0134 - LWLRAP:0.9360\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:30 - Loss0.0119: 100%|██████████| 121/121 [00:48<00:00,  2.51it/s]\n","Valid E:30 - Loss:0.0131: 100%|██████████| 31/31 [00:02<00:00, 14.99it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:13:20 2021 \n","\n","                Fold:2, Epoch:30, lr:0.0003651016\n","\n","                Train Loss:0.0119 - LWLRAP:0.9319\n","\n","                Valid Loss:0.0131 - LWLRAP:0.9347\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 3\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:31 - Loss0.0115: 100%|██████████| 121/121 [00:47<00:00,  2.55it/s]\n","Valid E:31 - Loss:0.0128: 100%|██████████| 31/31 [00:02<00:00, 15.20it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:14:11 2021 \n","\n","                Fold:2, Epoch:31, lr:0.0003325602\n","\n","                Train Loss:0.0115 - LWLRAP:0.9337\n","\n","                Valid Loss:0.0128 - LWLRAP:0.9436\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9405575620901953 ----> 0.9435798018096816\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:32 - Loss0.0116: 100%|██████████| 121/121 [00:49<00:00,  2.43it/s]\n","Valid E:32 - Loss:0.0132: 100%|██████████| 31/31 [00:02<00:00, 14.92it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:15:03 2021 \n","\n","                Fold:2, Epoch:32, lr:0.0003007995\n","\n","                Train Loss:0.0116 - LWLRAP:0.9345\n","\n","                Valid Loss:0.0132 - LWLRAP:0.9366\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:33 - Loss0.0112: 100%|██████████| 121/121 [00:47<00:00,  2.53it/s]\n","Valid E:33 - Loss:0.0136: 100%|██████████| 31/31 [00:02<00:00, 14.83it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:15:53 2021 \n","\n","                Fold:2, Epoch:33, lr:0.0002699675\n","\n","                Train Loss:0.0112 - LWLRAP:0.9405\n","\n","                Valid Loss:0.0136 - LWLRAP:0.9340\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:34 - Loss0.0114: 100%|██████████| 121/121 [00:51<00:00,  2.35it/s]\n","Valid E:34 - Loss:0.0133: 100%|██████████| 31/31 [00:02<00:00, 14.77it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:16:47 2021 \n","\n","                Fold:2, Epoch:34, lr:0.000240208\n","\n","                Train Loss:0.0114 - LWLRAP:0.9352\n","\n","                Valid Loss:0.0133 - LWLRAP:0.9434\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:35 - Loss0.0109: 100%|██████████| 121/121 [00:52<00:00,  2.32it/s]\n","Valid E:35 - Loss:0.0136: 100%|██████████| 31/31 [00:02<00:00, 14.92it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:17:42 2021 \n","\n","                Fold:2, Epoch:35, lr:0.0002116598\n","\n","                Train Loss:0.0109 - LWLRAP:0.9405\n","\n","                Valid Loss:0.0136 - LWLRAP:0.9382\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 4\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:36 - Loss0.0137: 100%|██████████| 121/121 [00:48<00:00,  2.48it/s]\n","Valid E:36 - Loss:0.0126: 100%|██████████| 31/31 [00:02<00:00, 15.01it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:18:33 2021 \n","\n","                Fold:2, Epoch:36, lr:0.000184456\n","\n","                Train Loss:0.0137 - LWLRAP:0.9212\n","\n","                Valid Loss:0.0126 - LWLRAP:0.9439\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9435798018096816 ----> 0.9439032785137234\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:37 - Loss0.0113: 100%|██████████| 121/121 [00:49<00:00,  2.46it/s]\n","Valid E:37 - Loss:0.0125: 100%|██████████| 31/31 [00:02<00:00, 15.08it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:19:26 2021 \n","\n","                Fold:2, Epoch:37, lr:0.0001587234\n","\n","                Train Loss:0.0113 - LWLRAP:0.9349\n","\n","                Valid Loss:0.0125 - LWLRAP:0.9411\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:38 - Loss0.0101: 100%|██████████| 121/121 [00:45<00:00,  2.66it/s]\n","Valid E:38 - Loss:0.0130: 100%|██████████| 31/31 [00:02<00:00, 15.11it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:20:13 2021 \n","\n","                Fold:2, Epoch:38, lr:0.000134582\n","\n","                Train Loss:0.0101 - LWLRAP:0.9481\n","\n","                Valid Loss:0.0130 - LWLRAP:0.9428\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:39 - Loss0.0096: 100%|██████████| 121/121 [00:50<00:00,  2.41it/s]\n","Valid E:39 - Loss:0.0123: 100%|██████████| 31/31 [00:02<00:00, 14.77it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:21:06 2021 \n","\n","                Fold:2, Epoch:39, lr:0.0001121444\n","\n","                Train Loss:0.0096 - LWLRAP:0.9503\n","\n","                Valid Loss:0.0123 - LWLRAP:0.9480\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9439032785137234 ----> 0.9480022233922679\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:40 - Loss0.0093: 100%|██████████| 121/121 [00:49<00:00,  2.45it/s]\n","Valid E:40 - Loss:0.0128: 100%|██████████| 31/31 [00:02<00:00, 15.00it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:21:58 2021 \n","\n","                Fold:2, Epoch:40, lr:9.151505e-05\n","\n","                Train Loss:0.0093 - LWLRAP:0.9511\n","\n","                Valid Loss:0.0128 - LWLRAP:0.9476\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 1\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:41 - Loss0.0087: 100%|██████████| 121/121 [00:47<00:00,  2.55it/s]\n","Valid E:41 - Loss:0.0126: 100%|██████████| 31/31 [00:02<00:00, 15.04it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:22:48 2021 \n","\n","                Fold:2, Epoch:41, lr:7.27903e-05\n","\n","                Train Loss:0.0087 - LWLRAP:0.9570\n","\n","                Valid Loss:0.0126 - LWLRAP:0.9465\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:42 - Loss0.0081: 100%|██████████| 121/121 [00:52<00:00,  2.33it/s]\n","Valid E:42 - Loss:0.0129: 100%|██████████| 31/31 [00:02<00:00, 15.09it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:23:43 2021 \n","\n","                Fold:2, Epoch:42, lr:5.605739e-05\n","\n","                Train Loss:0.0081 - LWLRAP:0.9581\n","\n","                Valid Loss:0.0129 - LWLRAP:0.9461\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:43 - Loss0.0079: 100%|██████████| 121/121 [00:49<00:00,  2.42it/s]\n","Valid E:43 - Loss:0.0130: 100%|██████████| 31/31 [00:02<00:00, 14.96it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:24:35 2021 \n","\n","                Fold:2, Epoch:43, lr:4.139435e-05\n","\n","                Train Loss:0.0079 - LWLRAP:0.9600\n","\n","                Valid Loss:0.0130 - LWLRAP:0.9467\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:44 - Loss0.0075: 100%|██████████| 121/121 [00:51<00:00,  2.36it/s]\n","Valid E:44 - Loss:0.0132: 100%|██████████| 31/31 [00:02<00:00, 14.76it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:25:29 2021 \n","\n","                Fold:2, Epoch:44, lr:2.886954e-05\n","\n","                Train Loss:0.0075 - LWLRAP:0.9626\n","\n","                Valid Loss:0.0132 - LWLRAP:0.9495\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9480022233922679 ----> 0.9495196610938502\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:45 - Loss0.0073: 100%|██████████| 121/121 [00:48<00:00,  2.51it/s]\n","Valid E:45 - Loss:0.0132: 100%|██████████| 31/31 [00:02<00:00, 14.81it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:26:20 2021 \n","\n","                Fold:2, Epoch:45, lr:1.854136e-05\n","\n","                Train Loss:0.0073 - LWLRAP:0.9663\n","\n","                Valid Loss:0.0132 - LWLRAP:0.9482\n","\n","        \n","\n"," $$$ ---? Ohoo.... we reached early stoping count : 1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 498/498 [05:34<00:00,  1.49it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["(1992, 24)\n","weights/bird_mluti_ResNet50_5F_BASE_head1024_framewides_ResampleLoss_2048_512_256_addmask0202_earystop35_batch/fold-2-submission.csv\n","      recording_id  species_id  songtype_id  t_min  f_min  t_max  f_max  kfold\n","0     d49a94504_01        0,18            1      0   5000    5.2  10000      2\n","1     97630c03d_03      0,18,3            1      0   5000    5.2  10000      1\n","2     97630c03d_02      0,18,3            1      0   5000    5.2  10000      2\n","3     d9bfc9e6b_02    0,1,3,12            1      0   5000    5.2  10000      1\n","4     3710abba6_02        0,18            1      0   5000    5.2  10000      2\n","...            ...         ...          ...    ...    ...    ...    ...    ...\n","2421  d8b7f9ed6_01      23,5,3            1      0   5000    5.2  10000      1\n","2422  59a9eb657_03  23,3,12,18            1      0   5000    5.2  10000      1\n","2424  6c032e356_01       23,12            1      0   5000    5.2  10000      4\n","2425  006ab765f_05        23,3            1      0   5000    5.2  10000      0\n","2426  79f38de91_02          23            1      0   5000    5.2  10000      4\n","\n","[1947 rows x 8 columns]\n","1947\n","[125, 251, 103, 1005, 163, 95, 78, 286, 131, 87, 96, 199, 416, 85, 100, 188, 80, 80, 410, 88, 106, 194, 100, 208]\n","[1822, 1696, 1844, 942, 1784, 1852, 1869, 1661, 1816, 1860, 1851, 1748, 1531, 1862, 1847, 1759, 1867, 1867, 1537, 1859, 1841, 1753, 1847, 1739]\n","{'class_freq': [125, 251, 103, 1005, 163, 95, 78, 286, 131, 87, 96, 199, 416, 85, 100, 188, 80, 80, 410, 88, 106, 194, 100, 208], 'neg_class_freq': [1822, 1696, 1844, 942, 1784, 1852, 1869, 1661, 1816, 1860, 1851, 1748, 1531, 1862, 1847, 1759, 1867, 1867, 1537, 1859, 1841, 1753, 1847, 1739]}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"stream","text":["Loading Microsoft Vision pretrained model\n","Model already downloaded.\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[1;35m loading from ./class_freq.pkl | rebalance | {'neg_scale': 5.0, 'init_bias': 0.1} | s\u001b[0;0m\n","\u001b[1;35m rebalance reweighting mapping params: 10.00 | 0.20 | 0.10 \u001b[0;0m\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:0 - Loss0.3539: 100%|██████████| 121/121 [00:48<00:00,  2.47it/s]\n","Valid E:0 - Loss:0.0889: 100%|██████████| 30/30 [00:03<00:00,  8.44it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:32:53 2021 \n","\n","                Fold:3, Epoch:0, lr:0.0001\n","\n","                Train Loss:0.3539 - LWLRAP:0.3752\n","\n","                Valid Loss:0.0889 - LWLRAP:0.5497\n","\n","        \n","########## >>>>>>>> Model Improved From -inf ----> 0.5497077761379895\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:1 - Loss0.0566: 100%|██████████| 121/121 [00:47<00:00,  2.56it/s]\n","Valid E:1 - Loss:0.0432: 100%|██████████| 30/30 [00:02<00:00, 14.34it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:33:43 2021 \n","\n","                Fold:3, Epoch:1, lr:0.0004\n","\n","                Train Loss:0.0566 - LWLRAP:0.4473\n","\n","                Valid Loss:0.0432 - LWLRAP:0.5630\n","\n","        \n","########## >>>>>>>> Model Improved From 0.5497077761379895 ----> 0.5630446705370241\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:2 - Loss0.0450: 100%|██████████| 121/121 [00:46<00:00,  2.60it/s]\n","Valid E:2 - Loss:0.0386: 100%|██████████| 30/30 [00:02<00:00, 14.72it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:34:32 2021 \n","\n","                Fold:3, Epoch:2, lr:0.0007\n","\n","                Train Loss:0.0450 - LWLRAP:0.4915\n","\n","                Valid Loss:0.0386 - LWLRAP:0.5851\n","\n","        \n","########## >>>>>>>> Model Improved From 0.5630446705370241 ----> 0.5850524521318643\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:3 - Loss0.0402: 100%|██████████| 121/121 [00:48<00:00,  2.51it/s]\n","Valid E:3 - Loss:0.0352: 100%|██████████| 30/30 [00:02<00:00, 14.84it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:35:23 2021 \n","\n","                Fold:3, Epoch:3, lr:0.001\n","\n","                Train Loss:0.0402 - LWLRAP:0.5270\n","\n","                Valid Loss:0.0352 - LWLRAP:0.6180\n","\n","        \n","########## >>>>>>>> Model Improved From 0.5850524521318643 ----> 0.6179651540765694\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:4 - Loss0.0361: 100%|██████████| 121/121 [00:48<00:00,  2.52it/s]\n","Valid E:4 - Loss:0.0337: 100%|██████████| 30/30 [00:02<00:00, 14.60it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:36:14 2021 \n","\n","                Fold:3, Epoch:4, lr:0.001\n","\n","                Train Loss:0.0361 - LWLRAP:0.5671\n","\n","                Valid Loss:0.0337 - LWLRAP:0.6511\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6179651540765694 ----> 0.6510591958087356\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:5 - Loss0.0343: 100%|██████████| 121/121 [00:47<00:00,  2.56it/s]\n","Valid E:5 - Loss:0.0333: 100%|██████████| 30/30 [00:02<00:00, 14.63it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:37:04 2021 \n","\n","                Fold:3, Epoch:5, lr:0.000995343\n","\n","                Train Loss:0.0343 - LWLRAP:0.5962\n","\n","                Valid Loss:0.0333 - LWLRAP:0.6628\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6510591958087356 ----> 0.6628314354937933\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:6 - Loss0.0335: 100%|██████████| 121/121 [00:52<00:00,  2.32it/s]\n","Valid E:6 - Loss:0.0319: 100%|██████████| 30/30 [00:02<00:00, 14.67it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:37:59 2021 \n","\n","                Fold:3, Epoch:6, lr:0.000989542\n","\n","                Train Loss:0.0335 - LWLRAP:0.6092\n","\n","                Valid Loss:0.0319 - LWLRAP:0.6749\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6628314354937933 ----> 0.6749061034716447\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:7 - Loss0.0322: 100%|██████████| 121/121 [00:47<00:00,  2.56it/s]\n","Valid E:7 - Loss:0.0311: 100%|██████████| 30/30 [00:02<00:00, 14.74it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:38:49 2021 \n","\n","                Fold:3, Epoch:7, lr:0.0009814586\n","\n","                Train Loss:0.0322 - LWLRAP:0.6359\n","\n","                Valid Loss:0.0311 - LWLRAP:0.6837\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6749061034716447 ----> 0.6836853879295173\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:8 - Loss0.0311: 100%|██████████| 121/121 [00:48<00:00,  2.49it/s]\n","Valid E:8 - Loss:0.0301: 100%|██████████| 30/30 [00:02<00:00, 14.50it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:39:41 2021 \n","\n","                Fold:3, Epoch:8, lr:0.0009711305\n","\n","                Train Loss:0.0311 - LWLRAP:0.6614\n","\n","                Valid Loss:0.0301 - LWLRAP:0.7034\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6836853879295173 ----> 0.703441797904602\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:9 - Loss0.0304: 100%|██████████| 121/121 [00:48<00:00,  2.49it/s]\n","Valid E:9 - Loss:0.0283: 100%|██████████| 30/30 [00:02<00:00, 14.80it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:40:32 2021 \n","\n","                Fold:3, Epoch:9, lr:0.0009586057\n","\n","                Train Loss:0.0304 - LWLRAP:0.6751\n","\n","                Valid Loss:0.0283 - LWLRAP:0.7478\n","\n","        \n","########## >>>>>>>> Model Improved From 0.703441797904602 ----> 0.7478252765156879\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:10 - Loss0.0291: 100%|██████████| 121/121 [00:49<00:00,  2.45it/s]\n","Valid E:10 - Loss:0.0264: 100%|██████████| 30/30 [00:02<00:00, 14.56it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:41:25 2021 \n","\n","                Fold:3, Epoch:10, lr:0.0009439426\n","\n","                Train Loss:0.0291 - LWLRAP:0.6955\n","\n","                Valid Loss:0.0264 - LWLRAP:0.7673\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7478252765156879 ----> 0.7673178724942293\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:11 - Loss0.0333: 100%|██████████| 121/121 [00:51<00:00,  2.36it/s]\n","Valid E:11 - Loss:0.0299: 100%|██████████| 30/30 [00:02<00:00, 14.70it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:42:19 2021 \n","\n","                Fold:3, Epoch:11, lr:0.0009272097\n","\n","                Train Loss:0.0333 - LWLRAP:0.6319\n","\n","                Valid Loss:0.0299 - LWLRAP:0.7192\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:12 - Loss0.0304: 100%|██████████| 121/121 [00:50<00:00,  2.39it/s]\n","Valid E:12 - Loss:0.0283: 100%|██████████| 30/30 [00:02<00:00, 14.46it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:43:12 2021 \n","\n","                Fold:3, Epoch:12, lr:0.0009084849\n","\n","                Train Loss:0.0304 - LWLRAP:0.6727\n","\n","                Valid Loss:0.0283 - LWLRAP:0.7315\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:13 - Loss0.0289: 100%|██████████| 121/121 [00:46<00:00,  2.62it/s]\n","Valid E:13 - Loss:0.0256: 100%|██████████| 30/30 [00:02<00:00, 14.72it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:44:00 2021 \n","\n","                Fold:3, Epoch:13, lr:0.0008878556\n","\n","                Train Loss:0.0289 - LWLRAP:0.7028\n","\n","                Valid Loss:0.0256 - LWLRAP:0.7725\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7673178724942293 ----> 0.7725111066938248\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:14 - Loss0.0276: 100%|██████████| 121/121 [00:49<00:00,  2.46it/s]\n","Valid E:14 - Loss:0.0250: 100%|██████████| 30/30 [00:02<00:00, 14.72it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:44:52 2021 \n","\n","                Fold:3, Epoch:14, lr:0.000865418\n","\n","                Train Loss:0.0276 - LWLRAP:0.7235\n","\n","                Valid Loss:0.0250 - LWLRAP:0.7823\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7725111066938248 ----> 0.7822691421205987\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:15 - Loss0.0271: 100%|██████████| 121/121 [00:48<00:00,  2.48it/s]\n","Valid E:15 - Loss:0.0243: 100%|██████████| 30/30 [00:02<00:00, 14.54it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:45:44 2021 \n","\n","                Fold:3, Epoch:15, lr:0.0008412766\n","\n","                Train Loss:0.0271 - LWLRAP:0.7367\n","\n","                Valid Loss:0.0243 - LWLRAP:0.8043\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7822691421205987 ----> 0.8043160687843894\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:16 - Loss0.0259: 100%|██████████| 121/121 [00:48<00:00,  2.47it/s]\n","Valid E:16 - Loss:0.0227: 100%|██████████| 30/30 [00:02<00:00, 14.58it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:46:36 2021 \n","\n","                Fold:3, Epoch:16, lr:0.000815544\n","\n","                Train Loss:0.0259 - LWLRAP:0.7546\n","\n","                Valid Loss:0.0227 - LWLRAP:0.8202\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8043160687843894 ----> 0.8201510033229942\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:17 - Loss0.0246: 100%|██████████| 121/121 [00:47<00:00,  2.52it/s]\n","Valid E:17 - Loss:0.0226: 100%|██████████| 30/30 [00:02<00:00, 14.54it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:47:26 2021 \n","\n","                Fold:3, Epoch:17, lr:0.0007883402\n","\n","                Train Loss:0.0246 - LWLRAP:0.7804\n","\n","                Valid Loss:0.0226 - LWLRAP:0.8168\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:18 - Loss0.0235: 100%|██████████| 121/121 [00:47<00:00,  2.53it/s]\n","Valid E:18 - Loss:0.0209: 100%|██████████| 30/30 [00:02<00:00, 14.58it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:48:17 2021 \n","\n","                Fold:3, Epoch:18, lr:0.000759792\n","\n","                Train Loss:0.0235 - LWLRAP:0.7951\n","\n","                Valid Loss:0.0209 - LWLRAP:0.8423\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8201510033229942 ----> 0.8423265711983583\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:19 - Loss0.0221: 100%|██████████| 121/121 [00:49<00:00,  2.46it/s]\n","Valid E:19 - Loss:0.0201: 100%|██████████| 30/30 [00:02<00:00, 14.75it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:49:09 2021 \n","\n","                Fold:3, Epoch:19, lr:0.0007300325\n","\n","                Train Loss:0.0221 - LWLRAP:0.8137\n","\n","                Valid Loss:0.0201 - LWLRAP:0.8582\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8423265711983583 ----> 0.85815330336812\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:20 - Loss0.0213: 100%|██████████| 121/121 [00:52<00:00,  2.29it/s]\n","Valid E:20 - Loss:0.0172: 100%|██████████| 30/30 [00:02<00:00, 14.72it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:50:04 2021 \n","\n","                Fold:3, Epoch:20, lr:0.0006992005\n","\n","                Train Loss:0.0213 - LWLRAP:0.8295\n","\n","                Valid Loss:0.0172 - LWLRAP:0.8971\n","\n","        \n","########## >>>>>>>> Model Improved From 0.85815330336812 ----> 0.8970678251810807\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:21 - Loss0.0194: 100%|██████████| 121/121 [00:52<00:00,  2.30it/s]\n","Valid E:21 - Loss:0.0158: 100%|██████████| 30/30 [00:02<00:00, 14.45it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:51:00 2021 \n","\n","                Fold:3, Epoch:21, lr:0.0006674398\n","\n","                Train Loss:0.0194 - LWLRAP:0.8537\n","\n","                Valid Loss:0.0158 - LWLRAP:0.9156\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8970678251810807 ----> 0.9156395036892114\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:22 - Loss0.0185: 100%|██████████| 121/121 [00:50<00:00,  2.39it/s]\n","Valid E:22 - Loss:0.0154: 100%|██████████| 30/30 [00:02<00:00, 14.65it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:51:53 2021 \n","\n","                Fold:3, Epoch:22, lr:0.0006348984\n","\n","                Train Loss:0.0185 - LWLRAP:0.8656\n","\n","                Valid Loss:0.0154 - LWLRAP:0.9099\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:23 - Loss0.0172: 100%|██████████| 121/121 [00:50<00:00,  2.40it/s]\n","Valid E:23 - Loss:0.0159: 100%|██████████| 30/30 [00:02<00:00, 14.70it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:52:46 2021 \n","\n","                Fold:3, Epoch:23, lr:0.000601728\n","\n","                Train Loss:0.0172 - LWLRAP:0.8845\n","\n","                Valid Loss:0.0159 - LWLRAP:0.9176\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9156395036892114 ----> 0.9176461528349948\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:24 - Loss0.0166: 100%|██████████| 121/121 [00:47<00:00,  2.57it/s]\n","Valid E:24 - Loss:0.0150: 100%|██████████| 30/30 [00:02<00:00, 14.53it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:53:36 2021 \n","\n","                Fold:3, Epoch:24, lr:0.0005680833\n","\n","                Train Loss:0.0166 - LWLRAP:0.8884\n","\n","                Valid Loss:0.0150 - LWLRAP:0.9225\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9176461528349948 ----> 0.9224970499681748\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:25 - Loss0.0333: 100%|██████████| 121/121 [00:51<00:00,  2.34it/s]\n","Valid E:25 - Loss:0.0418: 100%|██████████| 30/30 [00:02<00:00, 14.55it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:54:31 2021 \n","\n","                Fold:3, Epoch:25, lr:0.0005341212\n","\n","                Train Loss:0.0333 - LWLRAP:0.6579\n","\n","                Valid Loss:0.0418 - LWLRAP:0.5126\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:26 - Loss0.0341: 100%|██████████| 121/121 [00:49<00:00,  2.43it/s]\n","Valid E:26 - Loss:0.0311: 100%|██████████| 30/30 [00:02<00:00, 14.45it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:55:23 2021 \n","\n","                Fold:3, Epoch:26, lr:0.0005\n","\n","                Train Loss:0.0341 - LWLRAP:0.6014\n","\n","                Valid Loss:0.0311 - LWLRAP:0.6996\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:27 - Loss0.0304: 100%|██████████| 121/121 [00:47<00:00,  2.56it/s]\n","Valid E:27 - Loss:0.0280: 100%|██████████| 30/30 [00:02<00:00, 14.28it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:56:13 2021 \n","\n","                Fold:3, Epoch:27, lr:0.0004658788\n","\n","                Train Loss:0.0304 - LWLRAP:0.6770\n","\n","                Valid Loss:0.0280 - LWLRAP:0.7402\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:28 - Loss0.0279: 100%|██████████| 121/121 [00:52<00:00,  2.30it/s]\n","Valid E:28 - Loss:0.0253: 100%|██████████| 30/30 [00:02<00:00, 14.36it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:57:08 2021 \n","\n","                Fold:3, Epoch:28, lr:0.0004319167\n","\n","                Train Loss:0.0279 - LWLRAP:0.7236\n","\n","                Valid Loss:0.0253 - LWLRAP:0.7902\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:29 - Loss0.0257: 100%|██████████| 121/121 [00:52<00:00,  2.29it/s]\n","Valid E:29 - Loss:0.0237: 100%|██████████| 30/30 [00:02<00:00, 14.42it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:58:03 2021 \n","\n","                Fold:3, Epoch:29, lr:0.000398272\n","\n","                Train Loss:0.0257 - LWLRAP:0.7557\n","\n","                Valid Loss:0.0237 - LWLRAP:0.8155\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:30 - Loss0.0244: 100%|██████████| 121/121 [00:52<00:00,  2.32it/s]\n","Valid E:30 - Loss:0.0213: 100%|██████████| 30/30 [00:02<00:00, 14.41it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:58:57 2021 \n","\n","                Fold:3, Epoch:30, lr:0.0003651016\n","\n","                Train Loss:0.0244 - LWLRAP:0.7850\n","\n","                Valid Loss:0.0213 - LWLRAP:0.8515\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 6\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:31 - Loss0.0230: 100%|██████████| 121/121 [00:54<00:00,  2.23it/s]\n","Valid E:31 - Loss:0.0191: 100%|██████████| 30/30 [00:02<00:00, 14.55it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 04:59:54 2021 \n","\n","                Fold:3, Epoch:31, lr:0.0003325602\n","\n","                Train Loss:0.0230 - LWLRAP:0.8111\n","\n","                Valid Loss:0.0191 - LWLRAP:0.8756\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:32 - Loss0.0215: 100%|██████████| 121/121 [00:50<00:00,  2.40it/s]\n","Valid E:32 - Loss:0.0179: 100%|██████████| 30/30 [00:02<00:00, 14.60it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:00:47 2021 \n","\n","                Fold:3, Epoch:32, lr:0.0003007995\n","\n","                Train Loss:0.0215 - LWLRAP:0.8336\n","\n","                Valid Loss:0.0179 - LWLRAP:0.8898\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:33 - Loss0.0197: 100%|██████████| 121/121 [00:50<00:00,  2.40it/s]\n","Valid E:33 - Loss:0.0166: 100%|██████████| 30/30 [00:02<00:00, 14.06it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:01:40 2021 \n","\n","                Fold:3, Epoch:33, lr:0.0002699675\n","\n","                Train Loss:0.0197 - LWLRAP:0.8592\n","\n","                Valid Loss:0.0166 - LWLRAP:0.9030\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:34 - Loss0.0183: 100%|██████████| 121/121 [00:51<00:00,  2.37it/s]\n","Valid E:34 - Loss:0.0156: 100%|██████████| 30/30 [00:02<00:00, 14.40it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:02:34 2021 \n","\n","                Fold:3, Epoch:34, lr:0.000240208\n","\n","                Train Loss:0.0183 - LWLRAP:0.8762\n","\n","                Valid Loss:0.0156 - LWLRAP:0.9092\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:35 - Loss0.0172: 100%|██████████| 121/121 [00:50<00:00,  2.41it/s]\n","Valid E:35 - Loss:0.0150: 100%|██████████| 30/30 [00:02<00:00, 14.26it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:03:26 2021 \n","\n","                Fold:3, Epoch:35, lr:0.0002116598\n","\n","                Train Loss:0.0172 - LWLRAP:0.8856\n","\n","                Valid Loss:0.0150 - LWLRAP:0.9191\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 11\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:36 - Loss0.0163: 100%|██████████| 121/121 [00:47<00:00,  2.57it/s]\n","Valid E:36 - Loss:0.0138: 100%|██████████| 30/30 [00:02<00:00, 14.35it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:04:16 2021 \n","\n","                Fold:3, Epoch:36, lr:0.000184456\n","\n","                Train Loss:0.0163 - LWLRAP:0.8929\n","\n","                Valid Loss:0.0138 - LWLRAP:0.9286\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9224970499681748 ----> 0.9286031646134086\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:37 - Loss0.0162: 100%|██████████| 121/121 [00:52<00:00,  2.31it/s]\n","Valid E:37 - Loss:0.0141: 100%|██████████| 30/30 [00:02<00:00, 14.58it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:05:11 2021 \n","\n","                Fold:3, Epoch:37, lr:0.0001587234\n","\n","                Train Loss:0.0162 - LWLRAP:0.8934\n","\n","                Valid Loss:0.0141 - LWLRAP:0.9316\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9286031646134086 ----> 0.9316262525240521\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:38 - Loss0.0149: 100%|██████████| 121/121 [00:48<00:00,  2.50it/s]\n","Valid E:38 - Loss:0.0130: 100%|██████████| 30/30 [00:02<00:00, 14.37it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:06:03 2021 \n","\n","                Fold:3, Epoch:38, lr:0.000134582\n","\n","                Train Loss:0.0149 - LWLRAP:0.9089\n","\n","                Valid Loss:0.0130 - LWLRAP:0.9416\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9316262525240521 ----> 0.9416113909377382\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:39 - Loss0.0144: 100%|██████████| 121/121 [00:49<00:00,  2.43it/s]\n","Valid E:39 - Loss:0.0137: 100%|██████████| 30/30 [00:02<00:00, 14.28it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:06:55 2021 \n","\n","                Fold:3, Epoch:39, lr:0.0001121444\n","\n","                Train Loss:0.0144 - LWLRAP:0.9115\n","\n","                Valid Loss:0.0137 - LWLRAP:0.9327\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:40 - Loss0.0141: 100%|██████████| 121/121 [00:48<00:00,  2.47it/s]\n","Valid E:40 - Loss:0.0127: 100%|██████████| 30/30 [00:02<00:00, 14.52it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:07:47 2021 \n","\n","                Fold:3, Epoch:40, lr:9.151505e-05\n","\n","                Train Loss:0.0141 - LWLRAP:0.9153\n","\n","                Valid Loss:0.0127 - LWLRAP:0.9465\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9416113909377382 ----> 0.9464830009178725\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 0\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:41 - Loss0.0141: 100%|██████████| 121/121 [00:54<00:00,  2.22it/s]\n","Valid E:41 - Loss:0.0128: 100%|██████████| 30/30 [00:02<00:00, 14.43it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:08:45 2021 \n","\n","                Fold:3, Epoch:41, lr:7.27903e-05\n","\n","                Train Loss:0.0141 - LWLRAP:0.9150\n","\n","                Valid Loss:0.0128 - LWLRAP:0.9432\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:42 - Loss0.0133: 100%|██████████| 121/121 [00:54<00:00,  2.21it/s]\n","Valid E:42 - Loss:0.0128: 100%|██████████| 30/30 [00:02<00:00, 14.31it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:09:42 2021 \n","\n","                Fold:3, Epoch:42, lr:5.605739e-05\n","\n","                Train Loss:0.0133 - LWLRAP:0.9221\n","\n","                Valid Loss:0.0128 - LWLRAP:0.9464\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:43 - Loss0.0133: 100%|██████████| 121/121 [00:52<00:00,  2.30it/s]\n","Valid E:43 - Loss:0.0125: 100%|██████████| 30/30 [00:02<00:00, 14.42it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:10:37 2021 \n","\n","                Fold:3, Epoch:43, lr:4.139435e-05\n","\n","                Train Loss:0.0133 - LWLRAP:0.9215\n","\n","                Valid Loss:0.0125 - LWLRAP:0.9452\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:44 - Loss0.0128: 100%|██████████| 121/121 [00:48<00:00,  2.49it/s]\n","Valid E:44 - Loss:0.0129: 100%|██████████| 30/30 [00:02<00:00, 14.39it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/121 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:11:28 2021 \n","\n","                Fold:3, Epoch:44, lr:2.886954e-05\n","\n","                Train Loss:0.0128 - LWLRAP:0.9281\n","\n","                Valid Loss:0.0129 - LWLRAP:0.9442\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:45 - Loss0.0122: 100%|██████████| 121/121 [00:48<00:00,  2.50it/s]\n","Valid E:45 - Loss:0.0124: 100%|██████████| 30/30 [00:02<00:00, 14.28it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:12:19 2021 \n","\n","                Fold:3, Epoch:45, lr:1.854136e-05\n","\n","                Train Loss:0.0122 - LWLRAP:0.9296\n","\n","                Valid Loss:0.0124 - LWLRAP:0.9463\n","\n","        \n","\n"," $$$ ---? Ohoo.... we reached early stoping count : 5\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 498/498 [05:35<00:00,  1.48it/s]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"stream","text":["(1992, 24)\n","weights/bird_mluti_ResNet50_5F_BASE_head1024_framewides_ResampleLoss_2048_512_256_addmask0202_earystop35_batch/fold-3-submission.csv\n","      recording_id  species_id  songtype_id  t_min  f_min  t_max  f_max  kfold\n","0     d49a94504_01        0,18            1      0   5000    5.2  10000      2\n","1     97630c03d_03      0,18,3            1      0   5000    5.2  10000      1\n","2     97630c03d_02      0,18,3            1      0   5000    5.2  10000      2\n","3     d9bfc9e6b_02    0,1,3,12            1      0   5000    5.2  10000      1\n","4     3710abba6_02        0,18            1      0   5000    5.2  10000      2\n","...            ...         ...          ...    ...    ...    ...    ...    ...\n","2421  d8b7f9ed6_01      23,5,3            1      0   5000    5.2  10000      1\n","2422  59a9eb657_03  23,3,12,18            1      0   5000    5.2  10000      1\n","2423  59a9eb657_02     23,3,12            1      0   5000    5.2  10000      3\n","2425  006ab765f_05        23,3            1      0   5000    5.2  10000      0\n","2427  774912d66_03        23,3            1      0   5000    5.2  10000      3\n","\n","[1937 rows x 8 columns]\n","1937\n","[126, 252, 104, 1006, 164, 95, 77, 286, 132, 87, 96, 200, 416, 86, 100, 188, 80, 80, 409, 88, 107, 194, 101, 208]\n","[1811, 1685, 1833, 931, 1773, 1842, 1860, 1651, 1805, 1850, 1841, 1737, 1521, 1851, 1837, 1749, 1857, 1857, 1528, 1849, 1830, 1743, 1836, 1729]\n","{'class_freq': [126, 252, 104, 1006, 164, 95, 77, 286, 132, 87, 96, 200, 416, 86, 100, 188, 80, 80, 409, 88, 107, 194, 101, 208], 'neg_class_freq': [1811, 1685, 1833, 931, 1773, 1842, 1860, 1651, 1805, 1850, 1841, 1737, 1521, 1851, 1837, 1749, 1857, 1857, 1528, 1849, 1830, 1743, 1836, 1729]}\n","Loading Microsoft Vision pretrained model\n","Model already downloaded.\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[1;35m loading from ./class_freq.pkl | rebalance | {'neg_scale': 5.0, 'init_bias': 0.1} | s\u001b[0;0m\n","\u001b[1;35m rebalance reweighting mapping params: 10.00 | 0.20 | 0.10 \u001b[0;0m\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:0 - Loss0.3544: 100%|██████████| 120/120 [00:50<00:00,  2.38it/s]\n","Valid E:0 - Loss:0.1112: 100%|██████████| 31/31 [00:02<00:00, 13.75it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:18:53 2021 \n","\n","                Fold:4, Epoch:0, lr:0.0001\n","\n","                Train Loss:0.3544 - LWLRAP:0.3650\n","\n","                Valid Loss:0.1112 - LWLRAP:0.5290\n","\n","        \n","########## >>>>>>>> Model Improved From -inf ----> 0.5289707754244972\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:1 - Loss0.0688: 100%|██████████| 120/120 [00:49<00:00,  2.41it/s]\n","Valid E:1 - Loss:0.0486: 100%|██████████| 31/31 [00:02<00:00, 14.73it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:19:46 2021 \n","\n","                Fold:4, Epoch:1, lr:0.0004\n","\n","                Train Loss:0.0688 - LWLRAP:0.4318\n","\n","                Valid Loss:0.0486 - LWLRAP:0.5612\n","\n","        \n","########## >>>>>>>> Model Improved From 0.5289707754244972 ----> 0.5611549906803979\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:2 - Loss0.0487: 100%|██████████| 120/120 [00:48<00:00,  2.49it/s]\n","Valid E:2 - Loss:0.0393: 100%|██████████| 31/31 [00:02<00:00, 14.77it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:20:37 2021 \n","\n","                Fold:4, Epoch:2, lr:0.0007\n","\n","                Train Loss:0.0487 - LWLRAP:0.4783\n","\n","                Valid Loss:0.0393 - LWLRAP:0.5924\n","\n","        \n","########## >>>>>>>> Model Improved From 0.5611549906803979 ----> 0.5924388978891659\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:3 - Loss0.0423: 100%|██████████| 120/120 [00:50<00:00,  2.39it/s]\n","Valid E:3 - Loss:0.0363: 100%|██████████| 31/31 [00:02<00:00, 14.80it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:21:30 2021 \n","\n","                Fold:4, Epoch:3, lr:0.001\n","\n","                Train Loss:0.0423 - LWLRAP:0.5166\n","\n","                Valid Loss:0.0363 - LWLRAP:0.6238\n","\n","        \n","########## >>>>>>>> Model Improved From 0.5924388978891659 ----> 0.6237920387349108\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:4 - Loss0.0379: 100%|██████████| 120/120 [00:51<00:00,  2.32it/s]\n","Valid E:4 - Loss:0.0360: 100%|██████████| 31/31 [00:02<00:00, 14.40it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:22:25 2021 \n","\n","                Fold:4, Epoch:4, lr:0.001\n","\n","                Train Loss:0.0379 - LWLRAP:0.5584\n","\n","                Valid Loss:0.0360 - LWLRAP:0.6275\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6237920387349108 ----> 0.6275328665466224\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:5 - Loss0.0355: 100%|██████████| 120/120 [00:46<00:00,  2.59it/s]\n","Valid E:5 - Loss:0.0346: 100%|██████████| 31/31 [00:02<00:00, 14.60it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:23:14 2021 \n","\n","                Fold:4, Epoch:5, lr:0.000995343\n","\n","                Train Loss:0.0355 - LWLRAP:0.5849\n","\n","                Valid Loss:0.0346 - LWLRAP:0.6342\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6275328665466224 ----> 0.6341821776098814\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:6 - Loss0.0346: 100%|██████████| 120/120 [00:54<00:00,  2.20it/s]\n","Valid E:6 - Loss:0.0329: 100%|██████████| 31/31 [00:02<00:00, 14.70it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:24:12 2021 \n","\n","                Fold:4, Epoch:6, lr:0.000989542\n","\n","                Train Loss:0.0346 - LWLRAP:0.5941\n","\n","                Valid Loss:0.0329 - LWLRAP:0.6472\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6341821776098814 ----> 0.6471538115712747\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:7 - Loss0.0334: 100%|██████████| 120/120 [00:48<00:00,  2.50it/s]\n","Valid E:7 - Loss:0.0317: 100%|██████████| 31/31 [00:02<00:00, 14.60it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:25:03 2021 \n","\n","                Fold:4, Epoch:7, lr:0.0009814586\n","\n","                Train Loss:0.0334 - LWLRAP:0.6163\n","\n","                Valid Loss:0.0317 - LWLRAP:0.6701\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6471538115712747 ----> 0.6700503204638744\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:8 - Loss0.0320: 100%|██████████| 120/120 [00:55<00:00,  2.17it/s]\n","Valid E:8 - Loss:0.0311: 100%|██████████| 31/31 [00:02<00:00, 14.48it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:26:01 2021 \n","\n","                Fold:4, Epoch:8, lr:0.0009711305\n","\n","                Train Loss:0.0320 - LWLRAP:0.6381\n","\n","                Valid Loss:0.0311 - LWLRAP:0.6792\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6700503204638744 ----> 0.6792070306577158\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:9 - Loss0.0313: 100%|██████████| 120/120 [00:49<00:00,  2.41it/s]\n","Valid E:9 - Loss:0.0300: 100%|██████████| 31/31 [00:02<00:00, 14.59it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:26:54 2021 \n","\n","                Fold:4, Epoch:9, lr:0.0009586057\n","\n","                Train Loss:0.0313 - LWLRAP:0.6472\n","\n","                Valid Loss:0.0300 - LWLRAP:0.6993\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6792070306577158 ----> 0.699310849386846\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:10 - Loss0.0312: 100%|██████████| 120/120 [00:51<00:00,  2.31it/s]\n","Valid E:10 - Loss:0.0301: 100%|██████████| 31/31 [00:02<00:00, 14.64it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:27:49 2021 \n","\n","                Fold:4, Epoch:10, lr:0.0009439426\n","\n","                Train Loss:0.0312 - LWLRAP:0.6555\n","\n","                Valid Loss:0.0301 - LWLRAP:0.7128\n","\n","        \n","########## >>>>>>>> Model Improved From 0.699310849386846 ----> 0.7128218664997645\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:11 - Loss0.0301: 100%|██████████| 120/120 [00:51<00:00,  2.35it/s]\n","Valid E:11 - Loss:0.0287: 100%|██████████| 31/31 [00:02<00:00, 14.63it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:28:43 2021 \n","\n","                Fold:4, Epoch:11, lr:0.0009272097\n","\n","                Train Loss:0.0301 - LWLRAP:0.6802\n","\n","                Valid Loss:0.0287 - LWLRAP:0.7254\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7128218664997645 ----> 0.7254186008884913\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:12 - Loss0.0287: 100%|██████████| 120/120 [00:52<00:00,  2.29it/s]\n","Valid E:12 - Loss:0.0277: 100%|██████████| 31/31 [00:02<00:00, 14.52it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:29:38 2021 \n","\n","                Fold:4, Epoch:12, lr:0.0009084849\n","\n","                Train Loss:0.0287 - LWLRAP:0.7040\n","\n","                Valid Loss:0.0277 - LWLRAP:0.7326\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7254186008884913 ----> 0.7326373928534694\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:13 - Loss0.0281: 100%|██████████| 120/120 [00:52<00:00,  2.29it/s]\n","Valid E:13 - Loss:0.0261: 100%|██████████| 31/31 [00:02<00:00, 14.47it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:30:33 2021 \n","\n","                Fold:4, Epoch:13, lr:0.0008878556\n","\n","                Train Loss:0.0281 - LWLRAP:0.7117\n","\n","                Valid Loss:0.0261 - LWLRAP:0.7737\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7326373928534694 ----> 0.773699777491564\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:14 - Loss0.0269: 100%|██████████| 120/120 [00:50<00:00,  2.36it/s]\n","Valid E:14 - Loss:0.0237: 100%|██████████| 31/31 [00:02<00:00, 14.61it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:31:27 2021 \n","\n","                Fold:4, Epoch:14, lr:0.000865418\n","\n","                Train Loss:0.0269 - LWLRAP:0.7289\n","\n","                Valid Loss:0.0237 - LWLRAP:0.7973\n","\n","        \n","########## >>>>>>>> Model Improved From 0.773699777491564 ----> 0.7972949177788667\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:15 - Loss0.0252: 100%|██████████| 120/120 [00:53<00:00,  2.26it/s]\n","Valid E:15 - Loss:0.0229: 100%|██████████| 31/31 [00:02<00:00, 14.49it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:32:23 2021 \n","\n","                Fold:4, Epoch:15, lr:0.0008412766\n","\n","                Train Loss:0.0252 - LWLRAP:0.7580\n","\n","                Valid Loss:0.0229 - LWLRAP:0.8225\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7972949177788667 ----> 0.8225433433266462\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:16 - Loss0.0245: 100%|██████████| 120/120 [00:51<00:00,  2.35it/s]\n","Valid E:16 - Loss:0.0214: 100%|██████████| 31/31 [00:02<00:00, 14.36it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:33:18 2021 \n","\n","                Fold:4, Epoch:16, lr:0.000815544\n","\n","                Train Loss:0.0245 - LWLRAP:0.7781\n","\n","                Valid Loss:0.0214 - LWLRAP:0.8320\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8225433433266462 ----> 0.8319837310256553\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:17 - Loss0.0230: 100%|██████████| 120/120 [00:50<00:00,  2.38it/s]\n","Valid E:17 - Loss:0.0197: 100%|██████████| 31/31 [00:02<00:00, 14.66it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:34:11 2021 \n","\n","                Fold:4, Epoch:17, lr:0.0007883402\n","\n","                Train Loss:0.0230 - LWLRAP:0.8019\n","\n","                Valid Loss:0.0197 - LWLRAP:0.8558\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8319837310256553 ----> 0.8558431794495157\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:18 - Loss0.0214: 100%|██████████| 120/120 [00:52<00:00,  2.27it/s]\n","Valid E:18 - Loss:0.0190: 100%|██████████| 31/31 [00:02<00:00, 14.25it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:35:07 2021 \n","\n","                Fold:4, Epoch:18, lr:0.000759792\n","\n","                Train Loss:0.0214 - LWLRAP:0.8266\n","\n","                Valid Loss:0.0190 - LWLRAP:0.8805\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8558431794495157 ----> 0.8805117297557056\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:19 - Loss0.0199: 100%|██████████| 120/120 [00:49<00:00,  2.41it/s]\n","Valid E:19 - Loss:0.0169: 100%|██████████| 31/31 [00:02<00:00, 14.80it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:35:59 2021 \n","\n","                Fold:4, Epoch:19, lr:0.0007300325\n","\n","                Train Loss:0.0199 - LWLRAP:0.8494\n","\n","                Valid Loss:0.0169 - LWLRAP:0.8955\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8805117297557056 ----> 0.8955235498435569\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:20 - Loss0.0186: 100%|██████████| 120/120 [00:52<00:00,  2.28it/s]\n","Valid E:20 - Loss:0.0167: 100%|██████████| 31/31 [00:02<00:00, 14.68it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:36:55 2021 \n","\n","                Fold:4, Epoch:20, lr:0.0006992005\n","\n","                Train Loss:0.0186 - LWLRAP:0.8624\n","\n","                Valid Loss:0.0167 - LWLRAP:0.9089\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8955235498435569 ----> 0.9088804974287078\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:21 - Loss0.0182: 100%|██████████| 120/120 [00:53<00:00,  2.26it/s]\n","Valid E:21 - Loss:0.0154: 100%|██████████| 31/31 [00:02<00:00, 14.61it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:37:51 2021 \n","\n","                Fold:4, Epoch:21, lr:0.0006674398\n","\n","                Train Loss:0.0182 - LWLRAP:0.8733\n","\n","                Valid Loss:0.0154 - LWLRAP:0.9198\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9088804974287078 ----> 0.9198084240406196\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:22 - Loss0.0176: 100%|██████████| 120/120 [00:54<00:00,  2.21it/s]\n","Valid E:22 - Loss:0.0151: 100%|██████████| 31/31 [00:02<00:00, 14.56it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:38:48 2021 \n","\n","                Fold:4, Epoch:22, lr:0.0006348984\n","\n","                Train Loss:0.0176 - LWLRAP:0.8820\n","\n","                Valid Loss:0.0151 - LWLRAP:0.9213\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9198084240406196 ----> 0.9212596734810601\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:23 - Loss0.0161: 100%|██████████| 120/120 [00:55<00:00,  2.15it/s]\n","Valid E:23 - Loss:0.0146: 100%|██████████| 31/31 [00:02<00:00, 14.48it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:39:47 2021 \n","\n","                Fold:4, Epoch:23, lr:0.000601728\n","\n","                Train Loss:0.0161 - LWLRAP:0.8944\n","\n","                Valid Loss:0.0146 - LWLRAP:0.9216\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9212596734810601 ----> 0.9216114876848808\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:24 - Loss0.0156: 100%|██████████| 120/120 [00:50<00:00,  2.36it/s]\n","Valid E:24 - Loss:0.0134: 100%|██████████| 31/31 [00:02<00:00, 14.70it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:40:41 2021 \n","\n","                Fold:4, Epoch:24, lr:0.0005680833\n","\n","                Train Loss:0.0156 - LWLRAP:0.9019\n","\n","                Valid Loss:0.0134 - LWLRAP:0.9378\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9216114876848808 ----> 0.9378027080616506\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:25 - Loss0.0156: 100%|██████████| 120/120 [00:49<00:00,  2.43it/s]\n","Valid E:25 - Loss:0.0132: 100%|██████████| 31/31 [00:02<00:00, 14.63it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:41:33 2021 \n","\n","                Fold:4, Epoch:25, lr:0.0005341212\n","\n","                Train Loss:0.0156 - LWLRAP:0.9014\n","\n","                Valid Loss:0.0132 - LWLRAP:0.9419\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9378027080616506 ----> 0.9418946965748872\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:26 - Loss0.0148: 100%|██████████| 120/120 [00:51<00:00,  2.34it/s]\n","Valid E:26 - Loss:0.0124: 100%|██████████| 31/31 [00:02<00:00, 14.25it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:42:27 2021 \n","\n","                Fold:4, Epoch:26, lr:0.0005\n","\n","                Train Loss:0.0148 - LWLRAP:0.9139\n","\n","                Valid Loss:0.0124 - LWLRAP:0.9460\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9418946965748872 ----> 0.9459903723453884\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:27 - Loss0.0139: 100%|██████████| 120/120 [00:50<00:00,  2.39it/s]\n","Valid E:27 - Loss:0.0134: 100%|██████████| 31/31 [00:02<00:00, 14.57it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:43:21 2021 \n","\n","                Fold:4, Epoch:27, lr:0.0004658788\n","\n","                Train Loss:0.0139 - LWLRAP:0.9179\n","\n","                Valid Loss:0.0134 - LWLRAP:0.9445\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:28 - Loss0.0138: 100%|██████████| 120/120 [00:52<00:00,  2.28it/s]\n","Valid E:28 - Loss:0.0139: 100%|██████████| 31/31 [00:02<00:00, 14.45it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:44:16 2021 \n","\n","                Fold:4, Epoch:28, lr:0.0004319167\n","\n","                Train Loss:0.0138 - LWLRAP:0.9173\n","\n","                Valid Loss:0.0139 - LWLRAP:0.9348\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:29 - Loss0.0129: 100%|██████████| 120/120 [00:54<00:00,  2.20it/s]\n","Valid E:29 - Loss:0.0142: 100%|██████████| 31/31 [00:02<00:00, 14.42it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:45:13 2021 \n","\n","                Fold:4, Epoch:29, lr:0.000398272\n","\n","                Train Loss:0.0129 - LWLRAP:0.9278\n","\n","                Valid Loss:0.0142 - LWLRAP:0.9340\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:30 - Loss0.0128: 100%|██████████| 120/120 [00:52<00:00,  2.29it/s]\n","Valid E:30 - Loss:0.0136: 100%|██████████| 31/31 [00:02<00:00, 14.31it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:46:08 2021 \n","\n","                Fold:4, Epoch:30, lr:0.0003651016\n","\n","                Train Loss:0.0128 - LWLRAP:0.9263\n","\n","                Valid Loss:0.0136 - LWLRAP:0.9394\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 4\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:31 - Loss0.0122: 100%|██████████| 120/120 [00:51<00:00,  2.31it/s]\n","Valid E:31 - Loss:0.0126: 100%|██████████| 31/31 [00:02<00:00, 14.74it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:47:03 2021 \n","\n","                Fold:4, Epoch:31, lr:0.0003325602\n","\n","                Train Loss:0.0122 - LWLRAP:0.9326\n","\n","                Valid Loss:0.0126 - LWLRAP:0.9395\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:32 - Loss0.0113: 100%|██████████| 120/120 [00:48<00:00,  2.46it/s]\n","Valid E:32 - Loss:0.0124: 100%|██████████| 31/31 [00:02<00:00, 14.67it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:47:54 2021 \n","\n","                Fold:4, Epoch:32, lr:0.0003007995\n","\n","                Train Loss:0.0113 - LWLRAP:0.9362\n","\n","                Valid Loss:0.0124 - LWLRAP:0.9423\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:33 - Loss0.0112: 100%|██████████| 120/120 [00:52<00:00,  2.30it/s]\n","Valid E:33 - Loss:0.0126: 100%|██████████| 31/31 [00:02<00:00, 14.60it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:48:48 2021 \n","\n","                Fold:4, Epoch:33, lr:0.0002699675\n","\n","                Train Loss:0.0112 - LWLRAP:0.9393\n","\n","                Valid Loss:0.0126 - LWLRAP:0.9470\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9459903723453884 ----> 0.9469968080322964\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:34 - Loss0.0114: 100%|██████████| 120/120 [00:52<00:00,  2.27it/s]\n","Valid E:34 - Loss:0.0125: 100%|██████████| 31/31 [00:02<00:00, 14.58it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:49:44 2021 \n","\n","                Fold:4, Epoch:34, lr:0.000240208\n","\n","                Train Loss:0.0114 - LWLRAP:0.9363\n","\n","                Valid Loss:0.0125 - LWLRAP:0.9438\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:35 - Loss0.0112: 100%|██████████| 120/120 [00:51<00:00,  2.33it/s]\n","Valid E:35 - Loss:0.0130: 100%|██████████| 31/31 [00:02<00:00, 14.54it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:50:38 2021 \n","\n","                Fold:4, Epoch:35, lr:0.0002116598\n","\n","                Train Loss:0.0112 - LWLRAP:0.9374\n","\n","                Valid Loss:0.0130 - LWLRAP:0.9455\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 2\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:36 - Loss0.0104: 100%|██████████| 120/120 [00:49<00:00,  2.43it/s]\n","Valid E:36 - Loss:0.0132: 100%|██████████| 31/31 [00:02<00:00, 14.57it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:51:30 2021 \n","\n","                Fold:4, Epoch:36, lr:0.000184456\n","\n","                Train Loss:0.0104 - LWLRAP:0.9447\n","\n","                Valid Loss:0.0132 - LWLRAP:0.9440\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:37 - Loss0.0102: 100%|██████████| 120/120 [00:49<00:00,  2.40it/s]\n","Valid E:37 - Loss:0.0120: 100%|██████████| 31/31 [00:02<00:00, 14.72it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:52:23 2021 \n","\n","                Fold:4, Epoch:37, lr:0.0001587234\n","\n","                Train Loss:0.0102 - LWLRAP:0.9460\n","\n","                Valid Loss:0.0120 - LWLRAP:0.9478\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9469968080322964 ----> 0.9477611966356851\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:38 - Loss0.0090: 100%|██████████| 120/120 [00:50<00:00,  2.38it/s]\n","Valid E:38 - Loss:0.0133: 100%|██████████| 31/31 [00:02<00:00, 14.55it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:53:16 2021 \n","\n","                Fold:4, Epoch:38, lr:0.000134582\n","\n","                Train Loss:0.0090 - LWLRAP:0.9545\n","\n","                Valid Loss:0.0133 - LWLRAP:0.9421\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:39 - Loss0.0088: 100%|██████████| 120/120 [00:52<00:00,  2.28it/s]\n","Valid E:39 - Loss:0.0130: 100%|██████████| 31/31 [00:02<00:00, 14.52it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:54:11 2021 \n","\n","                Fold:4, Epoch:39, lr:0.0001121444\n","\n","                Train Loss:0.0088 - LWLRAP:0.9571\n","\n","                Valid Loss:0.0130 - LWLRAP:0.9367\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:40 - Loss0.0101: 100%|██████████| 120/120 [00:54<00:00,  2.19it/s]\n","Valid E:40 - Loss:0.0123: 100%|██████████| 31/31 [00:02<00:00, 14.50it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:55:08 2021 \n","\n","                Fold:4, Epoch:40, lr:9.151505e-05\n","\n","                Train Loss:0.0101 - LWLRAP:0.9428\n","\n","                Valid Loss:0.0123 - LWLRAP:0.9433\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"," $$$ ---? Ohoo.... we reached early stoping count : 3\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:41 - Loss0.0102: 100%|██████████| 120/120 [00:51<00:00,  2.34it/s]\n","Valid E:41 - Loss:0.0124: 100%|██████████| 31/31 [00:02<00:00, 14.75it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:56:03 2021 \n","\n","                Fold:4, Epoch:41, lr:7.27903e-05\n","\n","                Train Loss:0.0102 - LWLRAP:0.9419\n","\n","                Valid Loss:0.0124 - LWLRAP:0.9490\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9477611966356851 ----> 0.9489831914314278\n"],"name":"stdout"},{"output_type":"stream","text":["Train E:42 - Loss0.0090: 100%|██████████| 120/120 [00:51<00:00,  2.32it/s]\n","Valid E:42 - Loss:0.0130: 100%|██████████| 31/31 [00:02<00:00, 14.75it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:56:57 2021 \n","\n","                Fold:4, Epoch:42, lr:5.605739e-05\n","\n","                Train Loss:0.0090 - LWLRAP:0.9515\n","\n","                Valid Loss:0.0130 - LWLRAP:0.9446\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:43 - Loss0.0083: 100%|██████████| 120/120 [00:46<00:00,  2.57it/s]\n","Valid E:43 - Loss:0.0133: 100%|██████████| 31/31 [00:02<00:00, 14.57it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:57:46 2021 \n","\n","                Fold:4, Epoch:43, lr:4.139435e-05\n","\n","                Train Loss:0.0083 - LWLRAP:0.9595\n","\n","                Valid Loss:0.0133 - LWLRAP:0.9477\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:44 - Loss0.0082: 100%|██████████| 120/120 [00:53<00:00,  2.26it/s]\n","Valid E:44 - Loss:0.0127: 100%|██████████| 31/31 [00:02<00:00, 14.31it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","  0%|          | 0/120 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:58:42 2021 \n","\n","                Fold:4, Epoch:44, lr:2.886954e-05\n","\n","                Train Loss:0.0082 - LWLRAP:0.9562\n","\n","                Valid Loss:0.0127 - LWLRAP:0.9464\n","\n","        \n"],"name":"stdout"},{"output_type":"stream","text":["Train E:45 - Loss0.0082: 100%|██████████| 120/120 [00:52<00:00,  2.28it/s]\n","Valid E:45 - Loss:0.0126: 100%|██████████| 31/31 [00:02<00:00, 14.62it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","                Sun Feb 14 05:59:37 2021 \n","\n","                Fold:4, Epoch:45, lr:1.854136e-05\n","\n","                Train Loss:0.0082 - LWLRAP:0.9569\n","\n","                Valid Loss:0.0126 - LWLRAP:0.9483\n","\n","        \n","\n"," $$$ ---? Ohoo.... we reached early stoping count : 4\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 498/498 [05:36<00:00,  1.48it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["(1992, 24)\n","weights/bird_mluti_ResNet50_5F_BASE_head1024_framewides_ResampleLoss_2048_512_256_addmask0202_earystop35_batch/fold-4-submission.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hG3dQprC4yil"},"source":["last_sub_s = pd.DataFrame()\n","last_sub_recording_id = pd.DataFrame()\n","for folds in range(FOLDS):\n","    fold_df = pd.read_csv(f'./weights/{args.exp_name}/fold-{folds}-submission.csv')#<==========\n","    if folds == 0:\n","        last_sub_s = pd.concat([last_sub_s,fold_df.iloc[:,1:]])\n","        last_sub_recording_id = pd.DataFrame(fold_df['recording_id'])\n","        continue\n","        \n","    last_sub_s = last_sub_s + fold_df.iloc[:,1:]\n","\n","last_sub_mean_FOLDS = last_sub_s / FOLDS\n","last_sub_df = pd.concat([last_sub_recording_id,last_sub_mean_FOLDS],axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":439},"id":"lYjutPpWTb2e","executionInfo":{"elapsed":1785,"status":"ok","timestamp":1613246129107,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"6794d1db-a01a-4420-f7f2-b6addd9e50d0"},"source":["last_sub_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>recording_id</th>\n","      <th>s0</th>\n","      <th>s1</th>\n","      <th>s2</th>\n","      <th>s3</th>\n","      <th>s4</th>\n","      <th>s5</th>\n","      <th>s6</th>\n","      <th>s7</th>\n","      <th>s8</th>\n","      <th>s9</th>\n","      <th>s10</th>\n","      <th>s11</th>\n","      <th>s12</th>\n","      <th>s13</th>\n","      <th>s14</th>\n","      <th>s15</th>\n","      <th>s16</th>\n","      <th>s17</th>\n","      <th>s18</th>\n","      <th>s19</th>\n","      <th>s20</th>\n","      <th>s21</th>\n","      <th>s22</th>\n","      <th>s23</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000316da7</td>\n","      <td>0.454418</td>\n","      <td>0.410838</td>\n","      <td>0.381290</td>\n","      <td>0.877776</td>\n","      <td>0.363517</td>\n","      <td>0.441159</td>\n","      <td>0.378172</td>\n","      <td>0.426355</td>\n","      <td>0.414684</td>\n","      <td>0.465739</td>\n","      <td>0.413559</td>\n","      <td>0.405459</td>\n","      <td>0.683334</td>\n","      <td>0.429275</td>\n","      <td>0.394767</td>\n","      <td>0.431638</td>\n","      <td>0.381096</td>\n","      <td>0.378928</td>\n","      <td>0.987677</td>\n","      <td>0.389682</td>\n","      <td>0.483707</td>\n","      <td>0.432987</td>\n","      <td>0.376018</td>\n","      <td>0.398530</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>003bc2cb2</td>\n","      <td>0.366574</td>\n","      <td>0.417767</td>\n","      <td>0.386687</td>\n","      <td>0.975360</td>\n","      <td>0.346989</td>\n","      <td>0.362667</td>\n","      <td>0.331576</td>\n","      <td>0.391116</td>\n","      <td>0.379239</td>\n","      <td>0.424393</td>\n","      <td>0.378985</td>\n","      <td>0.379944</td>\n","      <td>0.534362</td>\n","      <td>0.400302</td>\n","      <td>0.372884</td>\n","      <td>0.407543</td>\n","      <td>0.998514</td>\n","      <td>0.421011</td>\n","      <td>0.373939</td>\n","      <td>0.383144</td>\n","      <td>0.366689</td>\n","      <td>0.415500</td>\n","      <td>0.334942</td>\n","      <td>0.353138</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0061c037e</td>\n","      <td>0.405547</td>\n","      <td>0.412953</td>\n","      <td>0.378255</td>\n","      <td>0.489718</td>\n","      <td>0.370028</td>\n","      <td>0.524348</td>\n","      <td>0.388259</td>\n","      <td>0.753611</td>\n","      <td>0.403011</td>\n","      <td>0.425790</td>\n","      <td>0.553775</td>\n","      <td>0.475922</td>\n","      <td>0.441213</td>\n","      <td>0.485838</td>\n","      <td>0.429632</td>\n","      <td>0.600600</td>\n","      <td>0.397214</td>\n","      <td>0.517608</td>\n","      <td>0.423877</td>\n","      <td>0.415650</td>\n","      <td>0.481050</td>\n","      <td>0.366126</td>\n","      <td>0.411711</td>\n","      <td>0.437048</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>010eb14d3</td>\n","      <td>0.983088</td>\n","      <td>0.268766</td>\n","      <td>0.285464</td>\n","      <td>0.990953</td>\n","      <td>0.278399</td>\n","      <td>0.276225</td>\n","      <td>0.244805</td>\n","      <td>0.261956</td>\n","      <td>0.991951</td>\n","      <td>0.268361</td>\n","      <td>0.243503</td>\n","      <td>0.206241</td>\n","      <td>0.809015</td>\n","      <td>0.229408</td>\n","      <td>0.231450</td>\n","      <td>0.268925</td>\n","      <td>0.234570</td>\n","      <td>0.248731</td>\n","      <td>0.989984</td>\n","      <td>0.256210</td>\n","      <td>0.283087</td>\n","      <td>0.233189</td>\n","      <td>0.208032</td>\n","      <td>0.259600</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>011318064</td>\n","      <td>0.419670</td>\n","      <td>0.498061</td>\n","      <td>0.401132</td>\n","      <td>0.989453</td>\n","      <td>0.383486</td>\n","      <td>0.423120</td>\n","      <td>0.541212</td>\n","      <td>0.439069</td>\n","      <td>0.431537</td>\n","      <td>0.433830</td>\n","      <td>0.404794</td>\n","      <td>0.441701</td>\n","      <td>0.530387</td>\n","      <td>0.467339</td>\n","      <td>0.986595</td>\n","      <td>0.947387</td>\n","      <td>0.408119</td>\n","      <td>0.430219</td>\n","      <td>0.941875</td>\n","      <td>0.403430</td>\n","      <td>0.448202</td>\n","      <td>0.486663</td>\n","      <td>0.381650</td>\n","      <td>0.390816</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1987</th>\n","      <td>ff68f3ac3</td>\n","      <td>0.467600</td>\n","      <td>0.689482</td>\n","      <td>0.473200</td>\n","      <td>0.981017</td>\n","      <td>0.626022</td>\n","      <td>0.983837</td>\n","      <td>0.391950</td>\n","      <td>0.512594</td>\n","      <td>0.416471</td>\n","      <td>0.460402</td>\n","      <td>0.410971</td>\n","      <td>0.419136</td>\n","      <td>0.875320</td>\n","      <td>0.735405</td>\n","      <td>0.413398</td>\n","      <td>0.975493</td>\n","      <td>0.416509</td>\n","      <td>0.413162</td>\n","      <td>0.985216</td>\n","      <td>0.415941</td>\n","      <td>0.472202</td>\n","      <td>0.416398</td>\n","      <td>0.399951</td>\n","      <td>0.981397</td>\n","    </tr>\n","    <tr>\n","      <th>1988</th>\n","      <td>ff973e852</td>\n","      <td>0.410647</td>\n","      <td>0.438278</td>\n","      <td>0.378536</td>\n","      <td>0.497276</td>\n","      <td>0.382654</td>\n","      <td>0.423704</td>\n","      <td>0.510229</td>\n","      <td>0.966009</td>\n","      <td>0.396930</td>\n","      <td>0.739276</td>\n","      <td>0.425248</td>\n","      <td>0.939995</td>\n","      <td>0.471495</td>\n","      <td>0.494435</td>\n","      <td>0.417750</td>\n","      <td>0.939422</td>\n","      <td>0.399095</td>\n","      <td>0.869820</td>\n","      <td>0.417820</td>\n","      <td>0.428322</td>\n","      <td>0.577057</td>\n","      <td>0.422123</td>\n","      <td>0.410020</td>\n","      <td>0.418828</td>\n","    </tr>\n","    <tr>\n","      <th>1989</th>\n","      <td>ffa5cf6d6</td>\n","      <td>0.439320</td>\n","      <td>0.968359</td>\n","      <td>0.473887</td>\n","      <td>0.908947</td>\n","      <td>0.398759</td>\n","      <td>0.436604</td>\n","      <td>0.408183</td>\n","      <td>0.523504</td>\n","      <td>0.422283</td>\n","      <td>0.558716</td>\n","      <td>0.447559</td>\n","      <td>0.444568</td>\n","      <td>0.718647</td>\n","      <td>0.578763</td>\n","      <td>0.420089</td>\n","      <td>0.974826</td>\n","      <td>0.481199</td>\n","      <td>0.883152</td>\n","      <td>0.444549</td>\n","      <td>0.447860</td>\n","      <td>0.442554</td>\n","      <td>0.418432</td>\n","      <td>0.402981</td>\n","      <td>0.418504</td>\n","    </tr>\n","    <tr>\n","      <th>1990</th>\n","      <td>ffa88cbb8</td>\n","      <td>0.424821</td>\n","      <td>0.958047</td>\n","      <td>0.480993</td>\n","      <td>0.997520</td>\n","      <td>0.403327</td>\n","      <td>0.446201</td>\n","      <td>0.419503</td>\n","      <td>0.567482</td>\n","      <td>0.422792</td>\n","      <td>0.799238</td>\n","      <td>0.421684</td>\n","      <td>0.435941</td>\n","      <td>0.652990</td>\n","      <td>0.467525</td>\n","      <td>0.442448</td>\n","      <td>0.495663</td>\n","      <td>0.970126</td>\n","      <td>0.425163</td>\n","      <td>0.457980</td>\n","      <td>0.428844</td>\n","      <td>0.442323</td>\n","      <td>0.442131</td>\n","      <td>0.404177</td>\n","      <td>0.421897</td>\n","    </tr>\n","    <tr>\n","      <th>1991</th>\n","      <td>ffda5d7b3</td>\n","      <td>0.464751</td>\n","      <td>0.458583</td>\n","      <td>0.971020</td>\n","      <td>0.798334</td>\n","      <td>0.372287</td>\n","      <td>0.416871</td>\n","      <td>0.352953</td>\n","      <td>0.428935</td>\n","      <td>0.387459</td>\n","      <td>0.425740</td>\n","      <td>0.375594</td>\n","      <td>0.374379</td>\n","      <td>0.725192</td>\n","      <td>0.382231</td>\n","      <td>0.353924</td>\n","      <td>0.415954</td>\n","      <td>0.379064</td>\n","      <td>0.416323</td>\n","      <td>0.428781</td>\n","      <td>0.391254</td>\n","      <td>0.420051</td>\n","      <td>0.406534</td>\n","      <td>0.522329</td>\n","      <td>0.357499</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1992 rows × 25 columns</p>\n","</div>"],"text/plain":["     recording_id        s0        s1  ...       s21       s22       s23\n","0       000316da7  0.454418  0.410838  ...  0.432987  0.376018  0.398530\n","1       003bc2cb2  0.366574  0.417767  ...  0.415500  0.334942  0.353138\n","2       0061c037e  0.405547  0.412953  ...  0.366126  0.411711  0.437048\n","3       010eb14d3  0.983088  0.268766  ...  0.233189  0.208032  0.259600\n","4       011318064  0.419670  0.498061  ...  0.486663  0.381650  0.390816\n","...           ...       ...       ...  ...       ...       ...       ...\n","1987    ff68f3ac3  0.467600  0.689482  ...  0.416398  0.399951  0.981397\n","1988    ff973e852  0.410647  0.438278  ...  0.422123  0.410020  0.418828\n","1989    ffa5cf6d6  0.439320  0.968359  ...  0.418432  0.402981  0.418504\n","1990    ffa88cbb8  0.424821  0.958047  ...  0.442131  0.404177  0.421897\n","1991    ffda5d7b3  0.464751  0.458583  ...  0.406534  0.522329  0.357499\n","\n","[1992 rows x 25 columns]"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"qOfYVkQ40ZI5"},"source":["args.save_path = os.path.join(args.output_dir, args.exp_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yh5Avzvf9JHZ"},"source":["last_sub_df.to_csv(os.path.join(args.save_path, f\"1s_pred_submission.csv\"), index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLVP-iPE7j3F","executionInfo":{"elapsed":1754,"status":"ok","timestamp":1613246129109,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"aeb54093-7c11-4f7d-f250-54233cdda10e"},"source":["print('end')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["end\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-xfLSOpT-WcQ"},"source":["def pretty_size(size):\n","\t\"\"\"Pretty prints a torch.Size object\"\"\"\n","\tassert(isinstance(size, torch.Size))\n","\treturn \" × \".join(map(str, size))\n","\n","def dump_tensors(gpu_only=True):\n","\t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n","\timport gc\n","\ttotal_size = 0\n","\tfor obj in gc.get_objects():\n","\t\ttry:\n","\t\t\tif torch.is_tensor(obj):\n","\t\t\t\tif not gpu_only or obj.is_cuda:\n","\t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n","\t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n","\t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n","\t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n","\t\t\t\t\ttotal_size += obj.numel()\n","\t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n","\t\t\t\tif not gpu_only or obj.is_cuda:\n","\t\t\t\t\tprint(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n","\t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n","\t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n","\t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n","\t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n","\t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n","\t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n","\t\t\t\t\ttotal_size += obj.data.numel()\n","\t\texcept Exception as e:\n","\t\t\tpass        \n","\tprint(\"Total size:\", total_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OvUD4sgV-XeC"},"source":["dump_tensors()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3talKoTqbfFu"},"source":["# torch.cuda.empty_cache()"]},{"cell_type":"code","metadata":{"id":"w4LCSZLZ_CV9"},"source":["torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qXHJvPeYODR"},"source":["# sub_df = pd.DataFrame()\n","# for index, row in last_sub_df.iterrows():\n","#   if row['s3']>0.5:\n","#     row['s3'] = 0.5\n","#   if row['s12']>0.5:\n","#     row['s12'] = 0.5\n","#   if row['s18']>0.5:\n","#     row['s18'] = 0.5\n","#   sub_df = pd.concat([sub_df,row],axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M4xoWyYSY0MY"},"source":["sub_df = sub_df.T\n","##########################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pxMVS8FuZhbp"},"source":["sub_df.to_csv(os.path.join(args.save_path, f\"submission.csv\"), index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8VFCj3aWHlj"},"source":["last_sub_df[last_sub_df['s0']>0.5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JrqcSnjvWg39"},"source":["dic_count = []\n","for x in range(24):\n","  count_nb = len(last_sub_df[last_sub_df[f's{x}']>0.5])\n","  dic_count.append([f's{x}',count_nb])\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":439},"id":"nvzUsT_v8cgq","executionInfo":{"elapsed":790,"status":"ok","timestamp":1613255799825,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"9f72d743-aeff-465d-f2bc-718e10d45015"},"source":["last_sub_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>recording_id</th>\n","      <th>s0</th>\n","      <th>s1</th>\n","      <th>s2</th>\n","      <th>s3</th>\n","      <th>s4</th>\n","      <th>s5</th>\n","      <th>s6</th>\n","      <th>s7</th>\n","      <th>s8</th>\n","      <th>s9</th>\n","      <th>s10</th>\n","      <th>s11</th>\n","      <th>s12</th>\n","      <th>s13</th>\n","      <th>s14</th>\n","      <th>s15</th>\n","      <th>s16</th>\n","      <th>s17</th>\n","      <th>s18</th>\n","      <th>s19</th>\n","      <th>s20</th>\n","      <th>s21</th>\n","      <th>s22</th>\n","      <th>s23</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000316da7</td>\n","      <td>0.454418</td>\n","      <td>0.410838</td>\n","      <td>0.381290</td>\n","      <td>0.877776</td>\n","      <td>0.363517</td>\n","      <td>0.441159</td>\n","      <td>0.378172</td>\n","      <td>0.426355</td>\n","      <td>0.414684</td>\n","      <td>0.465739</td>\n","      <td>0.413559</td>\n","      <td>0.405459</td>\n","      <td>0.683334</td>\n","      <td>0.429275</td>\n","      <td>0.394767</td>\n","      <td>0.431638</td>\n","      <td>0.381096</td>\n","      <td>0.378928</td>\n","      <td>0.987677</td>\n","      <td>0.389682</td>\n","      <td>0.483707</td>\n","      <td>0.432987</td>\n","      <td>0.376018</td>\n","      <td>0.398530</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>003bc2cb2</td>\n","      <td>0.366574</td>\n","      <td>0.417767</td>\n","      <td>0.386687</td>\n","      <td>0.975360</td>\n","      <td>0.346989</td>\n","      <td>0.362667</td>\n","      <td>0.331576</td>\n","      <td>0.391116</td>\n","      <td>0.379239</td>\n","      <td>0.424393</td>\n","      <td>0.378985</td>\n","      <td>0.379944</td>\n","      <td>0.534362</td>\n","      <td>0.400302</td>\n","      <td>0.372884</td>\n","      <td>0.407543</td>\n","      <td>0.998514</td>\n","      <td>0.421011</td>\n","      <td>0.373939</td>\n","      <td>0.383144</td>\n","      <td>0.366689</td>\n","      <td>0.415500</td>\n","      <td>0.334942</td>\n","      <td>0.353138</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0061c037e</td>\n","      <td>0.405547</td>\n","      <td>0.412953</td>\n","      <td>0.378255</td>\n","      <td>0.489718</td>\n","      <td>0.370028</td>\n","      <td>0.524348</td>\n","      <td>0.388259</td>\n","      <td>0.753611</td>\n","      <td>0.403011</td>\n","      <td>0.425790</td>\n","      <td>0.553775</td>\n","      <td>0.475922</td>\n","      <td>0.441213</td>\n","      <td>0.485838</td>\n","      <td>0.429632</td>\n","      <td>0.600600</td>\n","      <td>0.397214</td>\n","      <td>0.517608</td>\n","      <td>0.423877</td>\n","      <td>0.415650</td>\n","      <td>0.481050</td>\n","      <td>0.366126</td>\n","      <td>0.411711</td>\n","      <td>0.437048</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>010eb14d3</td>\n","      <td>0.983088</td>\n","      <td>0.268766</td>\n","      <td>0.285464</td>\n","      <td>0.990953</td>\n","      <td>0.278399</td>\n","      <td>0.276225</td>\n","      <td>0.244805</td>\n","      <td>0.261956</td>\n","      <td>0.991951</td>\n","      <td>0.268361</td>\n","      <td>0.243503</td>\n","      <td>0.206241</td>\n","      <td>0.809015</td>\n","      <td>0.229408</td>\n","      <td>0.231450</td>\n","      <td>0.268925</td>\n","      <td>0.234570</td>\n","      <td>0.248731</td>\n","      <td>0.989984</td>\n","      <td>0.256210</td>\n","      <td>0.283087</td>\n","      <td>0.233189</td>\n","      <td>0.208032</td>\n","      <td>0.259600</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>011318064</td>\n","      <td>0.419670</td>\n","      <td>0.498061</td>\n","      <td>0.401132</td>\n","      <td>0.989453</td>\n","      <td>0.383486</td>\n","      <td>0.423120</td>\n","      <td>0.541212</td>\n","      <td>0.439069</td>\n","      <td>0.431537</td>\n","      <td>0.433830</td>\n","      <td>0.404794</td>\n","      <td>0.441701</td>\n","      <td>0.530387</td>\n","      <td>0.467339</td>\n","      <td>0.986595</td>\n","      <td>0.947387</td>\n","      <td>0.408119</td>\n","      <td>0.430219</td>\n","      <td>0.941875</td>\n","      <td>0.403430</td>\n","      <td>0.448202</td>\n","      <td>0.486663</td>\n","      <td>0.381650</td>\n","      <td>0.390816</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1987</th>\n","      <td>ff68f3ac3</td>\n","      <td>0.467600</td>\n","      <td>0.689482</td>\n","      <td>0.473200</td>\n","      <td>0.981017</td>\n","      <td>0.626022</td>\n","      <td>0.983837</td>\n","      <td>0.391950</td>\n","      <td>0.512594</td>\n","      <td>0.416471</td>\n","      <td>0.460402</td>\n","      <td>0.410971</td>\n","      <td>0.419136</td>\n","      <td>0.875320</td>\n","      <td>0.735405</td>\n","      <td>0.413398</td>\n","      <td>0.975493</td>\n","      <td>0.416509</td>\n","      <td>0.413162</td>\n","      <td>0.985216</td>\n","      <td>0.415941</td>\n","      <td>0.472202</td>\n","      <td>0.416398</td>\n","      <td>0.399951</td>\n","      <td>0.981397</td>\n","    </tr>\n","    <tr>\n","      <th>1988</th>\n","      <td>ff973e852</td>\n","      <td>0.410647</td>\n","      <td>0.438278</td>\n","      <td>0.378536</td>\n","      <td>0.497276</td>\n","      <td>0.382654</td>\n","      <td>0.423704</td>\n","      <td>0.510229</td>\n","      <td>0.966009</td>\n","      <td>0.396930</td>\n","      <td>0.739276</td>\n","      <td>0.425248</td>\n","      <td>0.939995</td>\n","      <td>0.471495</td>\n","      <td>0.494435</td>\n","      <td>0.417750</td>\n","      <td>0.939422</td>\n","      <td>0.399095</td>\n","      <td>0.869820</td>\n","      <td>0.417820</td>\n","      <td>0.428322</td>\n","      <td>0.577057</td>\n","      <td>0.422123</td>\n","      <td>0.410020</td>\n","      <td>0.418828</td>\n","    </tr>\n","    <tr>\n","      <th>1989</th>\n","      <td>ffa5cf6d6</td>\n","      <td>0.439320</td>\n","      <td>0.968359</td>\n","      <td>0.473887</td>\n","      <td>0.908947</td>\n","      <td>0.398759</td>\n","      <td>0.436604</td>\n","      <td>0.408183</td>\n","      <td>0.523504</td>\n","      <td>0.422283</td>\n","      <td>0.558716</td>\n","      <td>0.447559</td>\n","      <td>0.444568</td>\n","      <td>0.718647</td>\n","      <td>0.578763</td>\n","      <td>0.420089</td>\n","      <td>0.974826</td>\n","      <td>0.481199</td>\n","      <td>0.883152</td>\n","      <td>0.444549</td>\n","      <td>0.447860</td>\n","      <td>0.442554</td>\n","      <td>0.418432</td>\n","      <td>0.402981</td>\n","      <td>0.418504</td>\n","    </tr>\n","    <tr>\n","      <th>1990</th>\n","      <td>ffa88cbb8</td>\n","      <td>0.424821</td>\n","      <td>0.958047</td>\n","      <td>0.480993</td>\n","      <td>0.997520</td>\n","      <td>0.403327</td>\n","      <td>0.446201</td>\n","      <td>0.419503</td>\n","      <td>0.567482</td>\n","      <td>0.422792</td>\n","      <td>0.799238</td>\n","      <td>0.421684</td>\n","      <td>0.435941</td>\n","      <td>0.652990</td>\n","      <td>0.467525</td>\n","      <td>0.442448</td>\n","      <td>0.495663</td>\n","      <td>0.970126</td>\n","      <td>0.425163</td>\n","      <td>0.457980</td>\n","      <td>0.428844</td>\n","      <td>0.442323</td>\n","      <td>0.442131</td>\n","      <td>0.404177</td>\n","      <td>0.421897</td>\n","    </tr>\n","    <tr>\n","      <th>1991</th>\n","      <td>ffda5d7b3</td>\n","      <td>0.464751</td>\n","      <td>0.458583</td>\n","      <td>0.971020</td>\n","      <td>0.798334</td>\n","      <td>0.372287</td>\n","      <td>0.416871</td>\n","      <td>0.352953</td>\n","      <td>0.428935</td>\n","      <td>0.387459</td>\n","      <td>0.425740</td>\n","      <td>0.375594</td>\n","      <td>0.374379</td>\n","      <td>0.725192</td>\n","      <td>0.382231</td>\n","      <td>0.353924</td>\n","      <td>0.415954</td>\n","      <td>0.379064</td>\n","      <td>0.416323</td>\n","      <td>0.428781</td>\n","      <td>0.391254</td>\n","      <td>0.420051</td>\n","      <td>0.406534</td>\n","      <td>0.522329</td>\n","      <td>0.357499</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1992 rows × 25 columns</p>\n","</div>"],"text/plain":["     recording_id        s0        s1  ...       s21       s22       s23\n","0       000316da7  0.454418  0.410838  ...  0.432987  0.376018  0.398530\n","1       003bc2cb2  0.366574  0.417767  ...  0.415500  0.334942  0.353138\n","2       0061c037e  0.405547  0.412953  ...  0.366126  0.411711  0.437048\n","3       010eb14d3  0.983088  0.268766  ...  0.233189  0.208032  0.259600\n","4       011318064  0.419670  0.498061  ...  0.486663  0.381650  0.390816\n","...           ...       ...       ...  ...       ...       ...       ...\n","1987    ff68f3ac3  0.467600  0.689482  ...  0.416398  0.399951  0.981397\n","1988    ff973e852  0.410647  0.438278  ...  0.422123  0.410020  0.418828\n","1989    ffa5cf6d6  0.439320  0.968359  ...  0.418432  0.402981  0.418504\n","1990    ffa88cbb8  0.424821  0.958047  ...  0.442131  0.404177  0.421897\n","1991    ffda5d7b3  0.464751  0.458583  ...  0.406534  0.522329  0.357499\n","\n","[1992 rows x 25 columns]"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"id":"1Nz06m46imXg"},"source":["rank = last_sub_df.iloc[:,1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"jHpF_dGCCX68","executionInfo":{"elapsed":7065,"status":"ok","timestamp":1613255864561,"user":{"displayName":"篠田尚熙","photoUrl":"","userId":"15467222547494384678"},"user_tz":-540},"outputId":"30d93199-c883-4eec-b44d-7ca6c73ae703"},"source":["for i in range(24):\n","  rank[f's{i}'].hist(bins=20,range=(0, 1)); # 基数の数を20個にする  \n","\n","  plt.savefig(\"age_bins.png\")\n","\n","\n","  plt.suptitle(f's{i}')\n","  plt.show()\n","  "],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAEVCAYAAAAb/KWvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUDElEQVR4nO3df4xd5X3n8fenuJAsTmwSkhGy3ZqoLrtsUBoyTYi66o7jbdeQVUBKisjSYFLvWm1JFCmsFHej1f7WEik0ClGUxlqymIrGobQpVkJasQ6zqFWhhYZiAs3GEFPsGBwCWJlAsmHz3T/mwI6dMXPn3jt3uM+8X9JoznnOc+79Pj53Pj7z3HPPpKqQJLXlp5a7AEnS8BnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGu9RJ8ntJZuZ8/TDJ95a7Lqkf8UNM0vyS3AD8uKp+Y7lrkRbLM3etSEk+kuRwku8l+UaSLSdsPx14N7B7eSqUBrNquQuQRi3JOcAHgF+sqm8n2QicckK3dwPfAe4cbXXScBjuWon+L3AacG6S71TVwXn6bANuLOctNaacc9eKlORfAr8N/GPgz4APV9W3u20/A3wL2FRVjyxflVL/DHetaEleDXwWeL6q3te1fRT451X1y8tanDQA31DVipPknCTvSHIa8APgOeDHc7pcAdywHLVJw2K4ayU6DbgGeBJ4HHg98DsASd4OrAf+cNmqk4bAaRlJapBn7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDWop3BPsjbJLUn+LslDSd6e5DVJbk/yze77GV3fJLkuyYEk9yc5f2mHIEk6Ua9n7p8E/rSq/iHwJuAhYCewr6o2Afu6dYALgU3d1w7gM0OtWJK0oAX/ElOSNcB9wBtqTuck3wCmqupIkrOA6ao6J8lnu+XPn9jvZM9x5pln1saNG/sawPe//31OP/30vvYdV455ZXDMK8MgY7733nufrKrXzbdtVQ/7nw18B/gfSd4E3At8CJiYE9iPAxPd8jrgsTn7H+rajgv3JDuYPbNnYmKCj3/8472N5gQzMzOsXr26r33HlWNeGRzzyjDImDdv3vzoybb1Eu6rgPOBD1bV3Uk+yf+fggGgqirJov4Ya1XtAnYBTE5O1tTU1GJ2f9H09DT97juuHPPK4JhXhqUacy9z7oeAQ1V1d7d+C7Nh/0Q3HUP3/Wi3/TCwYc7+67s2SdKILBjuVfU48FiSc7qmLcCDwF5gW9e2Dbi1W94LXNFdNXMBcOyl5tslScPXy7QMwAeBm5KcCjwCvJ/Z/xhuTrIdeBS4tOt7G3ARcAB4tusrSRqhnsK9qu4DJufZtGWevgVcNWBdkqQB+AlVSWqQ4S5JDTLcJalBhrskNajXq2WkZbX/8DGu3PnlvvY9eM07h1yN9PLnmbskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWpQT+Ge5GCS/UnuS3JP1/aaJLcn+Wb3/YyuPUmuS3Igyf1Jzl/KAUiSftJiztw3V9UvVNVkt74T2FdVm4B93TrAhcCm7msH8JlhFStJ6s0g0zIXA7u75d3AJXPab6xZdwFrk5w1wPNIkhYpVbVwp+RbwNNAAZ+tql1Jnqmqtd32AE9X1dokXwKuqao/77btAz5SVfec8Jg7mD2zZ2Ji4i179uzpawAzMzOsXr26r33H1Uoc89GnjvHEc/3te966NcMtZkRW4nF2zIuzefPme+fMphxnVY+P8U+q6nCS1wO3J/m7uRurqpIs/L/E8fvsAnYBTE5O1tTU1GJ2f9H09DT97juuVuKYP3XTrVy7v9eX6/EOXj413GJGZCUeZ8c8PD1Ny1TV4e77UeCLwFuBJ16Ybum+H+26HwY2zNl9fdcmSRqRBcM9yelJXvXCMvCrwAPAXmBb120bcGu3vBe4ortq5gLgWFUdGXrlkqST6uX33Angi7PT6qwC/qCq/jTJXwM3J9kOPApc2vW/DbgIOAA8C7x/6FVLkl7SguFeVY8Ab5qn/bvAlnnaC7hqKNVJkvriJ1QlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAb1HO5JTknytSRf6tbPTnJ3kgNJvpDk1K79tG79QLd949KULkk6mcWcuX8IeGjO+seAT1TVzwFPA9u79u3A0137J7p+kqQR6inck6wH3gn89249wDuAW7ouu4FLuuWLu3W67Vu6/pKkEUlVLdwpuQX4b8CrgH8DXAnc1Z2dk2QD8JWqemOSB4CtVXWo2/Yw8LaqevKEx9wB7ACYmJh4y549e/oawMzMDKtXr+5r33G1Esd89KljPPFcf/uet27NcIsZkZV4nB3z4mzevPneqpqcb9uqhXZO8i+Ao1V1b5KpviqYR1XtAnYBTE5O1tRUfw89PT1Nv/uOq5U45k/ddCvX7l/w5Tqvg5dPDbeYEVmJx9kxD08vPy2/BLwryUXAK4BXA58E1iZZVVXPA+uBw13/w8AG4FCSVcAa4LtDr1ySdFILzrlX1e9U1fqq2ghcBny1qi4H7gDe03XbBtzaLe/t1um2f7V6mfuRJA3NINe5fwT4cJIDwGuB67v264HXdu0fBnYOVqIkabEWNYlZVdPAdLf8CPDWefr8APi1IdQmSeqTn1CVpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDFvUHsiVJx9u488sD7X/D1tOHVMnxPHOXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDVow3JO8IslfJfnbJF9P8h+79rOT3J3kQJIvJDm1az+tWz/Qbd+4tEOQJJ2olzP3HwLvqKo3Ab8AbE1yAfAx4BNV9XPA08D2rv924Omu/RNdP0nSCC0Y7jVrplv96e6rgHcAt3Ttu4FLuuWLu3W67VuSZGgVS5IW1NOce5JTktwHHAVuBx4Gnqmq57suh4B13fI64DGAbvsx4LXDLFqS9NJSVb13TtYCXwT+HXBDN/VCkg3AV6rqjUkeALZW1aFu28PA26rqyRMeawewA2BiYuIte/bs6WsAMzMzrF69uq99x9VKHPPRp47xxHP97XveujXDLWZEVuJxHscx7z98bKD9z15zSt9j3rx5871VNTnftkXdW6aqnklyB/B2YG2SVd3Z+XrgcNftMLABOJRkFbAG+O48j7UL2AUwOTlZU1NTiynlRdPT0/S777haiWP+1E23cu3+/m6FdPDyqeEWMyIr8TiP45ivHMK9ZZZizAv+tCR5HfCjLthfCfwKs2+S3gG8B9gDbANu7XbZ263/Zbf9q7WYXw+kIRvkxk4Hr3nnECuRRqeXU6GzgN1JTmF2jv7mqvpSkgeBPUn+C/A14Pqu//XA7yc5ADwFXLYEdUuSXsKC4V5V9wNvnqf9EeCt87T/APi1oVQnSeqLn1CVpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhq0YLgn2ZDkjiQPJvl6kg917a9JcnuSb3bfz+jak+S6JAeS3J/k/KUehCTpeL2cuT8PXF1V5wIXAFclORfYCeyrqk3Avm4d4EJgU/e1A/jM0KuWJL2kBcO9qo5U1d90y98DHgLWARcDu7tuu4FLuuWLgRtr1l3A2iRnDb1ySdJJrVpM5yQbgTcDdwMTVXWk2/Q4MNEtrwMem7Pboa7tCFrRNu78ct/7Xn3eEAuRVoBUVW8dk9XA/wL+a1X9cZJnqmrtnO1PV9UZSb4EXFNVf9617wM+UlX3nPB4O5idtmFiYuIte/bs6WsAMzMzrF69uq99x9W4jnn/4WN97zvxSnjiuSEW06Pz1q0Z/ZN2xvU4D2IcxzzI6xrg7DWn9D3mzZs331tVk/Nt6+nMPclPA38E3FRVf9w1P5HkrKo60k27HO3aDwMb5uy+vms7TlXtAnYBTE5O1tTUVC+l/ITp6Wn63XdcjeuYrxzozP15rt2/qF80h+Lg5VMjf84XjOtxHsQ4jnmQ1zXADVtPX5Ix93K1TIDrgYeq6nfnbNoLbOuWtwG3zmm/ortq5gLg2JzpG0nSCPRyKvRLwPuA/Unu69r+LXANcHOS7cCjwKXdttuAi4ADwLPA+4dasSRpQQuGezd3npNs3jJP/wKuGrAuSdIA/ISqJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgBcM9yeeSHE3ywJy21yS5Pck3u+9ndO1Jcl2SA0nuT3L+UhYvSZpfL2fuNwBbT2jbCeyrqk3Avm4d4EJgU/e1A/jMcMqUJC3GguFeVXcCT53QfDGwu1veDVwyp/3GmnUXsDbJWcMqVpLUm37n3Ceq6ki3/Dgw0S2vAx6b0+9Q1yZJGqFVgz5AVVWSWux+SXYwO3XDxMQE09PTfT3/zMxM3/uOq3Ed89XnPd/3vhOvHGz/fi3nv/O4HudBjOOYB31dLtWY+w33J5KcVVVHummXo137YWDDnH7ru7afUFW7gF0Ak5OTNTU11Vch09PT9LvvuBrXMV+588t973v1ec9z7f6Bz0UW7eDlUyN/zheM63EexDiOeZDXNcANW09fkjH3+9OyF9gGXNN9v3VO+weS7AHeBhybM30jSS9LGwcM6JejBcM9yeeBKeDMJIeAf89sqN+cZDvwKHBp1/024CLgAPAs8P4lqFmStIAFw72q3nuSTVvm6VvAVYMWJb1cDHpGd/Cadw6pEmlx/ISqJDXIcJekBo3+8gONtRbfeJJa5Jm7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapCXQkpLaJBLR2/YevoQK9FK45m7JDXIcJekBhnuktQg59yll6n9h4/1/YcgvBulPHOXpAYZ7pLUIKdlJB1nOe/86eWfw+OZuyQ1yDN3SU3wbw0cz3CX9LIxyBVCOp7TMpLUIM/cVxh/dV0ZPM7yzF2SGmS4S1KDDHdJapDhLkkN8g3VMeTlYpIWsiRn7km2JvlGkgNJdi7Fc0iSTm7o4Z7kFODTwIXAucB7k5w77OeRJJ3cUkzLvBU4UFWPACTZA1wMPLgEzzW2BrkO+erzhliIpCYtxbTMOuCxOeuHujZJ0oikqob7gMl7gK1V9a+69fcBb6uqD5zQbwewo1s9B/hGn095JvBkn/uOK8e8MjjmlWGQMf9sVb1uvg1LMS1zGNgwZ31913acqtoF7Br0yZLcU1WTgz7OOHHMK4NjXhmWasxLMS3z18CmJGcnORW4DNi7BM8jSTqJoZ+5V9XzST4A/BlwCvC5qvr6sJ9HknRyS/Ihpqq6DbhtKR57HgNP7Ywhx7wyOOaVYUnGPPQ3VCVJy897y0hSg8Ym3Be6pUGS05J8odt+d5KNo69yuHoY84eTPJjk/iT7kvzsctQ5TL3euiLJu5NUkrG/sqKXMSe5tDvWX0/yB6Oucdh6eG3/TJI7knyte31ftBx1DkuSzyU5muSBk2xPkuu6f4/7k5w/8JNW1cv+i9k3Zh8G3gCcCvwtcO4JfX4b+L1u+TLgC8td9wjGvBn4B93yb62EMXf9XgXcCdwFTC533SM4zpuArwFndOuvX+66RzDmXcBvdcvnAgeXu+4Bx/zLwPnAAyfZfhHwFSDABcDdgz7nuJy5v3hLg6r6P8ALtzSY62Jgd7d8C7AlSUZY47AtOOaquqOqnu1W72L2MwXjrJfjDPCfgY8BPxhlcUuklzH/a+DTVfU0QFUdHXGNw9bLmAt4dbe8Bvj2COsbuqq6E3jqJbpcDNxYs+4C1iY5a5DnHJdw7+WWBi/2qarngWPAa0dS3dJY7G0ctjP7P/84W3DM3a+rG6qqlXse93Kcfx74+SR/keSuJFtHVt3S6GXM/wH49SSHmL3y7oOjKW3ZDP22Ld7PvQFJfh2YBP7pcteylJL8FPC7wJXLXMqorWJ2amaK2d/O7kxyXlU9s6xVLa33AjdU1bVJ3g78fpI3VtWPl7uwcTEuZ+693NLgxT5JVjH7q9x3R1Ld0ujpNg5J/hnwUeBdVfXDEdW2VBYa86uANwLTSQ4yOze5d8zfVO3lOB8C9lbVj6rqW8D/Zjbsx1UvY94O3AxQVX8JvILZe7C0qqef98UYl3Dv5ZYGe4Ft3fJ7gK9W907FmFpwzEneDHyW2WAf93lYWGDMVXWsqs6sqo1VtZHZ9xneVVX3LE+5Q9HLa/tPmD1rJ8mZzE7TPDLKIoeslzH/PbAFIMk/YjbcvzPSKkdrL3BFd9XMBcCxqjoy0CMu97vIi3i3+SJmz1geBj7atf0nZn+4Yfbg/yFwAPgr4A3LXfMIxvw/gSeA+7qvvctd81KP+YS+04z51TI9HucwOx31ILAfuGy5ax7BmM8F/oLZK2nuA351uWsecLyfB44AP2L2N7HtwG8CvznnGH+6+/fYP4zXtZ9QlaQGjcu0jCRpEQx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIa9P8A3y5QAzUitUcAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}