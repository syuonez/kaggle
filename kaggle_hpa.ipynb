{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f1e3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'index': '0',\n",
      "  'memory.free': '4781',\n",
      "  'memory.total': '16160',\n",
      "  'memory.used': '11379',\n",
      "  'name': 'Tesla V100-SXM2-16GB',\n",
      "  'timestamp': '2021/05/08 07:01:30.053',\n",
      "  'utilization.gpu': '67',\n",
      "  'utilization.memory': '39',\n",
      "  'uuid': 'GPU-5271dac4-fa67-8890-3e2c-2d9a60803d6f'}]\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "DEFAULT_ATTRIBUTES = (\n",
    "    'index',\n",
    "    'uuid',\n",
    "    'name',\n",
    "    'timestamp',\n",
    "    'memory.total',\n",
    "    'memory.free',\n",
    "    'memory.used',\n",
    "    'utilization.gpu',\n",
    "    'utilization.memory'\n",
    ")\n",
    "\n",
    "def get_gpu_info(nvidia_smi_path='nvidia-smi', keys=DEFAULT_ATTRIBUTES, no_units=True):\n",
    "    nu_opt = '' if not no_units else ',nounits'\n",
    "    cmd = '%s --query-gpu=%s --format=csv,noheader%s' % (nvidia_smi_path, ','.join(keys), nu_opt)\n",
    "    output = subprocess.check_output(cmd, shell=True)\n",
    "    lines = output.decode().split('\\n')\n",
    "    lines = [ line.strip() for line in lines if line.strip() != '' ]\n",
    "\n",
    "    return [ { k: v for k, v in zip(keys, line.split(', ')) } for line in lines ]\n",
    "\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(get_gpu_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ac1863",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5692665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "\n",
      "... OTHER IMPORTS STARTING ...\n",
      "\n",
      "\n",
      "\tVERSION INFORMATION\n",
      "\t\t– NUMPY VERSION: 1.19.5\n",
      "\t\t– SCIPY VERSION: 1.6.2\n",
      "\t\t– MATPLOTLIB VERSION: 3.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pydot\n",
    "!pip install -q pydotplus\n",
    "!apt-get install -q graphviz\n",
    "\n",
    "import pandas as pd; pd.options.mode.chained_assignment = None;\n",
    "import numpy as np; print(f\"\\t\\t– NUMPY VERSION: {np.__version__}\");\n",
    "import scipy; print(f\"\\t\\t– SCIPY VERSION: {scipy.__version__}\");\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "from glob import glob\n",
    "import warnings\n",
    "import requests\n",
    "import IPython\n",
    "import urllib\n",
    "import zipfile\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import string\n",
    "import math\n",
    "import tqdm\n",
    "import time\n",
    "import gzip\n",
    "import io\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import matplotlib; print(f\"\\t\\t– MATPLOTLIB VERSION: {matplotlib.__version__}\");\n",
    "\n",
    "import PIL\n",
    "import cv2\n",
    "import ast\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "# from warmup_scheduler import GradualWarmupScheduler  # https://github.com/ildoonet/pytorch-gradual-warmup-lr\n",
    "\n",
    "import librosa, librosa.display\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from typing import Optional, List\n",
    "\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n",
    "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
    "    IAAAdditiveGaussianNoise, Transpose, HueSaturationValue, CoarseDropout,OpticalDistortion,GridDistortion\n",
    "    )\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import timm\n",
    "import torchvision.models as models\n",
    "import pathlib\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91187d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q transformers\n",
    "# !pip -q install timm\n",
    "# !pip -q install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n",
    "# !pip -q install albumentations==0.5.2\n",
    "# !pip install librosa\n",
    "# !sudo apt-get install libsndfile1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1739ab",
   "metadata": {},
   "source": [
    "# HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "823eb187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_scaled(img_id, img_dir, img_size=512, load_style=\"tf\"):\n",
    "    \"\"\" Load An Image Using ID and Directory Path - Composes 4 Individual Images \"\"\"\n",
    "    def __load_with_tf(path, img_size=512):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_png(img, channels=1)\n",
    "        return tf.image.resize(img, (img_size, img_size))[..., 0]\n",
    "    \n",
    "    def __load_with_pil(path, img_size=512):\n",
    "        img = Image.open(path)\n",
    "        img = img.resize((img_size, img_size))\n",
    "        return np.asarray(img)\n",
    "    \n",
    "    def __load_with_cv2(path, img_size=512):\n",
    "        img = cv2.imread(path, 0)\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        return img\n",
    "        \n",
    "    if load_style is \"tf\":\n",
    "        load_fn = __load_with_tf\n",
    "    elif load_style is \"PIL\":\n",
    "        load_fn = __load_with_pil\n",
    "    else:\n",
    "        load_fn = __load_with_cv2\n",
    "    \n",
    "    return np.stack(\n",
    "        [np.asarray(load_fn(os.path.join(img_dir, img_id+f\"_{c}.png\"), img_size)/255.) for c in [\"red\", \"yellow\", \"blue\"]], axis=2\n",
    "    )\n",
    "\n",
    "\n",
    "def decode_img(img, img_size=(224,224)):\n",
    "    \"\"\"TBD\"\"\"\n",
    "    \n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "\n",
    "    # resize the image to the desired size\n",
    "    return tf.cast(tf.image.resize(img, img_size), tf.uint8)\n",
    "\n",
    "\n",
    "# image loader, using rgb only here\n",
    "def load_RGBY_image(image_id, train_or_test='train', image_size=None):\n",
    "    red = read_img(image_id, \"red\", train_or_test, image_size)\n",
    "    green = read_img(image_id, \"green\", train_or_test, image_size)\n",
    "    blue = read_img(image_id, \"blue\", train_or_test, image_size)\n",
    "    #yellow = read_img(image_id, \"yellow\", train_or_test, image_size)\n",
    "    stacked_images = np.transpose(np.array([red, green, blue]), (1,2,0))\n",
    "    return stacked_images\n",
    "\n",
    "# \n",
    "def read_img(image_id, color, train_or_test='train', image_size=None):\n",
    "    filename = f'{ROOT}/{train_or_test}/{image_id}_{color}.png'\n",
    "    assert os.path.exists(filename), f'not found {filename}'\n",
    "    img = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "    if image_size is not None:\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "    if img.max() > 255:\n",
    "        img_max = img.max()\n",
    "        img = (img/255).astype('uint8')\n",
    "    return img\n",
    "\n",
    "# make annotation helper called multi processes\n",
    "def mk_ann(idx):\n",
    "    image_id = df.iloc[idx].ID\n",
    "    class_id = df.iloc[idx].Label\n",
    "    anno = mk_mmdet_custom_data(image_id, class_id)\n",
    "    img = load_RGBY_image(image_id, train_or_test)\n",
    "    cv2.imwrite(f'{img_dir}/{image_id}.jpg', img)\n",
    "    return anno, idx, image_id\n",
    "\n",
    "\n",
    "def get_color_path_maps(color_dirs, tp_id_map):\n",
    "    c_p_maps = [{k:[] for k in INT_2_STR.keys()} for _ in range(len(color_dirs))]\n",
    "    color_d_paths = [\n",
    "        [d_path for d_path in os.listdir(color_dir) if d_path.endswith(\"_256\")] \\\n",
    "        for color_dir in color_dirs\n",
    "    ]\n",
    "    for c in tqdm(color_d_paths[0], total=len(color_d_paths[0])):\n",
    "        \n",
    "        # Get class stuff\n",
    "        cls = c.split(\"_\", 1)[1].rsplit(\"_\",1)[0]\n",
    "        cls_idx = STR_2_INT_LOWER[cls]\n",
    "        \n",
    "        # Get the relevant color directories\n",
    "        c_dirs = [\n",
    "            os.path.join(color_dir, c.replace(\"red\", clr), \"data\", \"train_tiles\", cls) \\\n",
    "            for clr, color_dir in zip([\"red\", \"green\", \"blue\", \"yellow\"], color_dirs)\n",
    "        ]\n",
    "\n",
    "        # Update map\n",
    "        for f_name in tqdm(os.listdir(c_dirs[0]), total=len(os.listdir(c_dirs[0]))):\n",
    "            # get the relevant full paths\n",
    "            full_paths = [os.path.join(c_dir, f_name.replace(\"red\", clr)) for clr, c_dir in zip([\"red\", \"green\", \"blue\", \"yellow\"], c_dirs)]\n",
    "            if tp_id_map==None:\n",
    "                for c_p_map, full_path in zip(c_p_maps, full_paths):\n",
    "                    c_p_map[cls_idx].append(full_path)\n",
    "            elif (f_name.endswith(\".png\") and (\"negative\" in full_paths[0] or f_name.rsplit(\"_\", 1)[0] in tp_id_map[cls_idx])):\n",
    "                for c_p_map, full_path in zip(c_p_maps, full_paths):\n",
    "                    c_p_map[cls_idx].append(full_path)\n",
    "            else:\n",
    "                for c_p_map, full_path in zip(c_p_maps, full_paths):\n",
    "                    c_p_map[STR_2_INT[\"Negative\"]].append(full_path)\n",
    "    return [{k:sorted(v) for k,v in c_p_map.items()} for c_p_map in c_p_maps]\n",
    "\n",
    "\n",
    "def get_tp_id_map(pkl_dir):\n",
    "    \"\"\" TBD \"\"\"\n",
    "    # Capture all relevant paths\n",
    "    pkl_paths = [\n",
    "        os.path.join(pkl_dir, f_name) \\\n",
    "        for f_name in os.listdir(pkl_dir) \\\n",
    "        if f_name.endswith(\".pkl\")\n",
    "    ]\n",
    "    \n",
    "    # REMOVE AFTER UPDATING CLASSBASED NOTEBOOK\n",
    "    pkl_paths.append(\"/kaggle/input/tmp-intermediate-filaments-pkl-file/intermediate_filaments_tp_list.pkl\")\n",
    "    \n",
    "    # Initialize\n",
    "    tp_id_map = {}\n",
    "    for path in pkl_paths:\n",
    "        class_id = STR_2_INT_LOWER[path.rsplit(\"/\", 1)[1].replace(\"_tp_list.pkl\", \"\")]\n",
    "        with open(path, \"rb\") as f:\n",
    "            tp_id_map[class_id] = pickle.load(f)\n",
    "    return tp_id_map\n",
    "\n",
    "    \n",
    "def plot_rgb(arr, figsize=(12,12)):\n",
    "    \"\"\" Plot 3 Channel Microscopy Image \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(f\"RGB Composite Image\", fontweight=\"bold\")\n",
    "    plt.imshow(arr)\n",
    "    plt.axis(False)\n",
    "    plt.show()    \n",
    "\n",
    "    \n",
    "def convert_rgby_to_rgb(arr):\n",
    "    \"\"\" Convert a 4 channel (RGBY) image to a 3 channel RGB image.\n",
    "    \n",
    "    Advice From Competition Host/User: lnhtrang\n",
    "\n",
    "    For annotation (by experts) and for the model, I guess we agree that individual \n",
    "    channels with full range px values are better. \n",
    "    In annotation, we toggled the channels. \n",
    "    For visualization purpose only, you can try blending the channels. \n",
    "    For example, \n",
    "        - red = red + yellow\n",
    "        - green = green + yellow/2\n",
    "        - blue=blue.\n",
    "        \n",
    "    Args:\n",
    "        arr (numpy array): The RGBY, 4 channel numpy array for a given image\n",
    "    \n",
    "    Returns:\n",
    "        RGB Image\n",
    "    \"\"\"\n",
    "    \n",
    "    rgb_arr = np.zeros_like(arr[..., :-1])\n",
    "    rgb_arr[..., 0] = arr[..., 0]\n",
    "    rgb_arr[..., 1] = arr[..., 1]+arr[..., 3]/2\n",
    "    rgb_arr[..., 2] = arr[..., 2]\n",
    "    \n",
    "    return rgb_arr\n",
    "    \n",
    "    \n",
    "def plot_ex(arr, figsize=(20,6), title=None, plot_merged=True, rgb_only=False):\n",
    "    \"\"\" Plot 4 Channels Side by Side \"\"\"\n",
    "    if plot_merged and not rgb_only:\n",
    "        n_images=5 \n",
    "    elif plot_merged and rgb_only:\n",
    "        n_images=4\n",
    "    elif not plot_merged and rgb_only:\n",
    "        n_images=4\n",
    "    else:\n",
    "        n_images=3\n",
    "    plt.figure(figsize=figsize)\n",
    "    if type(title) == str:\n",
    "        plt.suptitle(title, fontsize=20, fontweight=\"bold\")\n",
    "\n",
    "    for i, c in enumerate([\"Red Channel – Microtubles\", \"Green Channel – Protein of Interest\", \"Blue - Nucleus\", \"Yellow – Endoplasmic Reticulum\"]):\n",
    "        if not rgb_only:\n",
    "            ch_arr = np.zeros_like(arr[..., :-1])        \n",
    "        else:\n",
    "            ch_arr = np.zeros_like(arr)\n",
    "        if c in [\"Red Channel – Microtubles\", \"Green Channel – Protein of Interest\", \"Blue - Nucleus\"]:\n",
    "            ch_arr[..., i] = arr[..., i]\n",
    "        else:\n",
    "            if rgb_only:\n",
    "                continue\n",
    "            ch_arr[..., 0] = arr[..., i]\n",
    "            ch_arr[..., 1] = arr[..., i]\n",
    "        plt.subplot(1,n_images,i+1)\n",
    "        plt.title(f\"{c.title()}\", fontweight=\"bold\")\n",
    "        plt.imshow(ch_arr)\n",
    "        plt.axis(False)\n",
    "        \n",
    "    if plot_merged:\n",
    "        plt.subplot(1,n_images,n_images)\n",
    "        \n",
    "        if rgb_only:\n",
    "            plt.title(f\"Merged RGB\", fontweight=\"bold\")\n",
    "            plt.imshow(arr)\n",
    "        else:\n",
    "            plt.title(f\"Merged RGBY into RGB\", fontweight=\"bold\")\n",
    "            plt.imshow(convert_rgby_to_rgb(arr))\n",
    "        plt.axis(False)\n",
    "        \n",
    "    plt.tight_layout(rect=[0, 0.2, 1, 0.97])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def flatten_list_of_lists(l_o_l):\n",
    "    return [item for sublist in l_o_l for item in sublist]\n",
    "\n",
    "\n",
    "def create_input_list(crp, cgp, cbp, cyp, shuffle=True, val_split=0.025):\n",
    "    lbl_arr = flatten_list_of_lists([[k,]*len(v) for k, v in sorted(crp.items())])\n",
    "    cr_arr = flatten_list_of_lists([v for k,v in sorted(crp.items())])\n",
    "    cg_arr = flatten_list_of_lists([v for k,v in sorted(cgp.items())])\n",
    "    cb_arr = flatten_list_of_lists([v for k,v in sorted(cbp.items())])\n",
    "    cy_arr = flatten_list_of_lists([v for k,v in sorted(cyp.items())])\n",
    "    \n",
    "    if val_split is not None:\n",
    "        val_lbl_arr = lbl_arr[:int(len(lbl_arr)*val_split)]\n",
    "        lbl_arr = lbl_arr[int(len(lbl_arr)*val_split):]\n",
    "        \n",
    "        val_cr_arr = cr_arr[:int(len(cr_arr)*val_split)]\n",
    "        cr_arr = cr_arr[int(len(cr_arr)*val_split):]\n",
    "        \n",
    "        val_cg_arr = cg_arr[:int(len(cg_arr)*val_split)]\n",
    "        cg_arr = cg_arr[int(len(cg_arr)*val_split):]\n",
    "        \n",
    "        val_cb_arr = cb_arr[:int(len(cb_arr)*val_split)]\n",
    "        cb_arr = cb_arr[int(len(cb_arr)*val_split):]\n",
    "\n",
    "        val_cy_arr = cy_arr[:int(len(cy_arr)*val_split)]\n",
    "        cy_arr = cy_arr[int(len(cy_arr)*val_split):]\n",
    "        \n",
    "    if shuffle:\n",
    "        to_shuffle = list(zip(cr_arr, cg_arr, cb_arr, cy_arr, lbl_arr))\n",
    "        random.shuffle(to_shuffle)\n",
    "        cr_arr, cg_arr, cb_arr, cy_arr, lbl_arr = zip(*to_shuffle)\n",
    "        \n",
    "        if val_split is not None:\n",
    "            val_to_shuffle = list(zip(val_cr_arr, val_cg_arr, val_cb_arr, val_cy_arr, val_lbl_arr))\n",
    "            random.shuffle(val_to_shuffle)\n",
    "            val_cr_arr, val_cg_arr, val_cb_arr, val_cy_arr, val_lbl_arr = zip(*val_to_shuffle)\n",
    "    \n",
    "    if val_split is None:\n",
    "        return list(cr_arr), list(cg_arr), list(cb_arr), list(cy_arr), list(lbl_arr)\n",
    "    else:\n",
    "        return (list(cr_arr), list(cg_arr), list(cb_arr), list(cy_arr), list(lbl_arr)), \\\n",
    "               (list(val_cr_arr), list(val_cg_arr), list(val_cb_arr), list(val_cy_arr), list(val_lbl_arr))\n",
    "\n",
    "\n",
    "def get_class_wts(single_ch_paths, n_classes=19, exclude_mitotic=True, multiplier=10, return_counts=False):\n",
    "    \"\"\" TBD \"\"\"\n",
    "    # Get class counts\n",
    "    class_counts = {c_idx:len(single_ch_paths[c_idx]) for c_idx in range(n_classes)}\n",
    "\n",
    "    # Exclude mitotic spindle\n",
    "    if exclude_mitotic:\n",
    "        real_min_count = list(sorted(class_counts.values(), reverse=True))[-2]\n",
    "    else:\n",
    "        real_min_count = list(sorted(class_counts.values(), reverse=True))[-1]\n",
    "\n",
    "    # Calculate weights\n",
    "    class_wts = {k:min(1, multiplier*(real_min_count/v)) for k,v in class_counts.items()}\n",
    "\n",
    "    if exclude_mitotic:\n",
    "        # Manually adjust mitotic spindle to a more appropriate value\n",
    "        class_wts[min(class_counts, key=class_counts.get)] = 1.0\n",
    "\n",
    "    if return_counts:\n",
    "        return class_wts, class_counts\n",
    "    else:\n",
    "        return class_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6c9de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_to_mask(rle_string, height, width):\n",
    "    \"\"\" Convert RLE sttring into a binary mask \n",
    "    \n",
    "    Args:\n",
    "        rle_string (rle_string): Run length encoding containing \n",
    "            segmentation mask information\n",
    "        height (int): Height of the original image the map comes from\n",
    "        width (int): Width of the original image the map comes from\n",
    "    \n",
    "    Returns:\n",
    "        Numpy array of the binary segmentation mask for a given cell\n",
    "    \"\"\"\n",
    "    rows,cols = height,width\n",
    "    rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n",
    "    rle_pairs = np.array(rle_numbers).reshape(-1,2)\n",
    "    img = np.zeros(rows*cols,dtype=np.uint8)\n",
    "    for index,length in rle_pairs:\n",
    "        index -= 1\n",
    "        img[index:index+length] = 255\n",
    "    img = img.reshape(cols,rows)\n",
    "    img = img.T\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2dabe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(image_path,image_size=256):\n",
    "#     filename = f'{ROOT}/{train_or_test}/{image_id}_{color}.png'\n",
    "#     assert os.path.exists(filename), f'not found {filename}'\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "#     if image_size is not None:\n",
    "#         img = cv2.resize(img, (image_size, image_size))\n",
    "    if img.max() > 255:\n",
    "        img_max = img.max()\n",
    "        print('==============img_max')\n",
    "        img = (img/255).astype('uint8')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "145b92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_label(cels_ids):\n",
    "    cels_ids = str(cels_ids)\n",
    "    cels_ids = eval(cels_ids)\n",
    "    len_cels_ids = len(cels_ids)\n",
    "    len_cels_ids_list = []\n",
    "    for x in range(len_cels_ids):\n",
    "        len_cels_ids_list.append(cels_ids[x].split(','))\n",
    "#     print(len_cels_ids_list)\n",
    "        \n",
    "#     cels_ids = cels_ids.split(',')#cels_ids[0].split(',')\n",
    "    labels = np.zeros(19, dtype=\"f\")\n",
    "    labels = []\n",
    "    for i in len_cels_ids_list:\n",
    "        i = i[0]\n",
    "        i = int(i)\n",
    "        labels.append(i)\n",
    "#         labels[i] = 1\n",
    "    return labels\n",
    "        \n",
    "def set_label(labe): \n",
    "    return list(set(labe))   \n",
    "\n",
    "def how_len(yum):\n",
    "    if len(yum) > 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d747ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Warmup Bug\n",
    "from warmup_scheduler import GradualWarmupScheduler  \n",
    "\n",
    "class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ac697",
   "metadata": {},
   "source": [
    "# load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298d9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_saved_path_not_pub(df):\n",
    "    return 'train/' + df\n",
    "\n",
    "def make_saved_path_pub(df):\n",
    "    return 'publichpa_1024/' + df\n",
    "\n",
    "def split_str(df):\n",
    "    common_path = df.split('_')[0]\n",
    "    return common_path\n",
    "\n",
    "def find_label(label):\n",
    "    return ('0' in label and '1' in label and  '2' in label)\n",
    "    \n",
    "def find_label(label):\n",
    "    return ('0' in label and '1' in label and  '3' in label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f3c8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_not_pub = pd.read_csv('train_df_not_pub.csv')\n",
    "train_df_pub = pd.read_csv('train_df_pub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67a6ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_not_pub['saved_path'] = train_df_not_pub.common_ID.map(make_saved_path_not_pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ff8e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_pub['saved_path'] = train_df_pub.common_ID.map(make_saved_path_pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed5cc8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_df = pd.concat([train_df_pub,train_df_not_pub]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9abe64",
   "metadata": {},
   "source": [
    "# Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2844ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ====================================================\n",
    "# Transforms\n",
    "# ====================================================\n",
    "def get_transforms(*, data):  \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "#             ToGray(),\n",
    "#             Resize(CFG.size, CFG.size),\n",
    "            RandomResizedCrop(256, 256, scale=(0.85, 1.0)),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            RandomBrightnessContrast(p=0.1, brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1)),\n",
    "            HueSaturationValue(p=0.1, hue_shift_limit=0.1, sat_shift_limit=0.1, val_shift_limit=0.1),\n",
    "            ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=5, border_mode=cv2.BORDER_CONSTANT, p=0.8),\n",
    "            Cutout(p=0.5, max_h_size=16, max_w_size=16, fill_value=(0.), num_holes=50),\n",
    "            Normalize(mean = (0.0680, 0.0583, 0.0566), std = (0.1464, 0.1249, 0.1612)\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "#             Resize(CFG.size, CFG.size),\n",
    "            Normalize(mean = (0.0680, 0.0583, 0.0566), std = (0.1464, 0.1249, 0.1612)\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff252c",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2acb02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Efficientnet_b7(nn.Module):\n",
    "    def __init__ (self):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model('tf_efficientnet_b7_ns', pretrained=True)\n",
    "        in_ch = self.backbone.classifier.in_features\n",
    "        self.backbone.classifier = nn.Linear(in_ch, 19)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb1d0c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.379715M\n"
     ]
    }
   ],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "model = Efficientnet_b7()\n",
    "    \n",
    "para = get_n_params(model)/1000000\n",
    "print(f'{para}M') # 14.9M (Ours) / 15M(Paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c391b474",
   "metadata": {},
   "source": [
    "# LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44641b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss_(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "               ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "\n",
    "        return loss.sum(dim=1).mean()\n",
    "    \n",
    "class FbetaLoss(nn.Module):\n",
    "    def __init__(self, beta=1):\n",
    "        super(FbetaLoss, self).__init__()\n",
    "        self.small_value = 1e-6\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        beta = self.beta\n",
    "        batch_size = logits.size()[0]\n",
    "        p = F.sigmoid(logits)\n",
    "        l = labels\n",
    "        num_pos = torch.sum(p, 1) + self.small_value\n",
    "        num_pos_hat = torch.sum(l, 1) + self.small_value\n",
    "        tp = torch.sum(l * p, 1)\n",
    "        precise = tp / num_pos\n",
    "        recall = tp / num_pos_hat\n",
    "        fs = (1 + beta * beta) * precise * recall / (beta * beta * precise + recall + self.small_value)\n",
    "        loss = fs.sum() / batch_size\n",
    "        return 1 - loss\n",
    "\n",
    "class CombineLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombineLoss, self).__init__()\n",
    "        self.fbeta_loss = FbetaLoss(beta=2)\n",
    "        self.focal_loss = FocalLoss_()\n",
    "        \n",
    "    def forward(self, logits, labels):\n",
    "        loss_beta = self.fbeta_loss(logits, labels)\n",
    "        loss_focal = self.focal_loss(logits, labels)\n",
    "        return 0.5 * loss_beta + 0.5 * loss_focal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "571fe8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TTA\n",
    "def get_trans(img, I):\n",
    "    if I >= 4:\n",
    "        img = img.transpose(2,3)\n",
    "    if I % 4 == 0:\n",
    "        return img\n",
    "    elif I % 4 == 1:\n",
    "        return img.flip(2)\n",
    "    elif I % 4 == 2:\n",
    "        return img.flip(3)\n",
    "    elif I % 4 == 3:\n",
    "        return img.flip(2).flip(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "beb1d704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    if CFG.device == 'GPU':\n",
    "        scaler = GradScaler()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        if CFG.device == 'GPU':\n",
    "            with autocast():\n",
    "                y_preds = model(images)\n",
    "                \n",
    "                # loss = lsep_loss_stable(y_preds, labels)\n",
    "                loss = criterion(y_preds, labels)\n",
    "                # record loss\n",
    "                losses.update(loss.item(), batch_size)\n",
    "                if CFG.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / CFG.gradient_accumulation_steps\n",
    "                scaler.scale(loss).backward()\n",
    "                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "                if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                    global_step += 1\n",
    "\n",
    "                # ############\n",
    "                # if (step + 1) % 2000 == 0:\n",
    "                #   scheduler.step()\n",
    "                # ############\n",
    "        \n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if CFG.device == 'GPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                      'Grad: {grad_norm:.4f}  '\n",
    "                      'LR: {lr:.6f}  '\n",
    "                      .format(\n",
    "                       epoch, step, len(train_loader), batch_time=batch_time,\n",
    "                       data_time=data_time, loss=losses,\n",
    "                       remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                       grad_norm=grad_norm,\n",
    "                       lr=scheduler.get_lr()[0],\n",
    "                       ))\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    trues = []\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            probs = torch.zeros((images.shape[0], 19)).to(device)#(1,19)1_cellづつだから１だが、batchでも本来可能\n",
    "            if epoch < 9:\n",
    "                TTA_REPEATS = 1\n",
    "            else:\n",
    "                TTA_REPEATS = 4\n",
    "            for I in range(TTA_REPEATS):\n",
    "                output = model(get_trans(images, I))\n",
    "                probs += torch.sigmoid(output)\n",
    "            probs /= TTA_REPEATS\n",
    "            y_preds = probs\n",
    "        loss = criterion(y_preds, labels)\n",
    "        # loss = lsep_loss_stable(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        trues.append(labels.to('cpu').numpy())\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if CFG.device == 'GPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "                print('EVAL: [{0}/{1}] '\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                      .format(\n",
    "                       step, len(valid_loader), batch_time=batch_time,\n",
    "                       data_time=data_time, loss=losses,\n",
    "                       remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                       ))\n",
    "        \n",
    "    trues = np.concatenate(trues)\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions, trues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17d25c",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8d53c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_ID</th>\n",
       "      <th>saved_label</th>\n",
       "      <th>saved_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1231_G1_1</td>\n",
       "      <td>[0, 13]</td>\n",
       "      <td>publichpa_1024/1231_G1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>264_A10_2</td>\n",
       "      <td>[2, 13, 16]</td>\n",
       "      <td>publichpa_1024/264_A10_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198_F5_1</td>\n",
       "      <td>[0, 16]</td>\n",
       "      <td>publichpa_1024/198_F5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488_C4_1</td>\n",
       "      <td>[0, 13]</td>\n",
       "      <td>publichpa_1024/488_C4_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733_F7_1</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>publichpa_1024/733_F7_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33915</th>\n",
       "      <td>ffd298f4-bbc7-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>[16, 0, 4]</td>\n",
       "      <td>train/ffd298f4-bbc7-11e8-b2bc-ac1f6b6435d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33916</th>\n",
       "      <td>ffd2b880-bba8-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>[16, 0, 3]</td>\n",
       "      <td>train/ffd2b880-bba8-11e8-b2ba-ac1f6b6435d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33917</th>\n",
       "      <td>ffe55eba-bbba-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>train/ffe55eba-bbba-11e8-b2ba-ac1f6b6435d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33918</th>\n",
       "      <td>ffe61798-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>[12, 14, 7]</td>\n",
       "      <td>train/ffe61798-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33919</th>\n",
       "      <td>ffeae6f0-bbc9-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>[16, 0]</td>\n",
       "      <td>train/ffeae6f0-bbc9-11e8-b2bc-ac1f6b6435d0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  common_ID  saved_label  \\\n",
       "0                                 1231_G1_1      [0, 13]   \n",
       "1                                 264_A10_2  [2, 13, 16]   \n",
       "2                                  198_F5_1      [0, 16]   \n",
       "3                                  488_C4_1      [0, 13]   \n",
       "4                                  733_F7_1       [0, 1]   \n",
       "...                                     ...          ...   \n",
       "33915  ffd298f4-bbc7-11e8-b2bc-ac1f6b6435d0   [16, 0, 4]   \n",
       "33916  ffd2b880-bba8-11e8-b2ba-ac1f6b6435d0   [16, 0, 3]   \n",
       "33917  ffe55eba-bbba-11e8-b2ba-ac1f6b6435d0       [0, 5]   \n",
       "33918  ffe61798-bbc3-11e8-b2bc-ac1f6b6435d0  [12, 14, 7]   \n",
       "33919  ffeae6f0-bbc9-11e8-b2bc-ac1f6b6435d0      [16, 0]   \n",
       "\n",
       "                                       saved_path  \n",
       "0                        publichpa_1024/1231_G1_1  \n",
       "1                        publichpa_1024/264_A10_2  \n",
       "2                         publichpa_1024/198_F5_1  \n",
       "3                         publichpa_1024/488_C4_1  \n",
       "4                         publichpa_1024/733_F7_1  \n",
       "...                                           ...  \n",
       "33915  train/ffd298f4-bbc7-11e8-b2bc-ac1f6b6435d0  \n",
       "33916  train/ffd2b880-bba8-11e8-b2ba-ac1f6b6435d0  \n",
       "33917  train/ffe55eba-bbba-11e8-b2ba-ac1f6b6435d0  \n",
       "33918  train/ffe61798-bbc3-11e8-b2bc-ac1f6b6435d0  \n",
       "33919  train/ffeae6f0-bbc9-11e8-b2bc-ac1f6b6435d0  \n",
       "\n",
       "[33920 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f139ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3色混ぜて出力\n",
    "class HPADataset(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            df,\n",
    "            transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        record = self.df.iloc[idx]\n",
    "        dir_path = '/home/ubuntu/'\n",
    "        path_img = record['saved_path']\n",
    "        img = np.stack([\n",
    "        cv2.imread(f'/home/ubuntu/{path_img}_red.png', 0),\n",
    "        cv2.imread(f'/home/ubuntu/{path_img}_green.png', 0),\n",
    "        cv2.imread(f'/home/ubuntu/{path_img}_blue.png', 0),\n",
    "        ], axis=2)\n",
    "        if img.max() > 255:#if uint16 \n",
    "                img = cv2.convertScaleAbs(img, alpha=(255.0/65535.0))#uint8\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img)\n",
    "            img = augmented['image']\n",
    "\n",
    "        labels = np.zeros(19, dtype=\"f\")\n",
    "        cels_ids = record['saved_label']#.split(',') \n",
    "\n",
    "        for i in cels_ids:\n",
    "            i = int(i)\n",
    "            labels[i] = 1\n",
    "\n",
    "        # img = img.float()\n",
    "        labels = torch.tensor(labels).float()\n",
    "        return img,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257114a0",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b887c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# train_dataset = HPADataset(train_all_df, transform=get_transforms(data='train'))#get_transforms(data='train')\n",
    "\n",
    "# for i in range(20000,20005,1):\n",
    "#     image, label = train_dataset[i]\n",
    "#     print(image.shape)\n",
    "#     print(image.dtype)\n",
    "#     print(image[0].max())\n",
    "#     print(image[0].min())\n",
    "#     plt.imshow(image[0])\n",
    "#     plt.show()\n",
    "#     plt.imshow(image[1])\n",
    "#     plt.show()\n",
    "#     plt.imshow(image[2])\n",
    "#     plt.show()\n",
    "# #     plt.imshow(image.cpu().numpy().transpose((1, 2, 0)))\n",
    "#     print(image.transpose(0, 1).transpose(1,2).squeeze().shape)\n",
    "#     plt.imshow(image.transpose(0, 1).transpose(1,2).squeeze())\n",
    "# #     plt.imshow(image.squeeze().permute(1,2,0))\n",
    "#     plt.title(f'label: {label}')\n",
    "#     plt.show() \n",
    "#     plt.imshow(np.array(image).transpose((1,2,0)))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071b3e3",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "039fcda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "OUTPUT_DIR =  'OUTPUT/exp27_hpa_train_cropmodel_eff5/'\n",
    "TTA_REPEATS = 4\n",
    "\n",
    "if not os.path.exists(f'/home/ubuntu/{OUTPUT_DIR}'):\n",
    "    os.mkdir(f'/home/ubuntu/{OUTPUT_DIR}')\n",
    "\n",
    "class CFG:\n",
    "    debug=False\n",
    "    trn_fold=[0]\n",
    "    pretrain_weights =None#'/home/syuonez/OUTPUT/exp19_hpa_train_all_multi_1st_effnet5/tf_efficientnet_b5_fold0_epoch6.pth'\n",
    "    device='GPU' \n",
    "    nprocs=1 \n",
    "    print_freq=1000\n",
    "    num_workers=4\n",
    "    model_name='tf_efficientnet_b7'\n",
    "    size=1024#<===\n",
    "    scheduler='CosineAnnealingLR' \n",
    "    start_epcoh = 0\n",
    "    freeze_epo = 0\n",
    "    warmup_epo = 2\n",
    "    cosine_epo = 10\n",
    "    epochs= freeze_epo + warmup_epo + cosine_epo\n",
    "    T_max=10\n",
    "    warmup_epo = 2\n",
    "    T_0=5\n",
    "    lr=1e-4\n",
    "    min_lr=1e-6\n",
    "    batch_size=2\n",
    "    weight_decay=1e-6\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    seed=42\n",
    "    target_cols=['0', '1', '2','3', '4', '5', '6', '7', '8', '9','10', '11', '12', '13', '14', '15', '16', '17', '18']               \n",
    "    n_fold=5\n",
    "    train=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4731007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        try:\n",
    "            score = roc_auc_score(y_true[:,i], y_pred[:,i])\n",
    "            scores.append(score)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    return avg_score, scores\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7770c103",
   "metadata": {},
   "source": [
    "# LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9748a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold):\n",
    "   \n",
    "    if CFG.device == 'GPU':\n",
    "        LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "#     if CFG.debug:\n",
    "#         train_folds = train_folds.sample(n=200, random_state=CFG.seed).reset_index(drop=True)\n",
    "#     train_folds = train_folds.sample(n=100)\n",
    "#     valid_folds = valid_folds.sample(n=100)\n",
    "    train_dataset = HPADataset(train_folds, transform=get_transforms(data='train'))\n",
    "    valid_dataset = HPADataset(valid_folds, transform=get_transforms(data='valid'))\n",
    "\n",
    "    valid_labels = valid_folds['saved_label'].values\n",
    "\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=True, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                              batch_size=CFG.batch_size * 2, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    valid_labels_onehot_all = []\n",
    "    for cel_labels_valid in valid_labels:\n",
    "        valid_labels_onehot = np.zeros(19, dtype=\"f\")\n",
    "        cels_ids_ = eval(cel_labels_valid)#cel_labels_valid.split(',')\n",
    "        for u in cels_ids_:\n",
    "            t = int(u)\n",
    "            valid_labels_onehot[t] = 1\n",
    "        valid_labels_onehot_all.append(valid_labels_onehot)\n",
    "    valid_labels_onehot_all = np.asarray(valid_labels_onehot_all)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer & scheduler\n",
    "    # ====================================================\n",
    "    model = Efficientnet_b5()#SErexnext50()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #####再学習#####\n",
    "    if CFG.pretrain_weights:\n",
    "        print(\"---------------------loading pretrain weights\")\n",
    "        checkpoint = torch.load(CFG.pretrain_weights)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    #####再学習#####\n",
    "\n",
    "#     optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "    optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-5)\n",
    "#     optimizer = AdamP(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "#     optimizer = optim.RAdam(model.parameters(),lr= CFG.lr,betas=(0.9, 0.999),eps=1e-8,weight_decay=0,)\n",
    "\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, CFG.cosine_epo)\n",
    "    scheduler = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=CFG.warmup_epo, after_scheduler=scheduler_cosine)\n",
    "    # scheduler = MultiStepLR(optimizer, milestones=[200, 350], gamma=0.5)\n",
    "    # scheduler = get_scheduler(optimizer)\n",
    "    \n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = CombineLoss()#FocalLoss_()#CombineLoss()#CombineLoss()#ResampleLoss()#CombineLoss()\n",
    "\n",
    "    best_score = 0.\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    ####再学習#####\n",
    "    if CFG.pretrain_weights:\n",
    "        print(\"---------------------loading pretrain weights\")\n",
    "        # model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to('cuda')\n",
    "    ##############\n",
    "    \n",
    "    \n",
    "    ####再学習#####\n",
    "    current_epoch= 0\n",
    "    if CFG.pretrain_weights:\n",
    "        print('=>skip_current_epoch')\n",
    "        current_epoch = checkpoint['epoch'] + 1 #train中に止まると仮定　epoch5中　(checkpoint['epoch']==4) + 1\n",
    "        print('current_epoch',current_epoch)\n",
    "        CFG.start_epcoh = current_epoch \n",
    "        print(f'Config.start_epcoh={CFG.start_epcoh}=======>Config.epochs={CFG.epochs}')\n",
    "        for _ in range(current_epoch):#lrをcurrent_epochにする為\n",
    "            scheduler.step()\n",
    " #===============================================================================   \n",
    "    for epoch in range(CFG.start_epcoh, CFG.epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds, _ = valid_fn(valid_loader, model, criterion, device,epoch)\n",
    "\n",
    "        #warmup\n",
    "        scheduler.step()#epoch5でsave scheはepoch6状態\n",
    "\n",
    "        #scoring\n",
    "        score, scores = get_score(valid_labels_onehot_all, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        if CFG.device == 'GPU':\n",
    "            LOGGER.info(f'Epoch {epoch} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "            LOGGER.info(f'Epoch {epoch} - Score: {score:.4f}  Scores: {np.round(scores, decimals=4)}')\n",
    "\n",
    "        #save\n",
    "        LOGGER.info(f'Epoch {epoch} - Save Best Score: {best_score:.4f} Model')\n",
    "        torch.save({'model_state_dict': model.state_dict(), \n",
    "                          'preds': preds,\n",
    "                          'epoch':epoch,\n",
    "                          'optimizer_state_dict': optimizer.state_dict(),\n",
    "                          'scheduler_state_dict': scheduler.state_dict()},\n",
    "                           OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_epoch{epoch}.pth')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            if CFG.device == 'GPU':\n",
    "                LOGGER.info(f'Epoch {epoch} - Save Best Score: {best_score:.4f} Model')\n",
    "                torch.save({'model_state_dict': model.state_dict(), \n",
    "                          'preds': preds,\n",
    "                          'epoch':epoch,\n",
    "                          'optimizer_state_dict': optimizer.state_dict(),\n",
    "                          'scheduler_state_dict': scheduler.state_dict()},\n",
    "                           OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n",
    "\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            if CFG.device == 'GPU':\n",
    "                LOGGER.info(f'Epoch {epoch} - Save Best Loss: {best_loss:.4f} Model')\n",
    "                torch.save({'model_state_dict': model.state_dict(), \n",
    "                          'preds': preds,\n",
    "                          'epoch':epoch,\n",
    "                          'optimizer_state_dict': optimizer.state_dict(),\n",
    "                          'scheduler_state_dict': scheduler.state_dict()},\n",
    "                           OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth')\n",
    "#==========================================================================================\n",
    "            \n",
    "    \n",
    "    if CFG.nprocs != 8:\n",
    "        check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n",
    "        row_len = len(check_point['preds'])\n",
    "        oof_df = pd.DataFrame(np.zeros((row_len,19)),columns = CFG.target_cols)\n",
    "        oof_df[CFG.target_cols] = check_point['preds']\n",
    "\n",
    "    return oof_df,valid_labels_onehot_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7871988a",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f321aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Prepare: 1.train  2.folds\n",
    "    \"\"\"\n",
    "    def get_result(result_df,labels):#labels arr\n",
    "        preds = result_df.values\n",
    "#         labels = fold_oof[CFG.target_cols].values\n",
    "        score, scores = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.4f}  Scores: {np.round(scores, decimals=4)}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        oof_label_all = []\n",
    "        for cel_labels in train_all_df.saved_label.values:\n",
    "            oof_labels_onehot = np.zeros(19, dtype=\"f\")\n",
    "            cels_ids = eval(cel_labels)\n",
    "            for i in cels_ids:\n",
    "                i = int(i)\n",
    "                oof_labels_onehot[i] = 1\n",
    "            oof_label_all.append(oof_labels_onehot)\n",
    "        oof_label_all = np.asarray(oof_label_all)\n",
    "\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df,fold_oof = train_loop(train_all_df, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df,fold_oof)\n",
    "                if len(CFG.trn_fold) == 1:\n",
    "                    print(f'======>saveing.....fold{fold}_oof_df.csv')\n",
    "                    oof_df.to_csv(OUTPUT_DIR+f'fold{fold}_oof_df.csv', index=False)\n",
    "                    \n",
    "                    \n",
    "        if CFG.nprocs != 8:\n",
    "            # CV result\n",
    "            LOGGER.info(f\"========== CV ==========\")\n",
    "            get_result(oof_df,oof_label_all)\n",
    "            # save result\n",
    "            print(f'======>saveing.....{OUTPUT_DIR}all_fold_oof_df.csv')\n",
    "            oof_df.to_csv(OUTPUT_DIR+'all_fold_oof_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3138cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "========== fold: 0 training ==========\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/16559] Data 0.546 (0.546) Elapsed 0m 0s (remain 233m 17s) Loss: 1.9965(1.9965) Grad: 166244.1562  LR: 0.001000  \n",
      "Epoch: [0][1000/16559] Data 0.000 (0.001) Elapsed 3m 42s (remain 57m 45s) Loss: 1.7692(1.8738) Grad: 149388.6875  LR: 0.001000  \n",
      "Epoch: [0][2000/16559] Data 0.000 (0.000) Elapsed 7m 25s (remain 53m 57s) Loss: 1.5328(1.7596) Grad: 86461.0234  LR: 0.001000  \n",
      "Epoch: [0][3000/16559] Data 0.000 (0.000) Elapsed 11m 6s (remain 50m 11s) Loss: 1.3486(1.6532) Grad: 84596.8672  LR: 0.001000  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':#exp19\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e93730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp19 = pd.read_csv('OUTPUT/exp19_hpa_train_all_multi_1st_effnet5/all_fold_oof_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf657749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.452583</td>\n",
       "      <td>0.065082</td>\n",
       "      <td>0.417432</td>\n",
       "      <td>0.121861</td>\n",
       "      <td>0.032187</td>\n",
       "      <td>0.269144</td>\n",
       "      <td>0.018252</td>\n",
       "      <td>0.132344</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.105704</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>0.006493</td>\n",
       "      <td>0.301697</td>\n",
       "      <td>0.161969</td>\n",
       "      <td>0.077482</td>\n",
       "      <td>0.057907</td>\n",
       "      <td>0.401986</td>\n",
       "      <td>0.093884</td>\n",
       "      <td>0.003126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454949</td>\n",
       "      <td>0.088162</td>\n",
       "      <td>0.334720</td>\n",
       "      <td>0.181567</td>\n",
       "      <td>0.012136</td>\n",
       "      <td>0.311893</td>\n",
       "      <td>0.013568</td>\n",
       "      <td>0.149284</td>\n",
       "      <td>0.068272</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.017129</td>\n",
       "      <td>0.008582</td>\n",
       "      <td>0.467314</td>\n",
       "      <td>0.092692</td>\n",
       "      <td>0.079637</td>\n",
       "      <td>0.070031</td>\n",
       "      <td>0.218545</td>\n",
       "      <td>0.086124</td>\n",
       "      <td>0.011864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.487202</td>\n",
       "      <td>0.069489</td>\n",
       "      <td>0.204527</td>\n",
       "      <td>0.057138</td>\n",
       "      <td>0.030402</td>\n",
       "      <td>0.130926</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>0.055931</td>\n",
       "      <td>0.198096</td>\n",
       "      <td>0.032273</td>\n",
       "      <td>0.037710</td>\n",
       "      <td>0.405196</td>\n",
       "      <td>0.135363</td>\n",
       "      <td>0.107625</td>\n",
       "      <td>0.072113</td>\n",
       "      <td>0.270291</td>\n",
       "      <td>0.191561</td>\n",
       "      <td>0.011221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.454523</td>\n",
       "      <td>0.043706</td>\n",
       "      <td>0.190375</td>\n",
       "      <td>0.016845</td>\n",
       "      <td>0.040466</td>\n",
       "      <td>0.313066</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>0.053603</td>\n",
       "      <td>0.013419</td>\n",
       "      <td>0.072310</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>0.186313</td>\n",
       "      <td>0.032767</td>\n",
       "      <td>0.047692</td>\n",
       "      <td>0.014605</td>\n",
       "      <td>0.518120</td>\n",
       "      <td>0.061848</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.517837</td>\n",
       "      <td>0.142062</td>\n",
       "      <td>0.294394</td>\n",
       "      <td>0.091637</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>0.272183</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.111612</td>\n",
       "      <td>0.064060</td>\n",
       "      <td>0.105985</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.438428</td>\n",
       "      <td>0.102441</td>\n",
       "      <td>0.073953</td>\n",
       "      <td>0.076477</td>\n",
       "      <td>0.174567</td>\n",
       "      <td>0.111220</td>\n",
       "      <td>0.007209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59806</th>\n",
       "      <td>0.332458</td>\n",
       "      <td>0.122087</td>\n",
       "      <td>0.194189</td>\n",
       "      <td>0.452079</td>\n",
       "      <td>0.250288</td>\n",
       "      <td>0.371924</td>\n",
       "      <td>0.010424</td>\n",
       "      <td>0.183149</td>\n",
       "      <td>0.131522</td>\n",
       "      <td>0.250703</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>0.208870</td>\n",
       "      <td>0.270853</td>\n",
       "      <td>0.138432</td>\n",
       "      <td>0.076697</td>\n",
       "      <td>0.251885</td>\n",
       "      <td>0.176746</td>\n",
       "      <td>0.012299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59807</th>\n",
       "      <td>0.473109</td>\n",
       "      <td>0.100693</td>\n",
       "      <td>0.173211</td>\n",
       "      <td>0.183406</td>\n",
       "      <td>0.076741</td>\n",
       "      <td>0.193342</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>0.191492</td>\n",
       "      <td>0.180238</td>\n",
       "      <td>0.311742</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.006776</td>\n",
       "      <td>0.246767</td>\n",
       "      <td>0.289809</td>\n",
       "      <td>0.165872</td>\n",
       "      <td>0.055248</td>\n",
       "      <td>0.334935</td>\n",
       "      <td>0.069367</td>\n",
       "      <td>0.010210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59808</th>\n",
       "      <td>0.405866</td>\n",
       "      <td>0.112408</td>\n",
       "      <td>0.223267</td>\n",
       "      <td>0.232118</td>\n",
       "      <td>0.103992</td>\n",
       "      <td>0.265668</td>\n",
       "      <td>0.018285</td>\n",
       "      <td>0.274021</td>\n",
       "      <td>0.164278</td>\n",
       "      <td>0.330791</td>\n",
       "      <td>0.026996</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.310258</td>\n",
       "      <td>0.401818</td>\n",
       "      <td>0.137493</td>\n",
       "      <td>0.141468</td>\n",
       "      <td>0.273663</td>\n",
       "      <td>0.202106</td>\n",
       "      <td>0.017230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59809</th>\n",
       "      <td>0.201377</td>\n",
       "      <td>0.132124</td>\n",
       "      <td>0.118362</td>\n",
       "      <td>0.357336</td>\n",
       "      <td>0.175493</td>\n",
       "      <td>0.244609</td>\n",
       "      <td>0.053917</td>\n",
       "      <td>0.212638</td>\n",
       "      <td>0.171955</td>\n",
       "      <td>0.321731</td>\n",
       "      <td>0.073186</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.313417</td>\n",
       "      <td>0.316121</td>\n",
       "      <td>0.082088</td>\n",
       "      <td>0.153788</td>\n",
       "      <td>0.425528</td>\n",
       "      <td>0.224824</td>\n",
       "      <td>0.023224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59810</th>\n",
       "      <td>0.190011</td>\n",
       "      <td>0.095028</td>\n",
       "      <td>0.096634</td>\n",
       "      <td>0.202662</td>\n",
       "      <td>0.125581</td>\n",
       "      <td>0.158600</td>\n",
       "      <td>0.120240</td>\n",
       "      <td>0.179038</td>\n",
       "      <td>0.184554</td>\n",
       "      <td>0.268430</td>\n",
       "      <td>0.071798</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.335108</td>\n",
       "      <td>0.228835</td>\n",
       "      <td>0.137511</td>\n",
       "      <td>0.173690</td>\n",
       "      <td>0.552480</td>\n",
       "      <td>0.205627</td>\n",
       "      <td>0.021771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59811 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.452583  0.065082  0.417432  0.121861  0.032187  0.269144  0.018252   \n",
       "1      0.454949  0.088162  0.334720  0.181567  0.012136  0.311893  0.013568   \n",
       "2      0.487202  0.069489  0.204527  0.057138  0.030402  0.130926  0.009681   \n",
       "3      0.454523  0.043706  0.190375  0.016845  0.040466  0.313066  0.015094   \n",
       "4      0.517837  0.142062  0.294394  0.091637  0.009651  0.272183  0.008066   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "59806  0.332458  0.122087  0.194189  0.452079  0.250288  0.371924  0.010424   \n",
       "59807  0.473109  0.100693  0.173211  0.183406  0.076741  0.193342  0.026596   \n",
       "59808  0.405866  0.112408  0.223267  0.232118  0.103992  0.265668  0.018285   \n",
       "59809  0.201377  0.132124  0.118362  0.357336  0.175493  0.244609  0.053917   \n",
       "59810  0.190011  0.095028  0.096634  0.202662  0.125581  0.158600  0.120240   \n",
       "\n",
       "              7         8         9        10        11        12        13  \\\n",
       "0      0.132344  0.048919  0.105704  0.006168  0.006493  0.301697  0.161969   \n",
       "1      0.149284  0.068272  0.085308  0.017129  0.008582  0.467314  0.092692   \n",
       "2      0.079832  0.055931  0.198096  0.032273  0.037710  0.405196  0.135363   \n",
       "3      0.053603  0.013419  0.072310  0.001398  0.004281  0.186313  0.032767   \n",
       "4      0.111612  0.064060  0.105985  0.008542  0.004384  0.438428  0.102441   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "59806  0.183149  0.131522  0.250703  0.025751  0.006302  0.208870  0.270853   \n",
       "59807  0.191492  0.180238  0.311742  0.067532  0.006776  0.246767  0.289809   \n",
       "59808  0.274021  0.164278  0.330791  0.026996  0.010769  0.310258  0.401818   \n",
       "59809  0.212638  0.171955  0.321731  0.073186  0.006951  0.313417  0.316121   \n",
       "59810  0.179038  0.184554  0.268430  0.071798  0.009994  0.335108  0.228835   \n",
       "\n",
       "             14        15        16        17        18  \n",
       "0      0.077482  0.057907  0.401986  0.093884  0.003126  \n",
       "1      0.079637  0.070031  0.218545  0.086124  0.011864  \n",
       "2      0.107625  0.072113  0.270291  0.191561  0.011221  \n",
       "3      0.047692  0.014605  0.518120  0.061848  0.000529  \n",
       "4      0.073953  0.076477  0.174567  0.111220  0.007209  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "59806  0.138432  0.076697  0.251885  0.176746  0.012299  \n",
       "59807  0.165872  0.055248  0.334935  0.069367  0.010210  \n",
       "59808  0.137493  0.141468  0.273663  0.202106  0.017230  \n",
       "59809  0.082088  0.153788  0.425528  0.224824  0.023224  \n",
       "59810  0.137511  0.173690  0.552480  0.205627  0.021771  \n",
       "\n",
       "[59811 rows x 19 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp19"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
